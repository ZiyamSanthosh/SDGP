{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BreastCancerData (4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BreastFeeding</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>BreastCancerHistory</th>\n",
       "      <th>Age at firstPeriod</th>\n",
       "      <th>MenstrualCycle</th>\n",
       "      <th>Cancer Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>8.543723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10.204207</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>13.807133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>14.088867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>14.494061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  BreastFeeding  Marital Status  Alcohol  Smoking  \\\n",
       "0   48   8.543723              1               1        0        0   \n",
       "1   31  10.204207              1               1        0        0   \n",
       "2   31  13.807133              1               1        0        0   \n",
       "3   33  14.088867              1               1        1        0   \n",
       "4   49  14.494061              1               1        0        0   \n",
       "\n",
       "   BreastCancerHistory  Age at firstPeriod  MenstrualCycle  Cancer Positive  \n",
       "0                    0                  15               1                0  \n",
       "1                    0                  12               1                0  \n",
       "2                    0                  14               1                0  \n",
       "3                    0                  12               1                0  \n",
       "4                    0                  15               1                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>41.029313</td>\n",
       "      <td>7.694522</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BMI</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>24.723056</td>\n",
       "      <td>4.939623</td>\n",
       "      <td>8.543723</td>\n",
       "      <td>21.168699</td>\n",
       "      <td>24.453841</td>\n",
       "      <td>27.657793</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BreastFeeding</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.891122</td>\n",
       "      <td>0.311551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marital Status</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>1.126466</td>\n",
       "      <td>0.455754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Alcohol</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.351340</td>\n",
       "      <td>0.477489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Smoking</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.154941</td>\n",
       "      <td>0.361925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BreastCancerHistory</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>0.168718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age at firstPeriod</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>13.104690</td>\n",
       "      <td>1.684577</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MenstrualCycle</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.413093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cancer Positive</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.404523</td>\n",
       "      <td>0.490902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean       std        min        25%  \\\n",
       "Age                  2388.0  41.029313  7.694522  21.000000  35.000000   \n",
       "BMI                  2388.0  24.723056  4.939623   8.543723  21.168699   \n",
       "BreastFeeding        2388.0   0.891122  0.311551   0.000000   1.000000   \n",
       "Marital Status       2388.0   1.126466  0.455754   1.000000   1.000000   \n",
       "Alcohol              2388.0   0.351340  0.477489   0.000000   0.000000   \n",
       "Smoking              2388.0   0.154941  0.361925   0.000000   0.000000   \n",
       "BreastCancerHistory  2388.0   0.029313  0.168718   0.000000   0.000000   \n",
       "Age at firstPeriod   2388.0  13.104690  1.684577   8.000000  12.000000   \n",
       "MenstrualCycle       2388.0   0.781826  0.413093   0.000000   1.000000   \n",
       "Cancer Positive      2388.0   0.404523  0.490902   0.000000   0.000000   \n",
       "\n",
       "                           50%        75%   max  \n",
       "Age                  41.000000  48.000000  54.0  \n",
       "BMI                  24.453841  27.657793  69.5  \n",
       "BreastFeeding         1.000000   1.000000   1.0  \n",
       "Marital Status        1.000000   1.000000   3.0  \n",
       "Alcohol               0.000000   1.000000   1.0  \n",
       "Smoking               0.000000   0.000000   1.0  \n",
       "BreastCancerHistory   0.000000   0.000000   1.0  \n",
       "Age at firstPeriod   13.000000  14.000000  21.0  \n",
       "MenstrualCycle        1.000000   1.000000   1.0  \n",
       "Cancer Positive       0.000000   1.000000   1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2388 entries, 0 to 2387\n",
      "Data columns (total 10 columns):\n",
      "Age                    2388 non-null int64\n",
      "BMI                    2388 non-null float64\n",
      "BreastFeeding          2388 non-null int64\n",
      "Marital Status         2388 non-null int64\n",
      "Alcohol                2388 non-null int64\n",
      "Smoking                2388 non-null int64\n",
      "BreastCancerHistory    2388 non-null int64\n",
      "Age at firstPeriod     2388 non-null int64\n",
      "MenstrualCycle         2388 non-null int64\n",
      "Cancer Positive        2388 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 186.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26227704448>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Cancer Positive',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MenstrualCycle        -0.527303\n",
       "Age at firstPeriod    -0.143939\n",
       "BreastFeeding         -0.125521\n",
       "Alcohol                0.040402\n",
       "Smoking                0.047929\n",
       "BreastCancerHistory    0.145085\n",
       "Marital Status         0.230007\n",
       "BMI                    0.360163\n",
       "Age                    0.387485\n",
       "Name: Cancer Positive, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Cancer Positive'][:-1].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Cancer Positive',axis=1).values\n",
    "y = df['Cancer Positive'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.        ,  8.5437225 ,  1.        , ...,  0.        ,\n",
       "        15.        ,  1.        ],\n",
       "       [31.        , 10.20420723,  1.        , ...,  0.        ,\n",
       "        12.        ,  1.        ],\n",
       "       [31.        , 13.80713296,  1.        , ...,  0.        ,\n",
       "        14.        ,  1.        ],\n",
       "       ...,\n",
       "       [51.        , 44.17113007,  0.        , ...,  1.        ,\n",
       "        14.        ,  0.        ],\n",
       "       [41.        , 57.76097459,  1.        , ...,  0.        ,\n",
       "        13.        ,  1.        ],\n",
       "       [35.        , 69.5       ,  1.        , ...,  1.        ,\n",
       "        15.        ,  1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1791, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9,activation='relu',input_shape=(9, )))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1791 samples, validate on 597 samples\n",
      "Epoch 1/1000\n",
      "1791/1791 [==============================] - 2s 1ms/sample - loss: 0.6929 - val_loss: 0.6862\n",
      "Epoch 2/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.6750 - val_loss: 0.6703\n",
      "Epoch 3/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.6590 - val_loss: 0.6555\n",
      "Epoch 4/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.6451 - val_loss: 0.6417\n",
      "Epoch 5/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.6320 - val_loss: 0.6287\n",
      "Epoch 6/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.6203 - val_loss: 0.6166\n",
      "Epoch 7/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.6089 - val_loss: 0.6040\n",
      "Epoch 8/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.5969 - val_loss: 0.5914\n",
      "Epoch 9/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.5856 - val_loss: 0.5789\n",
      "Epoch 10/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.5744 - val_loss: 0.5662\n",
      "Epoch 11/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.5625 - val_loss: 0.5538\n",
      "Epoch 12/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.5511 - val_loss: 0.5404\n",
      "Epoch 13/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.5393 - val_loss: 0.5277\n",
      "Epoch 14/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.5278 - val_loss: 0.5155\n",
      "Epoch 15/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.5174 - val_loss: 0.5033\n",
      "Epoch 16/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.5068 - val_loss: 0.4927\n",
      "Epoch 17/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.4970 - val_loss: 0.4823\n",
      "Epoch 18/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.4880 - val_loss: 0.4724\n",
      "Epoch 19/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.4794 - val_loss: 0.4633\n",
      "Epoch 20/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4716 - val_loss: 0.4554\n",
      "Epoch 21/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4641 - val_loss: 0.4472\n",
      "Epoch 22/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.4571 - val_loss: 0.4398\n",
      "Epoch 23/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4506 - val_loss: 0.4327\n",
      "Epoch 24/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4442 - val_loss: 0.4264\n",
      "Epoch 25/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.4381 - val_loss: 0.4196\n",
      "Epoch 26/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.4326 - val_loss: 0.4124\n",
      "Epoch 27/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.4249 - val_loss: 0.4049\n",
      "Epoch 28/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4162 - val_loss: 0.3945\n",
      "Epoch 29/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.4082 - val_loss: 0.3873\n",
      "Epoch 30/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.4017 - val_loss: 0.3802\n",
      "Epoch 31/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3951 - val_loss: 0.3748\n",
      "Epoch 32/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3900 - val_loss: 0.3693\n",
      "Epoch 33/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3849 - val_loss: 0.3662\n",
      "Epoch 34/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3804 - val_loss: 0.3611\n",
      "Epoch 35/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3759 - val_loss: 0.3574\n",
      "Epoch 36/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3726 - val_loss: 0.3534\n",
      "Epoch 37/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3683 - val_loss: 0.3500\n",
      "Epoch 38/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3643 - val_loss: 0.3468\n",
      "Epoch 39/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3617 - val_loss: 0.3428\n",
      "Epoch 40/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3579 - val_loss: 0.3415\n",
      "Epoch 41/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3544 - val_loss: 0.3381\n",
      "Epoch 42/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3521 - val_loss: 0.3348\n",
      "Epoch 43/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.3495 - val_loss: 0.3326\n",
      "Epoch 44/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3466 - val_loss: 0.3306\n",
      "Epoch 45/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.3442 - val_loss: 0.3282\n",
      "Epoch 46/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3415 - val_loss: 0.3273\n",
      "Epoch 47/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3392 - val_loss: 0.3234\n",
      "Epoch 48/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.3374 - val_loss: 0.3247\n",
      "Epoch 49/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3350 - val_loss: 0.3193\n",
      "Epoch 50/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3349 - val_loss: 0.3203\n",
      "Epoch 51/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3327 - val_loss: 0.3162\n",
      "Epoch 52/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3303 - val_loss: 0.3172\n",
      "Epoch 53/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3281 - val_loss: 0.3139\n",
      "Epoch 54/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3268 - val_loss: 0.3135\n",
      "Epoch 55/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3258 - val_loss: 0.3102\n",
      "Epoch 56/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.3260 - val_loss: 0.3118\n",
      "Epoch 57/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.3228 - val_loss: 0.3079\n",
      "Epoch 58/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.3221 - val_loss: 0.3069\n",
      "Epoch 59/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.3198 - val_loss: 0.3057\n",
      "Epoch 60/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3193 - val_loss: 0.3053\n",
      "Epoch 61/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3176 - val_loss: 0.3053\n",
      "Epoch 62/1000\n",
      "1791/1791 [==============================] - 0s 48us/sample - loss: 0.3166 - val_loss: 0.3023\n",
      "Epoch 63/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.3151 - val_loss: 0.3026\n",
      "Epoch 64/1000\n",
      "1791/1791 [==============================] - 0s 48us/sample - loss: 0.3141 - val_loss: 0.3011\n",
      "Epoch 65/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.3127 - val_loss: 0.3039\n",
      "Epoch 66/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3119 - val_loss: 0.2991\n",
      "Epoch 67/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3109 - val_loss: 0.2984\n",
      "Epoch 68/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.3104 - val_loss: 0.2976\n",
      "Epoch 69/1000\n",
      "1791/1791 [==============================] - 0s 45us/sample - loss: 0.3086 - val_loss: 0.2988\n",
      "Epoch 70/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3087 - val_loss: 0.2955\n",
      "Epoch 71/1000\n",
      "1791/1791 [==============================] - 0s 68us/sample - loss: 0.3075 - val_loss: 0.2980\n",
      "Epoch 72/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3096 - val_loss: 0.2939\n",
      "Epoch 73/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3068 - val_loss: 0.2939\n",
      "Epoch 74/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.3047 - val_loss: 0.2951\n",
      "Epoch 75/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.3042 - val_loss: 0.2920\n",
      "Epoch 76/1000\n",
      "1791/1791 [==============================] - 0s 57us/sample - loss: 0.3035 - val_loss: 0.2921\n",
      "Epoch 77/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3021 - val_loss: 0.2926\n",
      "Epoch 78/1000\n",
      "1791/1791 [==============================] - 0s 45us/sample - loss: 0.3021 - val_loss: 0.2897\n",
      "Epoch 79/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3020 - val_loss: 0.2911\n",
      "Epoch 80/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3005 - val_loss: 0.2889\n",
      "Epoch 81/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2994 - val_loss: 0.2904\n",
      "Epoch 82/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3002 - val_loss: 0.2902\n",
      "Epoch 83/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2995 - val_loss: 0.2896\n",
      "Epoch 84/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2994 - val_loss: 0.2888\n",
      "Epoch 85/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2971 - val_loss: 0.2885\n",
      "Epoch 86/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2968 - val_loss: 0.2875\n",
      "Epoch 87/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2962 - val_loss: 0.2857\n",
      "Epoch 88/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2955 - val_loss: 0.2863\n",
      "Epoch 89/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2955 - val_loss: 0.2839\n",
      "Epoch 90/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2947 - val_loss: 0.2867\n",
      "Epoch 91/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2949 - val_loss: 0.2866\n",
      "Epoch 92/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2945 - val_loss: 0.2829\n",
      "Epoch 93/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2926 - val_loss: 0.2891\n",
      "Epoch 94/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2925 - val_loss: 0.2826\n",
      "Epoch 95/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2916 - val_loss: 0.2824\n",
      "Epoch 96/1000\n",
      "1791/1791 [==============================] - 0s 46us/sample - loss: 0.2911 - val_loss: 0.2847\n",
      "Epoch 97/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2907 - val_loss: 0.2812\n",
      "Epoch 98/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2907 - val_loss: 0.2808\n",
      "Epoch 99/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2900 - val_loss: 0.2811\n",
      "Epoch 100/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2891 - val_loss: 0.2812\n",
      "Epoch 101/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2884 - val_loss: 0.2810\n",
      "Epoch 102/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2880 - val_loss: 0.2812\n",
      "Epoch 103/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2885 - val_loss: 0.2805\n",
      "Epoch 104/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2876 - val_loss: 0.2809\n",
      "Epoch 105/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2877 - val_loss: 0.2763\n",
      "Epoch 106/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2860 - val_loss: 0.2802\n",
      "Epoch 107/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2866 - val_loss: 0.2762\n",
      "Epoch 108/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2855 - val_loss: 0.2763\n",
      "Epoch 109/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2845 - val_loss: 0.2765\n",
      "Epoch 110/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2839 - val_loss: 0.2781\n",
      "Epoch 111/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2841 - val_loss: 0.2783\n",
      "Epoch 112/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2834 - val_loss: 0.2754\n",
      "Epoch 113/1000\n",
      "1791/1791 [==============================] - 0s 48us/sample - loss: 0.2823 - val_loss: 0.2753\n",
      "Epoch 114/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2828 - val_loss: 0.2736\n",
      "Epoch 115/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2836 - val_loss: 0.2763\n",
      "Epoch 116/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2824 - val_loss: 0.2751\n",
      "Epoch 117/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2805 - val_loss: 0.2722\n",
      "Epoch 118/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2798 - val_loss: 0.2738\n",
      "Epoch 119/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2803 - val_loss: 0.2727\n",
      "Epoch 120/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2800 - val_loss: 0.2720\n",
      "Epoch 121/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2796 - val_loss: 0.2707\n",
      "Epoch 122/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2793 - val_loss: 0.2720\n",
      "Epoch 123/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2777 - val_loss: 0.2706\n",
      "Epoch 124/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2768 - val_loss: 0.2707\n",
      "Epoch 125/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2772 - val_loss: 0.2730\n",
      "Epoch 126/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2773 - val_loss: 0.2691\n",
      "Epoch 127/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2756 - val_loss: 0.2702\n",
      "Epoch 128/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2754 - val_loss: 0.2682\n",
      "Epoch 129/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2745 - val_loss: 0.2703\n",
      "Epoch 130/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2756 - val_loss: 0.2680\n",
      "Epoch 131/1000\n",
      "1791/1791 [==============================] - 0s 51us/sample - loss: 0.2739 - val_loss: 0.2692\n",
      "Epoch 132/1000\n",
      "1791/1791 [==============================] - 0s 45us/sample - loss: 0.2741 - val_loss: 0.2693\n",
      "Epoch 133/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2728 - val_loss: 0.2664\n",
      "Epoch 134/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2733 - val_loss: 0.2669\n",
      "Epoch 135/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2730 - val_loss: 0.2687\n",
      "Epoch 136/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2725 - val_loss: 0.2676\n",
      "Epoch 137/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2716 - val_loss: 0.2659\n",
      "Epoch 138/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2715 - val_loss: 0.2655\n",
      "Epoch 139/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2710 - val_loss: 0.2655\n",
      "Epoch 140/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2701 - val_loss: 0.2653\n",
      "Epoch 141/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2704 - val_loss: 0.2651\n",
      "Epoch 142/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2694 - val_loss: 0.2634\n",
      "Epoch 143/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2693 - val_loss: 0.2648\n",
      "Epoch 144/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2684 - val_loss: 0.2647\n",
      "Epoch 145/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2685 - val_loss: 0.2618\n",
      "Epoch 146/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2684 - val_loss: 0.2624\n",
      "Epoch 147/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2678 - val_loss: 0.2642\n",
      "Epoch 148/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2669 - val_loss: 0.2622\n",
      "Epoch 149/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2669 - val_loss: 0.2629\n",
      "Epoch 150/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2666 - val_loss: 0.2616\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2670 - val_loss: 0.2639\n",
      "Epoch 152/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2655 - val_loss: 0.2610\n",
      "Epoch 153/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2654 - val_loss: 0.2605\n",
      "Epoch 154/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2647 - val_loss: 0.2606\n",
      "Epoch 155/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2644 - val_loss: 0.2614\n",
      "Epoch 156/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2649 - val_loss: 0.2581\n",
      "Epoch 157/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2642 - val_loss: 0.2633\n",
      "Epoch 158/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2636 - val_loss: 0.2571\n",
      "Epoch 159/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2639 - val_loss: 0.2610\n",
      "Epoch 160/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2631 - val_loss: 0.2575\n",
      "Epoch 161/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2640 - val_loss: 0.2610\n",
      "Epoch 162/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2630 - val_loss: 0.2579\n",
      "Epoch 163/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2614 - val_loss: 0.2571\n",
      "Epoch 164/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2612 - val_loss: 0.2592\n",
      "Epoch 165/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2610 - val_loss: 0.2562\n",
      "Epoch 166/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2614 - val_loss: 0.2606\n",
      "Epoch 167/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2607 - val_loss: 0.2560\n",
      "Epoch 168/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2607 - val_loss: 0.2610\n",
      "Epoch 169/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2616 - val_loss: 0.2539\n",
      "Epoch 170/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2616 - val_loss: 0.2619\n",
      "Epoch 171/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2592 - val_loss: 0.2536\n",
      "Epoch 172/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2587 - val_loss: 0.2578\n",
      "Epoch 173/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2596 - val_loss: 0.2536\n",
      "Epoch 174/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2586 - val_loss: 0.2560\n",
      "Epoch 175/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2574 - val_loss: 0.2524\n",
      "Epoch 176/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2574 - val_loss: 0.2576\n",
      "Epoch 177/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2579 - val_loss: 0.2530\n",
      "Epoch 178/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2564 - val_loss: 0.2540\n",
      "Epoch 179/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.286 - 0s 23us/sample - loss: 0.2574 - val_loss: 0.2566\n",
      "Epoch 180/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2569 - val_loss: 0.2537\n",
      "Epoch 181/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2560 - val_loss: 0.2531\n",
      "Epoch 182/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2558 - val_loss: 0.2524\n",
      "Epoch 183/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2553 - val_loss: 0.2519\n",
      "Epoch 184/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2561 - val_loss: 0.2570\n",
      "Epoch 185/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2550 - val_loss: 0.2500\n",
      "Epoch 186/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2545 - val_loss: 0.2537\n",
      "Epoch 187/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2550 - val_loss: 0.2513\n",
      "Epoch 188/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2537 - val_loss: 0.2515\n",
      "Epoch 189/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2534 - val_loss: 0.2534\n",
      "Epoch 190/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2547 - val_loss: 0.2505\n",
      "Epoch 191/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2532 - val_loss: 0.2526\n",
      "Epoch 192/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2531 - val_loss: 0.2499\n",
      "Epoch 193/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2522 - val_loss: 0.2552\n",
      "Epoch 194/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2528 - val_loss: 0.2484\n",
      "Epoch 195/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2525 - val_loss: 0.2518\n",
      "Epoch 196/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2546 - val_loss: 0.2474\n",
      "Epoch 197/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2532 - val_loss: 0.2495\n",
      "Epoch 198/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2518 - val_loss: 0.2470\n",
      "Epoch 199/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2519 - val_loss: 0.2520\n",
      "Epoch 200/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2511 - val_loss: 0.2480\n",
      "Epoch 201/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2505 - val_loss: 0.2480\n",
      "Epoch 202/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2505 - val_loss: 0.2480\n",
      "Epoch 203/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2500 - val_loss: 0.2480\n",
      "Epoch 204/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2499 - val_loss: 0.2494\n",
      "Epoch 205/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2497 - val_loss: 0.2486\n",
      "Epoch 206/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2496 - val_loss: 0.2490\n",
      "Epoch 207/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2495 - val_loss: 0.2496\n",
      "Epoch 208/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2486 - val_loss: 0.2459\n",
      "Epoch 209/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2502 - val_loss: 0.2467\n",
      "Epoch 210/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2492 - val_loss: 0.2473\n",
      "Epoch 211/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2495 - val_loss: 0.2482\n",
      "Epoch 212/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2488 - val_loss: 0.2490\n",
      "Epoch 213/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2483 - val_loss: 0.2463\n",
      "Epoch 214/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2487 - val_loss: 0.2482\n",
      "Epoch 215/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2481 - val_loss: 0.2467\n",
      "Epoch 216/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2475 - val_loss: 0.2464\n",
      "Epoch 217/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2480 - val_loss: 0.2470\n",
      "Epoch 218/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2477 - val_loss: 0.2476\n",
      "Epoch 219/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2472 - val_loss: 0.2463\n",
      "Epoch 220/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2478 - val_loss: 0.2477\n",
      "Epoch 221/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2466 - val_loss: 0.2474\n",
      "Epoch 222/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2467 - val_loss: 0.2435\n",
      "Epoch 223/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2468 - val_loss: 0.2475\n",
      "Epoch 224/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2473 - val_loss: 0.2427\n",
      "Epoch 225/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2456 - val_loss: 0.2470\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2471 - val_loss: 0.2442\n",
      "Epoch 227/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2458 - val_loss: 0.2455\n",
      "Epoch 228/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2457 - val_loss: 0.2450\n",
      "Epoch 229/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2458 - val_loss: 0.2435\n",
      "Epoch 230/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2456 - val_loss: 0.2461\n",
      "Epoch 231/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2467 - val_loss: 0.2475\n",
      "Epoch 232/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2451 - val_loss: 0.2430\n",
      "Epoch 233/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2453 - val_loss: 0.2481\n",
      "Epoch 234/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2458 - val_loss: 0.2417\n",
      "Epoch 235/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2454 - val_loss: 0.2469\n",
      "Epoch 236/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2438 - val_loss: 0.2430\n",
      "Epoch 237/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2444 - val_loss: 0.2417\n",
      "Epoch 238/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2456 - val_loss: 0.2424\n",
      "Epoch 239/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2451 - val_loss: 0.2448\n",
      "Epoch 240/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2441 - val_loss: 0.2438\n",
      "Epoch 241/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2436 - val_loss: 0.2433\n",
      "Epoch 242/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2435 - val_loss: 0.2429\n",
      "Epoch 243/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2435 - val_loss: 0.2415\n",
      "Epoch 244/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2428 - val_loss: 0.2441\n",
      "Epoch 245/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2429 - val_loss: 0.2427\n",
      "Epoch 246/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2431 - val_loss: 0.2428\n",
      "Epoch 247/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2435 - val_loss: 0.2455\n",
      "Epoch 248/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2427 - val_loss: 0.2424\n",
      "Epoch 249/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2424 - val_loss: 0.2421\n",
      "Epoch 250/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2422 - val_loss: 0.2435\n",
      "Epoch 251/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2419 - val_loss: 0.2421\n",
      "Epoch 252/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2422 - val_loss: 0.2439\n",
      "Epoch 253/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2422 - val_loss: 0.2406\n",
      "Epoch 254/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2427 - val_loss: 0.2465\n",
      "Epoch 255/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2426 - val_loss: 0.2423\n",
      "Epoch 256/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2420 - val_loss: 0.2396\n",
      "Epoch 257/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2420 - val_loss: 0.2416\n",
      "Epoch 258/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2421 - val_loss: 0.2444\n",
      "Epoch 259/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2416 - val_loss: 0.2396\n",
      "Epoch 260/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2412 - val_loss: 0.2425\n",
      "Epoch 261/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2433 - val_loss: 0.2391\n",
      "Epoch 262/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2419 - val_loss: 0.2424\n",
      "Epoch 263/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2414 - val_loss: 0.2415\n",
      "Epoch 264/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2427 - val_loss: 0.2442\n",
      "Epoch 265/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2415 - val_loss: 0.2393\n",
      "Epoch 266/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2402 - val_loss: 0.2404\n",
      "Epoch 267/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2407 - val_loss: 0.2383\n",
      "Epoch 268/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2407 - val_loss: 0.2448\n",
      "Epoch 269/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2398 - val_loss: 0.2387\n",
      "Epoch 270/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2402 - val_loss: 0.2408\n",
      "Epoch 271/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2405 - val_loss: 0.2447\n",
      "Epoch 272/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2398 - val_loss: 0.2383\n",
      "Epoch 273/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2399 - val_loss: 0.2394\n",
      "Epoch 274/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2399 - val_loss: 0.2395\n",
      "Epoch 275/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2400 - val_loss: 0.2383\n",
      "Epoch 276/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2407 - val_loss: 0.2382\n",
      "Epoch 277/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2394 - val_loss: 0.2396\n",
      "Epoch 278/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2390 - val_loss: 0.2383\n",
      "Epoch 279/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2399 - val_loss: 0.2419\n",
      "Epoch 280/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2398 - val_loss: 0.2409\n",
      "Epoch 281/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2403 - val_loss: 0.2410\n",
      "Epoch 282/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2388 - val_loss: 0.2384\n",
      "Epoch 283/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2387 - val_loss: 0.2390\n",
      "Epoch 284/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2389 - val_loss: 0.2411\n",
      "Epoch 285/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2385 - val_loss: 0.2369\n",
      "Epoch 286/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2392 - val_loss: 0.2383\n",
      "Epoch 287/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2383 - val_loss: 0.2398\n",
      "Epoch 288/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2380 - val_loss: 0.2395\n",
      "Epoch 289/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2387 - val_loss: 0.2389\n",
      "Epoch 290/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2384 - val_loss: 0.2387\n",
      "Epoch 291/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2388 - val_loss: 0.2380\n",
      "Epoch 292/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2378 - val_loss: 0.2380\n",
      "Epoch 293/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2379 - val_loss: 0.2383\n",
      "Epoch 294/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2378 - val_loss: 0.2388\n",
      "Epoch 295/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2389 - val_loss: 0.2405\n",
      "Epoch 296/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2392 - val_loss: 0.2366\n",
      "Epoch 297/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2388 - val_loss: 0.2377\n",
      "Epoch 298/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.2381 - val_loss: 0.2362\n",
      "Epoch 299/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2382 - val_loss: 0.2400\n",
      "Epoch 300/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2387 - val_loss: 0.2411\n",
      "Epoch 301/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2381 - val_loss: 0.2367\n",
      "Epoch 302/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.2378 - val_loss: 0.2427\n",
      "Epoch 303/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2373 - val_loss: 0.2381\n",
      "Epoch 304/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2366 - val_loss: 0.2370\n",
      "Epoch 305/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2364 - val_loss: 0.2397\n",
      "Epoch 306/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2367 - val_loss: 0.2370\n",
      "Epoch 307/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2370 - val_loss: 0.2390\n",
      "Epoch 308/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2362 - val_loss: 0.2365\n",
      "Epoch 309/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2371 - val_loss: 0.2369\n",
      "Epoch 310/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2361 - val_loss: 0.2378\n",
      "Epoch 311/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.288 - 0s 22us/sample - loss: 0.2362 - val_loss: 0.2391\n",
      "Epoch 312/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2358 - val_loss: 0.2375\n",
      "Epoch 313/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2358 - val_loss: 0.2380\n",
      "Epoch 314/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2364 - val_loss: 0.2393\n",
      "Epoch 315/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2356 - val_loss: 0.2389\n",
      "Epoch 316/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2354 - val_loss: 0.2372\n",
      "Epoch 317/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2357 - val_loss: 0.2357\n",
      "Epoch 318/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2357 - val_loss: 0.2389\n",
      "Epoch 319/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2359 - val_loss: 0.2364\n",
      "Epoch 320/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2363 - val_loss: 0.2360\n",
      "Epoch 321/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2363 - val_loss: 0.2365\n",
      "Epoch 322/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2363 - val_loss: 0.2350\n",
      "Epoch 323/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2362 - val_loss: 0.2399\n",
      "Epoch 324/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2351 - val_loss: 0.2369\n",
      "Epoch 325/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2348 - val_loss: 0.2366\n",
      "Epoch 326/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2373 - val_loss: 0.2339\n",
      "Epoch 327/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2359 - val_loss: 0.2389\n",
      "Epoch 328/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2355 - val_loss: 0.2353\n",
      "Epoch 329/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2375 - val_loss: 0.2374\n",
      "Epoch 330/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2348 - val_loss: 0.2352\n",
      "Epoch 331/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2344 - val_loss: 0.2372\n",
      "Epoch 332/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2338 - val_loss: 0.2369\n",
      "Epoch 333/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2343 - val_loss: 0.2364\n",
      "Epoch 334/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2337 - val_loss: 0.2364\n",
      "Epoch 335/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2339 - val_loss: 0.2381\n",
      "Epoch 336/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2341 - val_loss: 0.2354\n",
      "Epoch 337/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2338 - val_loss: 0.2416\n",
      "Epoch 338/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2352 - val_loss: 0.2334\n",
      "Epoch 339/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2350 - val_loss: 0.2415\n",
      "Epoch 340/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2343 - val_loss: 0.2351\n",
      "Epoch 341/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2334 - val_loss: 0.2370\n",
      "Epoch 342/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2332 - val_loss: 0.2379\n",
      "Epoch 343/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2344 - val_loss: 0.2388\n",
      "Epoch 344/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2330 - val_loss: 0.2358\n",
      "Epoch 345/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2335 - val_loss: 0.2357\n",
      "Epoch 346/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2335 - val_loss: 0.2368\n",
      "Epoch 347/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2332 - val_loss: 0.2365\n",
      "Epoch 348/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2330 - val_loss: 0.2381\n",
      "Epoch 349/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2328 - val_loss: 0.2385\n",
      "Epoch 350/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2333 - val_loss: 0.2350\n",
      "Epoch 351/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2329 - val_loss: 0.2384\n",
      "Epoch 352/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2325 - val_loss: 0.2349\n",
      "Epoch 353/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2325 - val_loss: 0.2356\n",
      "Epoch 354/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2331 - val_loss: 0.2410\n",
      "Epoch 355/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2322 - val_loss: 0.2345\n",
      "Epoch 356/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2324 - val_loss: 0.2361\n",
      "Epoch 357/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2324 - val_loss: 0.2353\n",
      "Epoch 358/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2323 - val_loss: 0.2351\n",
      "Epoch 359/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2328 - val_loss: 0.2396\n",
      "Epoch 360/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2326 - val_loss: 0.2356\n",
      "Epoch 361/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2336 - val_loss: 0.2344\n",
      "Epoch 362/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2325 - val_loss: 0.2382\n",
      "Epoch 363/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2323 - val_loss: 0.2385\n",
      "Epoch 364/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2337 - val_loss: 0.2329\n",
      "Epoch 365/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2336 - val_loss: 0.2415\n",
      "Epoch 366/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2330 - val_loss: 0.2326\n",
      "Epoch 367/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2325 - val_loss: 0.2365\n",
      "Epoch 368/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2314 - val_loss: 0.2341\n",
      "Epoch 369/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2314 - val_loss: 0.2368\n",
      "Epoch 370/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2313 - val_loss: 0.2366\n",
      "Epoch 371/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2309 - val_loss: 0.2351\n",
      "Epoch 372/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2313 - val_loss: 0.2366\n",
      "Epoch 373/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2312 - val_loss: 0.2375\n",
      "Epoch 374/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2313 - val_loss: 0.2355\n",
      "Epoch 375/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2324 - val_loss: 0.2336\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2320 - val_loss: 0.2384\n",
      "Epoch 377/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2329 - val_loss: 0.2318\n",
      "Epoch 378/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2331 - val_loss: 0.2443\n",
      "Epoch 379/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2320 - val_loss: 0.2336\n",
      "Epoch 380/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.251 - 0s 22us/sample - loss: 0.2309 - val_loss: 0.2380\n",
      "Epoch 381/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2314 - val_loss: 0.2357\n",
      "Epoch 382/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2306 - val_loss: 0.2374\n",
      "Epoch 383/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2318 - val_loss: 0.2378\n",
      "Epoch 384/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2307 - val_loss: 0.2345\n",
      "Epoch 385/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2312 - val_loss: 0.2385\n",
      "Epoch 386/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2304 - val_loss: 0.2338\n",
      "Epoch 387/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2316 - val_loss: 0.2415\n",
      "Epoch 388/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2308 - val_loss: 0.2338\n",
      "Epoch 389/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2313 - val_loss: 0.2387\n",
      "Epoch 390/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2311 - val_loss: 0.2327\n",
      "Epoch 391/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2299 - val_loss: 0.2373\n",
      "Epoch 392/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2303 - val_loss: 0.2354\n",
      "Epoch 393/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2299 - val_loss: 0.2326\n",
      "Epoch 394/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2308 - val_loss: 0.2358\n",
      "Epoch 395/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2302 - val_loss: 0.2382\n",
      "Epoch 396/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2300 - val_loss: 0.2335\n",
      "Epoch 397/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2298 - val_loss: 0.2344\n",
      "Epoch 398/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2300 - val_loss: 0.2331\n",
      "Epoch 399/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2306 - val_loss: 0.2349\n",
      "Epoch 400/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2305 - val_loss: 0.2356\n",
      "Epoch 401/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2292 - val_loss: 0.2326\n",
      "Epoch 402/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2295 - val_loss: 0.2362\n",
      "Epoch 403/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2307 - val_loss: 0.2333\n",
      "Epoch 404/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2306 - val_loss: 0.2369\n",
      "Epoch 405/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2303 - val_loss: 0.2382\n",
      "Epoch 406/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2302 - val_loss: 0.2318\n",
      "Epoch 407/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2306 - val_loss: 0.2369\n",
      "Epoch 408/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2291 - val_loss: 0.2341\n",
      "Epoch 409/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2301 - val_loss: 0.2375\n",
      "Epoch 410/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2307 - val_loss: 0.2313\n",
      "Epoch 411/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2312 - val_loss: 0.2355\n",
      "Epoch 412/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.219 - 0s 23us/sample - loss: 0.2322 - val_loss: 0.2352\n",
      "Epoch 413/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2295 - val_loss: 0.2349\n",
      "Epoch 414/1000\n",
      "1791/1791 [==============================] - 0s 49us/sample - loss: 0.2287 - val_loss: 0.2333\n",
      "Epoch 415/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2290 - val_loss: 0.2326\n",
      "Epoch 416/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2306 - val_loss: 0.2424\n",
      "Epoch 417/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2304 - val_loss: 0.2314\n",
      "Epoch 418/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2288 - val_loss: 0.2375\n",
      "Epoch 419/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2305 - val_loss: 0.2377\n",
      "Epoch 420/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2286 - val_loss: 0.2366\n",
      "Epoch 421/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2284 - val_loss: 0.2329\n",
      "Epoch 422/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2289 - val_loss: 0.2404\n",
      "Epoch 423/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2297 - val_loss: 0.2314\n",
      "Epoch 424/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2285 - val_loss: 0.2342\n",
      "Epoch 425/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2279 - val_loss: 0.2353\n",
      "Epoch 426/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2278 - val_loss: 0.2333\n",
      "Epoch 427/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2285 - val_loss: 0.2337\n",
      "Epoch 428/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2283 - val_loss: 0.2336\n",
      "Epoch 429/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2302 - val_loss: 0.2371\n",
      "Epoch 430/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2309 - val_loss: 0.2323\n",
      "Epoch 431/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2283 - val_loss: 0.2356\n",
      "Epoch 432/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2293 - val_loss: 0.2307\n",
      "Epoch 433/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2277 - val_loss: 0.2414\n",
      "Epoch 434/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2287 - val_loss: 0.2323\n",
      "Epoch 435/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2274 - val_loss: 0.2375\n",
      "Epoch 436/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2284 - val_loss: 0.2307\n",
      "Epoch 437/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2280 - val_loss: 0.2331\n",
      "Epoch 438/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2284 - val_loss: 0.2328\n",
      "Epoch 439/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2291 - val_loss: 0.2375\n",
      "Epoch 440/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2277 - val_loss: 0.2322\n",
      "Epoch 441/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2280 - val_loss: 0.2340\n",
      "Epoch 442/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2275 - val_loss: 0.2338\n",
      "Epoch 443/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2281 - val_loss: 0.2318\n",
      "Epoch 444/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2276 - val_loss: 0.2322\n",
      "Epoch 445/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2273 - val_loss: 0.2336\n",
      "Epoch 446/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2270 - val_loss: 0.2341\n",
      "Epoch 447/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2268 - val_loss: 0.2340\n",
      "Epoch 448/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2276 - val_loss: 0.2326\n",
      "Epoch 449/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2288 - val_loss: 0.2382\n",
      "Epoch 450/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2273 - val_loss: 0.2315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2274 - val_loss: 0.2383\n",
      "Epoch 452/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2274 - val_loss: 0.2313\n",
      "Epoch 453/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2272 - val_loss: 0.2333\n",
      "Epoch 454/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2272 - val_loss: 0.2322\n",
      "Epoch 455/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2267 - val_loss: 0.2339\n",
      "Epoch 456/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2267 - val_loss: 0.2332\n",
      "Epoch 457/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2274 - val_loss: 0.2400\n",
      "Epoch 458/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2274 - val_loss: 0.2329\n",
      "Epoch 459/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2274 - val_loss: 0.2366\n",
      "Epoch 460/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2269 - val_loss: 0.2325\n",
      "Epoch 461/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2265 - val_loss: 0.2317\n",
      "Epoch 462/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2264 - val_loss: 0.2340\n",
      "Epoch 463/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2264 - val_loss: 0.2337\n",
      "Epoch 464/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2263 - val_loss: 0.2342\n",
      "Epoch 465/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2262 - val_loss: 0.2325\n",
      "Epoch 466/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2254 - val_loss: 0.2344\n",
      "Epoch 467/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2274 - val_loss: 0.2350\n",
      "Epoch 468/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2261 - val_loss: 0.2341\n",
      "Epoch 469/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2256 - val_loss: 0.2341\n",
      "Epoch 470/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2264 - val_loss: 0.2361\n",
      "Epoch 471/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2256 - val_loss: 0.2314\n",
      "Epoch 472/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2262 - val_loss: 0.2349\n",
      "Epoch 473/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2255 - val_loss: 0.2298\n",
      "Epoch 474/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2254 - val_loss: 0.2357\n",
      "Epoch 475/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2263 - val_loss: 0.2287\n",
      "Epoch 476/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2250 - val_loss: 0.2357\n",
      "Epoch 477/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2255 - val_loss: 0.2328\n",
      "Epoch 478/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2258 - val_loss: 0.2296\n",
      "Epoch 479/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2250 - val_loss: 0.2330\n",
      "Epoch 480/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2246 - val_loss: 0.2317\n",
      "Epoch 481/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2247 - val_loss: 0.2311\n",
      "Epoch 482/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2251 - val_loss: 0.2371\n",
      "Epoch 483/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2252 - val_loss: 0.2309\n",
      "Epoch 484/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2248 - val_loss: 0.2318\n",
      "Epoch 485/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2256 - val_loss: 0.2366\n",
      "Epoch 486/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2247 - val_loss: 0.2291\n",
      "Epoch 487/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2249 - val_loss: 0.2366\n",
      "Epoch 488/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2259 - val_loss: 0.2333\n",
      "Epoch 489/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2248 - val_loss: 0.2312\n",
      "Epoch 490/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2237 - val_loss: 0.2319\n",
      "Epoch 491/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2242 - val_loss: 0.2306\n",
      "Epoch 492/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2247 - val_loss: 0.2287\n",
      "Epoch 493/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2251 - val_loss: 0.2329\n",
      "Epoch 494/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2247 - val_loss: 0.2320\n",
      "Epoch 495/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2244 - val_loss: 0.2291\n",
      "Epoch 496/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2245 - val_loss: 0.2345\n",
      "Epoch 497/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2256 - val_loss: 0.2333\n",
      "Epoch 498/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2240 - val_loss: 0.2298\n",
      "Epoch 499/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2250 - val_loss: 0.2367\n",
      "Epoch 500/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2273 - val_loss: 0.2266\n",
      "Epoch 501/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2239 - val_loss: 0.2334\n",
      "Epoch 502/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2245 - val_loss: 0.2320\n",
      "Epoch 503/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2237 - val_loss: 0.2286\n",
      "Epoch 504/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2236 - val_loss: 0.2340\n",
      "Epoch 505/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2241 - val_loss: 0.2283\n",
      "Epoch 506/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2237 - val_loss: 0.2343\n",
      "Epoch 507/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2229 - val_loss: 0.2274\n",
      "Epoch 508/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2226 - val_loss: 0.2326\n",
      "Epoch 509/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2229 - val_loss: 0.2319\n",
      "Epoch 510/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2231 - val_loss: 0.2313\n",
      "Epoch 511/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2227 - val_loss: 0.2293\n",
      "Epoch 512/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2235 - val_loss: 0.2307\n",
      "Epoch 513/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2229 - val_loss: 0.2310\n",
      "Epoch 514/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2225 - val_loss: 0.2276\n",
      "Epoch 515/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2228 - val_loss: 0.2310\n",
      "Epoch 516/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2244 - val_loss: 0.2271\n",
      "Epoch 517/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2244 - val_loss: 0.2367\n",
      "Epoch 518/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2227 - val_loss: 0.2273\n",
      "Epoch 519/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2240 - val_loss: 0.2361\n",
      "Epoch 520/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2232 - val_loss: 0.2287\n",
      "Epoch 521/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2226 - val_loss: 0.2294\n",
      "Epoch 522/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2221 - val_loss: 0.2318\n",
      "Epoch 523/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2232 - val_loss: 0.2327\n",
      "Epoch 524/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2228 - val_loss: 0.2283\n",
      "Epoch 525/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2229 - val_loss: 0.2292\n",
      "Epoch 526/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2230 - val_loss: 0.2328\n",
      "Epoch 527/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2226 - val_loss: 0.2309\n",
      "Epoch 528/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2221 - val_loss: 0.2287\n",
      "Epoch 529/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2219 - val_loss: 0.2288\n",
      "Epoch 530/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2214 - val_loss: 0.2285\n",
      "Epoch 531/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2227 - val_loss: 0.2348\n",
      "Epoch 532/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2221 - val_loss: 0.2269\n",
      "Epoch 533/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2217 - val_loss: 0.2349\n",
      "Epoch 534/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2231 - val_loss: 0.2264\n",
      "Epoch 535/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2218 - val_loss: 0.2353\n",
      "Epoch 536/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2225 - val_loss: 0.2265\n",
      "Epoch 537/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2219 - val_loss: 0.2295\n",
      "Epoch 538/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2215 - val_loss: 0.2290\n",
      "Epoch 539/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2215 - val_loss: 0.2325\n",
      "Epoch 540/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2212 - val_loss: 0.2307\n",
      "Epoch 541/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2211 - val_loss: 0.2299\n",
      "Epoch 542/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2207 - val_loss: 0.2291\n",
      "Epoch 543/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2212 - val_loss: 0.2344\n",
      "Epoch 544/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2213 - val_loss: 0.2300\n",
      "Epoch 545/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2208 - val_loss: 0.2280\n",
      "Epoch 546/1000\n",
      "1791/1791 [==============================] - 0s 47us/sample - loss: 0.2205 - val_loss: 0.2327\n",
      "Epoch 547/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.2211 - val_loss: 0.2294\n",
      "Epoch 548/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2214 - val_loss: 0.2295\n",
      "Epoch 549/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2211 - val_loss: 0.2289\n",
      "Epoch 550/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2205 - val_loss: 0.2346\n",
      "Epoch 551/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2207 - val_loss: 0.2272\n",
      "Epoch 552/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2211 - val_loss: 0.2285\n",
      "Epoch 553/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2212 - val_loss: 0.2333\n",
      "Epoch 554/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2208 - val_loss: 0.2282\n",
      "Epoch 555/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2210 - val_loss: 0.2317\n",
      "Epoch 556/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2204 - val_loss: 0.2299\n",
      "Epoch 557/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2202 - val_loss: 0.2291\n",
      "Epoch 558/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2208 - val_loss: 0.2301\n",
      "Epoch 559/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2203 - val_loss: 0.2278\n",
      "Epoch 560/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2210 - val_loss: 0.2305\n",
      "Epoch 561/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2207 - val_loss: 0.2334\n",
      "Epoch 562/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2220 - val_loss: 0.2260\n",
      "Epoch 563/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2228 - val_loss: 0.2358\n",
      "Epoch 564/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2209 - val_loss: 0.2287\n",
      "Epoch 565/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2212 - val_loss: 0.2286\n",
      "Epoch 566/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2210 - val_loss: 0.2281\n",
      "Epoch 567/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2199 - val_loss: 0.2300\n",
      "Epoch 568/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2199 - val_loss: 0.2290\n",
      "Epoch 569/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2198 - val_loss: 0.2320\n",
      "Epoch 570/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2200 - val_loss: 0.2295\n",
      "Epoch 571/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2196 - val_loss: 0.2277\n",
      "Epoch 572/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2198 - val_loss: 0.2277\n",
      "Epoch 573/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2189 - val_loss: 0.2339\n",
      "Epoch 574/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2198 - val_loss: 0.2264\n",
      "Epoch 575/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2201 - val_loss: 0.2298\n",
      "Epoch 576/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2191 - val_loss: 0.2302\n",
      "Epoch 577/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2205 - val_loss: 0.2268\n",
      "Epoch 578/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2194 - val_loss: 0.2311\n",
      "Epoch 579/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2201 - val_loss: 0.2268\n",
      "Epoch 580/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2194 - val_loss: 0.2346\n",
      "Epoch 581/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2193 - val_loss: 0.2266\n",
      "Epoch 582/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2201 - val_loss: 0.2388\n",
      "Epoch 583/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2213 - val_loss: 0.2274\n",
      "Epoch 584/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2195 - val_loss: 0.2302\n",
      "Epoch 585/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2194 - val_loss: 0.2322\n",
      "Epoch 586/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2188 - val_loss: 0.2280\n",
      "Epoch 587/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2191 - val_loss: 0.2279\n",
      "Epoch 588/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2194 - val_loss: 0.2321\n",
      "Epoch 589/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2186 - val_loss: 0.2288\n",
      "Epoch 590/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2189 - val_loss: 0.2301\n",
      "Epoch 591/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2199 - val_loss: 0.2254\n",
      "Epoch 592/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2195 - val_loss: 0.2292\n",
      "Epoch 593/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2183 - val_loss: 0.2309\n",
      "Epoch 594/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2187 - val_loss: 0.2284\n",
      "Epoch 595/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2185 - val_loss: 0.2309\n",
      "Epoch 596/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2187 - val_loss: 0.2313\n",
      "Epoch 597/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2184 - val_loss: 0.2250\n",
      "Epoch 598/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2193 - val_loss: 0.2311\n",
      "Epoch 599/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2198 - val_loss: 0.2289\n",
      "Epoch 600/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2195 - val_loss: 0.2277\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2189 - val_loss: 0.2315\n",
      "Epoch 602/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2180 - val_loss: 0.2290\n",
      "Epoch 603/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2193 - val_loss: 0.2271\n",
      "Epoch 604/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2180 - val_loss: 0.2277\n",
      "Epoch 605/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2178 - val_loss: 0.2318\n",
      "Epoch 606/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2184 - val_loss: 0.2288\n",
      "Epoch 607/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2196 - val_loss: 0.2283\n",
      "Epoch 608/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2181 - val_loss: 0.2280\n",
      "Epoch 609/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2177 - val_loss: 0.2279\n",
      "Epoch 610/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2189 - val_loss: 0.2260\n",
      "Epoch 611/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2186 - val_loss: 0.2340\n",
      "Epoch 612/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2184 - val_loss: 0.2269\n",
      "Epoch 613/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2185 - val_loss: 0.2342\n",
      "Epoch 614/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2187 - val_loss: 0.2267\n",
      "Epoch 615/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2173 - val_loss: 0.2298\n",
      "Epoch 616/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2172 - val_loss: 0.2281\n",
      "Epoch 617/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2190 - val_loss: 0.2347\n",
      "Epoch 618/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2179 - val_loss: 0.2260\n",
      "Epoch 619/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2179 - val_loss: 0.2296\n",
      "Epoch 620/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2174 - val_loss: 0.2253\n",
      "Epoch 621/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2188 - val_loss: 0.2274\n",
      "Epoch 622/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2192 - val_loss: 0.2332\n",
      "Epoch 623/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.2181 - val_loss: 0.2265\n",
      "Epoch 624/1000\n",
      "1791/1791 [==============================] - 0s 47us/sample - loss: 0.2190 - val_loss: 0.2356\n",
      "Epoch 625/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2186 - val_loss: 0.2250\n",
      "Epoch 626/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2191 - val_loss: 0.2297\n",
      "Epoch 627/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2173 - val_loss: 0.2296\n",
      "Epoch 628/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2169 - val_loss: 0.2276\n",
      "Epoch 629/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2164 - val_loss: 0.2283\n",
      "Epoch 630/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2163 - val_loss: 0.2275\n",
      "Epoch 631/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2171 - val_loss: 0.2308\n",
      "Epoch 632/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2166 - val_loss: 0.2266\n",
      "Epoch 633/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2162 - val_loss: 0.2294\n",
      "Epoch 634/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2164 - val_loss: 0.2257\n",
      "Epoch 635/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2169 - val_loss: 0.2312\n",
      "Epoch 636/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2173 - val_loss: 0.2275\n",
      "Epoch 637/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2156 - val_loss: 0.2276\n",
      "Epoch 638/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2157 - val_loss: 0.2260\n",
      "Epoch 639/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2160 - val_loss: 0.2297\n",
      "Epoch 640/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2156 - val_loss: 0.2269\n",
      "Epoch 641/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2153 - val_loss: 0.2326\n",
      "Epoch 642/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2159 - val_loss: 0.2294\n",
      "Epoch 643/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2152 - val_loss: 0.2281\n",
      "Epoch 644/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2150 - val_loss: 0.2282\n",
      "Epoch 645/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2162 - val_loss: 0.2248\n",
      "Epoch 646/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2149 - val_loss: 0.2290\n",
      "Epoch 647/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2158 - val_loss: 0.2259\n",
      "Epoch 648/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2158 - val_loss: 0.2283\n",
      "Epoch 649/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2151 - val_loss: 0.2293\n",
      "Epoch 650/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2152 - val_loss: 0.2277\n",
      "Epoch 651/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2147 - val_loss: 0.2272\n",
      "Epoch 652/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2150 - val_loss: 0.2263\n",
      "Epoch 653/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2150 - val_loss: 0.2293\n",
      "Epoch 654/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2152 - val_loss: 0.2252\n",
      "Epoch 655/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2147 - val_loss: 0.2266\n",
      "Epoch 656/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2147 - val_loss: 0.2256\n",
      "Epoch 657/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2151 - val_loss: 0.2293\n",
      "Epoch 658/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2147 - val_loss: 0.2257\n",
      "Epoch 659/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2153 - val_loss: 0.2243\n",
      "Epoch 660/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2142 - val_loss: 0.2294\n",
      "Epoch 661/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2145 - val_loss: 0.2307\n",
      "Epoch 662/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2145 - val_loss: 0.2260\n",
      "Epoch 663/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2143 - val_loss: 0.2257\n",
      "Epoch 664/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2147 - val_loss: 0.2245\n",
      "Epoch 665/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2138 - val_loss: 0.2285\n",
      "Epoch 666/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2142 - val_loss: 0.2241\n",
      "Epoch 667/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2160 - val_loss: 0.2232\n",
      "Epoch 668/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2140 - val_loss: 0.2321\n",
      "Epoch 669/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2137 - val_loss: 0.2276\n",
      "Epoch 670/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2144 - val_loss: 0.2247\n",
      "Epoch 671/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2152 - val_loss: 0.2261\n",
      "Epoch 672/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2137 - val_loss: 0.2250\n",
      "Epoch 673/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2135 - val_loss: 0.2299\n",
      "Epoch 674/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2138 - val_loss: 0.2262\n",
      "Epoch 675/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2137 - val_loss: 0.2265\n",
      "Epoch 676/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2132 - val_loss: 0.2238\n",
      "Epoch 677/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2136 - val_loss: 0.2279\n",
      "Epoch 678/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2137 - val_loss: 0.2228\n",
      "Epoch 679/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2135 - val_loss: 0.2282\n",
      "Epoch 680/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2141 - val_loss: 0.2309\n",
      "Epoch 681/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2127 - val_loss: 0.2237\n",
      "Epoch 682/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2130 - val_loss: 0.2276\n",
      "Epoch 683/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2141 - val_loss: 0.2221\n",
      "Epoch 684/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2135 - val_loss: 0.2302\n",
      "Epoch 685/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2141 - val_loss: 0.2241\n",
      "Epoch 686/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2119 - val_loss: 0.2262\n",
      "Epoch 687/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2128 - val_loss: 0.2270\n",
      "Epoch 688/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2151 - val_loss: 0.2222\n",
      "Epoch 689/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2124 - val_loss: 0.2291\n",
      "Epoch 690/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2127 - val_loss: 0.2258\n",
      "Epoch 691/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2119 - val_loss: 0.2256\n",
      "Epoch 692/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2120 - val_loss: 0.2248\n",
      "Epoch 693/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2122 - val_loss: 0.2283\n",
      "Epoch 694/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2121 - val_loss: 0.2239\n",
      "Epoch 695/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2131 - val_loss: 0.2233\n",
      "Epoch 696/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2144 - val_loss: 0.2293\n",
      "Epoch 697/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2124 - val_loss: 0.2233\n",
      "Epoch 698/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2125 - val_loss: 0.2272\n",
      "Epoch 699/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2129 - val_loss: 0.2222\n",
      "Epoch 700/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2125 - val_loss: 0.2243\n",
      "Epoch 701/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2119 - val_loss: 0.2254\n",
      "Epoch 702/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2111 - val_loss: 0.2217\n",
      "Epoch 703/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2111 - val_loss: 0.2242\n",
      "Epoch 704/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2111 - val_loss: 0.2250\n",
      "Epoch 705/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2108 - val_loss: 0.2241\n",
      "Epoch 706/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2108 - val_loss: 0.2258\n",
      "Epoch 707/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2104 - val_loss: 0.2235\n",
      "Epoch 708/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2109 - val_loss: 0.2235\n",
      "Epoch 709/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2107 - val_loss: 0.2235\n",
      "Epoch 710/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2107 - val_loss: 0.2228\n",
      "Epoch 711/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2106 - val_loss: 0.2219\n",
      "Epoch 712/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2109 - val_loss: 0.2254\n",
      "Epoch 713/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2106 - val_loss: 0.2201\n",
      "Epoch 714/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2097 - val_loss: 0.2259\n",
      "Epoch 715/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2116 - val_loss: 0.2261\n",
      "Epoch 716/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2108 - val_loss: 0.2198\n",
      "Epoch 717/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2102 - val_loss: 0.2255\n",
      "Epoch 718/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2108 - val_loss: 0.2240\n",
      "Epoch 719/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2112 - val_loss: 0.2254\n",
      "Epoch 720/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2099 - val_loss: 0.2226\n",
      "Epoch 721/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2096 - val_loss: 0.2204\n",
      "Epoch 722/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2109 - val_loss: 0.2188\n",
      "Epoch 723/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2093 - val_loss: 0.2221\n",
      "Epoch 724/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2095 - val_loss: 0.2227\n",
      "Epoch 725/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2090 - val_loss: 0.2178\n",
      "Epoch 726/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2113 - val_loss: 0.2333\n",
      "Epoch 727/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2122 - val_loss: 0.2174\n",
      "Epoch 728/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2094 - val_loss: 0.2233\n",
      "Epoch 729/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2088 - val_loss: 0.2190\n",
      "Epoch 730/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2089 - val_loss: 0.2201\n",
      "Epoch 731/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2114 - val_loss: 0.2296\n",
      "Epoch 732/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2109 - val_loss: 0.2151\n",
      "Epoch 733/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2096 - val_loss: 0.2202\n",
      "Epoch 734/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2088 - val_loss: 0.2149\n",
      "Epoch 735/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2085 - val_loss: 0.2262\n",
      "Epoch 736/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2120 - val_loss: 0.2162\n",
      "Epoch 737/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2072 - val_loss: 0.2218\n",
      "Epoch 738/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2087 - val_loss: 0.2166\n",
      "Epoch 739/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2084 - val_loss: 0.2177\n",
      "Epoch 740/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2100 - val_loss: 0.2259\n",
      "Epoch 741/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2125 - val_loss: 0.2137\n",
      "Epoch 742/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2070 - val_loss: 0.2250\n",
      "Epoch 743/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2078 - val_loss: 0.2149\n",
      "Epoch 744/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2093 - val_loss: 0.2155\n",
      "Epoch 745/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2084 - val_loss: 0.2178\n",
      "Epoch 746/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2070 - val_loss: 0.2175\n",
      "Epoch 747/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2071 - val_loss: 0.2162\n",
      "Epoch 748/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2068 - val_loss: 0.2215\n",
      "Epoch 749/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2069 - val_loss: 0.2175\n",
      "Epoch 750/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2066 - val_loss: 0.2139\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2068 - val_loss: 0.2170\n",
      "Epoch 752/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2063 - val_loss: 0.2140\n",
      "Epoch 753/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2067 - val_loss: 0.2191\n",
      "Epoch 754/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2055 - val_loss: 0.2131\n",
      "Epoch 755/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2056 - val_loss: 0.2145\n",
      "Epoch 756/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2055 - val_loss: 0.2165\n",
      "Epoch 757/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2063 - val_loss: 0.2126\n",
      "Epoch 758/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2052 - val_loss: 0.2121\n",
      "Epoch 759/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2053 - val_loss: 0.2182\n",
      "Epoch 760/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2047 - val_loss: 0.2114\n",
      "Epoch 761/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2045 - val_loss: 0.2186\n",
      "Epoch 762/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2049 - val_loss: 0.2103\n",
      "Epoch 763/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2039 - val_loss: 0.2142\n",
      "Epoch 764/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2038 - val_loss: 0.2142\n",
      "Epoch 765/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2038 - val_loss: 0.2121\n",
      "Epoch 766/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2033 - val_loss: 0.2112\n",
      "Epoch 767/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2033 - val_loss: 0.2092\n",
      "Epoch 768/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2036 - val_loss: 0.2137\n",
      "Epoch 769/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2052 - val_loss: 0.2060\n",
      "Epoch 770/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2044 - val_loss: 0.2182\n",
      "Epoch 771/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2026 - val_loss: 0.2065\n",
      "Epoch 772/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2032 - val_loss: 0.2086\n",
      "Epoch 773/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2014 - val_loss: 0.2060\n",
      "Epoch 774/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2018 - val_loss: 0.2108\n",
      "Epoch 775/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2014 - val_loss: 0.2037\n",
      "Epoch 776/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2025 - val_loss: 0.2072\n",
      "Epoch 777/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2013 - val_loss: 0.2111\n",
      "Epoch 778/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2009 - val_loss: 0.2045\n",
      "Epoch 779/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1996 - val_loss: 0.2095\n",
      "Epoch 780/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1994 - val_loss: 0.2041\n",
      "Epoch 781/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1993 - val_loss: 0.2090\n",
      "Epoch 782/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2002 - val_loss: 0.2019\n",
      "Epoch 783/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1997 - val_loss: 0.2092\n",
      "Epoch 784/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2019 - val_loss: 0.2033\n",
      "Epoch 785/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1982 - val_loss: 0.2046\n",
      "Epoch 786/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1986 - val_loss: 0.2028\n",
      "Epoch 787/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1991 - val_loss: 0.2075\n",
      "Epoch 788/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1988 - val_loss: 0.2018\n",
      "Epoch 789/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1979 - val_loss: 0.2030\n",
      "Epoch 790/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1981 - val_loss: 0.2022\n",
      "Epoch 791/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1975 - val_loss: 0.2038\n",
      "Epoch 792/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1975 - val_loss: 0.2006\n",
      "Epoch 793/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1979 - val_loss: 0.2028\n",
      "Epoch 794/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1976 - val_loss: 0.2020\n",
      "Epoch 795/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1967 - val_loss: 0.1994\n",
      "Epoch 796/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1972 - val_loss: 0.2033\n",
      "Epoch 797/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1963 - val_loss: 0.1994\n",
      "Epoch 798/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1965 - val_loss: 0.2038\n",
      "Epoch 799/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1956 - val_loss: 0.1987\n",
      "Epoch 800/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1956 - val_loss: 0.2021\n",
      "Epoch 801/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1954 - val_loss: 0.1963\n",
      "Epoch 802/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1959 - val_loss: 0.2052\n",
      "Epoch 803/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1961 - val_loss: 0.1957\n",
      "Epoch 804/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1950 - val_loss: 0.2030\n",
      "Epoch 805/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1951 - val_loss: 0.1976\n",
      "Epoch 806/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1947 - val_loss: 0.1980\n",
      "Epoch 807/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1949 - val_loss: 0.1961\n",
      "Epoch 808/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1941 - val_loss: 0.1974\n",
      "Epoch 809/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1943 - val_loss: 0.1961\n",
      "Epoch 810/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1939 - val_loss: 0.1996\n",
      "Epoch 811/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1941 - val_loss: 0.1953\n",
      "Epoch 812/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1946 - val_loss: 0.1956\n",
      "Epoch 813/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1942 - val_loss: 0.1985\n",
      "Epoch 814/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1932 - val_loss: 0.1958\n",
      "Epoch 815/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1931 - val_loss: 0.1964\n",
      "Epoch 816/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1928 - val_loss: 0.1965\n",
      "Epoch 817/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1926 - val_loss: 0.1945\n",
      "Epoch 818/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1929 - val_loss: 0.1955\n",
      "Epoch 819/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1923 - val_loss: 0.1972\n",
      "Epoch 820/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1925 - val_loss: 0.1927\n",
      "Epoch 821/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1927 - val_loss: 0.1969\n",
      "Epoch 822/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1919 - val_loss: 0.1930\n",
      "Epoch 823/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1929 - val_loss: 0.1919\n",
      "Epoch 824/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1926 - val_loss: 0.1943\n",
      "Epoch 825/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1925 - val_loss: 0.1969\n",
      "Epoch 826/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1929 - val_loss: 0.1912\n",
      "Epoch 827/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1929 - val_loss: 0.1969\n",
      "Epoch 828/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1912 - val_loss: 0.1930\n",
      "Epoch 829/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1923 - val_loss: 0.1907\n",
      "Epoch 830/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1916 - val_loss: 0.1972\n",
      "Epoch 831/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1918 - val_loss: 0.1913\n",
      "Epoch 832/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1901 - val_loss: 0.1950\n",
      "Epoch 833/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1904 - val_loss: 0.1915\n",
      "Epoch 834/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1905 - val_loss: 0.1905\n",
      "Epoch 835/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1912 - val_loss: 0.1918\n",
      "Epoch 836/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1904 - val_loss: 0.1925\n",
      "Epoch 837/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1909 - val_loss: 0.1962\n",
      "Epoch 838/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1902 - val_loss: 0.1913\n",
      "Epoch 839/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1931 - val_loss: 0.1892\n",
      "Epoch 840/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1916 - val_loss: 0.1992\n",
      "Epoch 841/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1911 - val_loss: 0.1886\n",
      "Epoch 842/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1893 - val_loss: 0.1915\n",
      "Epoch 843/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1888 - val_loss: 0.1892\n",
      "Epoch 844/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1900 - val_loss: 0.1932\n",
      "Epoch 845/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1894 - val_loss: 0.1903\n",
      "Epoch 846/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1894 - val_loss: 0.1892\n",
      "Epoch 847/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1895 - val_loss: 0.1937\n",
      "Epoch 848/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1888 - val_loss: 0.1887\n",
      "Epoch 849/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1888 - val_loss: 0.1924\n",
      "Epoch 850/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1888 - val_loss: 0.1915\n",
      "Epoch 851/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1881 - val_loss: 0.1887\n",
      "Epoch 852/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1894 - val_loss: 0.1975\n",
      "Epoch 853/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1891 - val_loss: 0.1870\n",
      "Epoch 854/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1886 - val_loss: 0.1899\n",
      "Epoch 855/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1870 - val_loss: 0.1888\n",
      "Epoch 856/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1884 - val_loss: 0.1881\n",
      "Epoch 857/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1884 - val_loss: 0.1905\n",
      "Epoch 858/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1875 - val_loss: 0.1880\n",
      "Epoch 859/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1875 - val_loss: 0.1915\n",
      "Epoch 860/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1887 - val_loss: 0.1935\n",
      "Epoch 861/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1893 - val_loss: 0.1863\n",
      "Epoch 862/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1872 - val_loss: 0.1897\n",
      "Epoch 863/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1857 - val_loss: 0.1864\n",
      "Epoch 864/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1865 - val_loss: 0.1890\n",
      "Epoch 865/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1862 - val_loss: 0.1858\n",
      "Epoch 866/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1872 - val_loss: 0.1877\n",
      "Epoch 867/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1861 - val_loss: 0.1878\n",
      "Epoch 868/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1861 - val_loss: 0.1884\n",
      "Epoch 869/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1866 - val_loss: 0.1903\n",
      "Epoch 870/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1862 - val_loss: 0.1865\n",
      "Epoch 871/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1864 - val_loss: 0.1904\n",
      "Epoch 872/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1851 - val_loss: 0.1846\n",
      "Epoch 873/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1861 - val_loss: 0.1863\n",
      "Epoch 874/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1855 - val_loss: 0.1873\n",
      "Epoch 875/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1851 - val_loss: 0.1857\n",
      "Epoch 876/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1848 - val_loss: 0.1879\n",
      "Epoch 877/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1849 - val_loss: 0.1859\n",
      "Epoch 878/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1844 - val_loss: 0.1870\n",
      "Epoch 879/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1839 - val_loss: 0.1891\n",
      "Epoch 880/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1852 - val_loss: 0.1854\n",
      "Epoch 881/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1842 - val_loss: 0.1871\n",
      "Epoch 882/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1845 - val_loss: 0.1871\n",
      "Epoch 883/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1850 - val_loss: 0.1860\n",
      "Epoch 884/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1837 - val_loss: 0.1862\n",
      "Epoch 885/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1837 - val_loss: 0.1856\n",
      "Epoch 886/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1838 - val_loss: 0.1863\n",
      "Epoch 887/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1844 - val_loss: 0.1825\n",
      "Epoch 888/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1836 - val_loss: 0.1879\n",
      "Epoch 889/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1847 - val_loss: 0.1822\n",
      "Epoch 890/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1848 - val_loss: 0.1885\n",
      "Epoch 891/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1823 - val_loss: 0.1833\n",
      "Epoch 892/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1826 - val_loss: 0.1850\n",
      "Epoch 893/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1823 - val_loss: 0.1853\n",
      "Epoch 894/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1842 - val_loss: 0.1824\n",
      "Epoch 895/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1835 - val_loss: 0.1850\n",
      "Epoch 896/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1824 - val_loss: 0.1843\n",
      "Epoch 897/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1821 - val_loss: 0.1853\n",
      "Epoch 898/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1831 - val_loss: 0.1837\n",
      "Epoch 899/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1817 - val_loss: 0.1848\n",
      "Epoch 900/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1819 - val_loss: 0.1827\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1826 - val_loss: 0.1805\n",
      "Epoch 902/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1818 - val_loss: 0.1813\n",
      "Epoch 903/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1818 - val_loss: 0.1828\n",
      "Epoch 904/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1825 - val_loss: 0.1880\n",
      "Epoch 905/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1812 - val_loss: 0.1801\n",
      "Epoch 906/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1828 - val_loss: 0.1834\n",
      "Epoch 907/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1840 - val_loss: 0.1860\n",
      "Epoch 908/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1835 - val_loss: 0.1784\n",
      "Epoch 909/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1834 - val_loss: 0.1903\n",
      "Epoch 910/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1821 - val_loss: 0.1798\n",
      "Epoch 911/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1819 - val_loss: 0.1799\n",
      "Epoch 912/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1803 - val_loss: 0.1836\n",
      "Epoch 913/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1805 - val_loss: 0.1804\n",
      "Epoch 914/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1811 - val_loss: 0.1795\n",
      "Epoch 915/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1803 - val_loss: 0.1808\n",
      "Epoch 916/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1798 - val_loss: 0.1793\n",
      "Epoch 917/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1806 - val_loss: 0.1826\n",
      "Epoch 918/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1796 - val_loss: 0.1787\n",
      "Epoch 919/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1796 - val_loss: 0.1848\n",
      "Epoch 920/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1803 - val_loss: 0.1791\n",
      "Epoch 921/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1791 - val_loss: 0.1809\n",
      "Epoch 922/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1797 - val_loss: 0.1784\n",
      "Epoch 923/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1797 - val_loss: 0.1785\n",
      "Epoch 924/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1791 - val_loss: 0.1810\n",
      "Epoch 925/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1791 - val_loss: 0.1789\n",
      "Epoch 926/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1787 - val_loss: 0.1800\n",
      "Epoch 927/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1781 - val_loss: 0.1792\n",
      "Epoch 928/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1803 - val_loss: 0.1775\n",
      "Epoch 929/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1801 - val_loss: 0.1803\n",
      "Epoch 930/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1784 - val_loss: 0.1769\n",
      "Epoch 931/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1788 - val_loss: 0.1788\n",
      "Epoch 932/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1778 - val_loss: 0.1791\n",
      "Epoch 933/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1780 - val_loss: 0.1767\n",
      "Epoch 934/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1774 - val_loss: 0.1804\n",
      "Epoch 935/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1783 - val_loss: 0.1788\n",
      "Epoch 936/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1773 - val_loss: 0.1766\n",
      "Epoch 937/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1783 - val_loss: 0.1770\n",
      "Epoch 938/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1771 - val_loss: 0.1765\n",
      "Epoch 939/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1771 - val_loss: 0.1775\n",
      "Epoch 940/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1766 - val_loss: 0.1765\n",
      "Epoch 941/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1766 - val_loss: 0.1784\n",
      "Epoch 942/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1772 - val_loss: 0.1802\n",
      "Epoch 943/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1766 - val_loss: 0.1750\n",
      "Epoch 944/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1760 - val_loss: 0.1805\n",
      "Epoch 945/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1768 - val_loss: 0.1762\n",
      "Epoch 946/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1760 - val_loss: 0.1772\n",
      "Epoch 947/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1768 - val_loss: 0.1759\n",
      "Epoch 948/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1768 - val_loss: 0.1818\n",
      "Epoch 949/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1782 - val_loss: 0.1752\n",
      "Epoch 950/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1754 - val_loss: 0.1757\n",
      "Epoch 951/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1759 - val_loss: 0.1744\n",
      "Epoch 952/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1754 - val_loss: 0.1780\n",
      "Epoch 953/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1750 - val_loss: 0.1752\n",
      "Epoch 954/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1751 - val_loss: 0.1777\n",
      "Epoch 955/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1771 - val_loss: 0.1740\n",
      "Epoch 956/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1753 - val_loss: 0.1802\n",
      "Epoch 957/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1749 - val_loss: 0.1723\n",
      "Epoch 958/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1746 - val_loss: 0.1768\n",
      "Epoch 959/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1758 - val_loss: 0.1730\n",
      "Epoch 960/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1740 - val_loss: 0.1772\n",
      "Epoch 961/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1742 - val_loss: 0.1735\n",
      "Epoch 962/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1745 - val_loss: 0.1717\n",
      "Epoch 963/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1739 - val_loss: 0.1780\n",
      "Epoch 964/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1744 - val_loss: 0.1721\n",
      "Epoch 965/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1736 - val_loss: 0.1756\n",
      "Epoch 966/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1732 - val_loss: 0.1731\n",
      "Epoch 967/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1752 - val_loss: 0.1783\n",
      "Epoch 968/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1749 - val_loss: 0.1746\n",
      "Epoch 969/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1730 - val_loss: 0.1729\n",
      "Epoch 970/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1731 - val_loss: 0.1735\n",
      "Epoch 971/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1743 - val_loss: 0.1777\n",
      "Epoch 972/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1750 - val_loss: 0.1748\n",
      "Epoch 973/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1751 - val_loss: 0.1706\n",
      "Epoch 974/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1731 - val_loss: 0.1712\n",
      "Epoch 975/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1726 - val_loss: 0.1768\n",
      "Epoch 976/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1741 - val_loss: 0.1709\n",
      "Epoch 977/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1724 - val_loss: 0.1756\n",
      "Epoch 978/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1718 - val_loss: 0.1701\n",
      "Epoch 979/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1727 - val_loss: 0.1706\n",
      "Epoch 980/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1720 - val_loss: 0.1721\n",
      "Epoch 981/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1738 - val_loss: 0.1753\n",
      "Epoch 982/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1718 - val_loss: 0.1712\n",
      "Epoch 983/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1717 - val_loss: 0.1737\n",
      "Epoch 984/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1713 - val_loss: 0.1700\n",
      "Epoch 985/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1715 - val_loss: 0.1691\n",
      "Epoch 986/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1710 - val_loss: 0.1718\n",
      "Epoch 987/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1710 - val_loss: 0.1688\n",
      "Epoch 988/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1712 - val_loss: 0.1700\n",
      "Epoch 989/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1706 - val_loss: 0.1700\n",
      "Epoch 990/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1704 - val_loss: 0.1686\n",
      "Epoch 991/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1703 - val_loss: 0.1688\n",
      "Epoch 992/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1704 - val_loss: 0.1708\n",
      "Epoch 993/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1705 - val_loss: 0.1665\n",
      "Epoch 994/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1700 - val_loss: 0.1745\n",
      "Epoch 995/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1698 - val_loss: 0.1671\n",
      "Epoch 996/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1696 - val_loss: 0.1753\n",
      "Epoch 997/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1700 - val_loss: 0.1672\n",
      "Epoch 998/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1689 - val_loss: 0.1683\n",
      "Epoch 999/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1700 - val_loss: 0.1738\n",
      "Epoch 1000/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1700 - val_loss: 0.1653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2622823fe88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=1000,validation_data=(X_test,y_test),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.692859</td>\n",
       "      <td>0.686218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.675002</td>\n",
       "      <td>0.670337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.659039</td>\n",
       "      <td>0.655509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.645098</td>\n",
       "      <td>0.641663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.631999</td>\n",
       "      <td>0.628711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.169609</td>\n",
       "      <td>0.175251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.170022</td>\n",
       "      <td>0.167179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.168855</td>\n",
       "      <td>0.168280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.169954</td>\n",
       "      <td>0.173804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.169987</td>\n",
       "      <td>0.165279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.692859  0.686218\n",
       "1    0.675002  0.670337\n",
       "2    0.659039  0.655509\n",
       "3    0.645098  0.641663\n",
       "4    0.631999  0.628711\n",
       "..        ...       ...\n",
       "995  0.169609  0.175251\n",
       "996  0.170022  0.167179\n",
       "997  0.168855  0.168280\n",
       "998  0.169954  0.173804\n",
       "999  0.169987  0.165279\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x262293c67c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9,activation='relu',input_shape=(9, )))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1791 samples, validate on 597 samples\n",
      "Epoch 1/1000\n",
      "1791/1791 [==============================] - 3s 1ms/sample - loss: 0.6826 - val_loss: 0.6754\n",
      "Epoch 2/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.6727 - val_loss: 0.6653\n",
      "Epoch 3/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.6626 - val_loss: 0.6547\n",
      "Epoch 4/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.6524 - val_loss: 0.6433\n",
      "Epoch 5/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.6411 - val_loss: 0.6318\n",
      "Epoch 6/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.6299 - val_loss: 0.6203\n",
      "Epoch 7/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.6188 - val_loss: 0.6082\n",
      "Epoch 8/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.6075 - val_loss: 0.5966\n",
      "Epoch 9/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.5967 - val_loss: 0.5849\n",
      "Epoch 10/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5859 - val_loss: 0.5732\n",
      "Epoch 11/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.5751 - val_loss: 0.5617\n",
      "Epoch 12/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.5649 - val_loss: 0.5500\n",
      "Epoch 13/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.5548 - val_loss: 0.5386\n",
      "Epoch 14/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.5450 - val_loss: 0.5277\n",
      "Epoch 15/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5349 - val_loss: 0.5171\n",
      "Epoch 16/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.5251 - val_loss: 0.5050\n",
      "Epoch 17/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5154 - val_loss: 0.4944\n",
      "Epoch 18/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5072 - val_loss: 0.4858\n",
      "Epoch 19/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4999 - val_loss: 0.4775\n",
      "Epoch 20/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4935 - val_loss: 0.4704\n",
      "Epoch 21/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4881 - val_loss: 0.4651\n",
      "Epoch 22/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4827 - val_loss: 0.4597\n",
      "Epoch 23/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4785 - val_loss: 0.4554\n",
      "Epoch 24/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4743 - val_loss: 0.4515\n",
      "Epoch 25/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4705 - val_loss: 0.4478\n",
      "Epoch 26/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4673 - val_loss: 0.4434\n",
      "Epoch 27/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.4624 - val_loss: 0.4399\n",
      "Epoch 28/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4583 - val_loss: 0.4361\n",
      "Epoch 29/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4540 - val_loss: 0.4312\n",
      "Epoch 30/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4498 - val_loss: 0.4266\n",
      "Epoch 31/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4454 - val_loss: 0.4230\n",
      "Epoch 32/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4400 - val_loss: 0.4180\n",
      "Epoch 33/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4356 - val_loss: 0.4141\n",
      "Epoch 34/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4312 - val_loss: 0.4091\n",
      "Epoch 35/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4261 - val_loss: 0.4058\n",
      "Epoch 36/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4215 - val_loss: 0.4003\n",
      "Epoch 37/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4168 - val_loss: 0.3968\n",
      "Epoch 38/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4120 - val_loss: 0.3917\n",
      "Epoch 39/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4076 - val_loss: 0.3881\n",
      "Epoch 40/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4034 - val_loss: 0.3828\n",
      "Epoch 41/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3985 - val_loss: 0.3781\n",
      "Epoch 42/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3924 - val_loss: 0.3739\n",
      "Epoch 43/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3868 - val_loss: 0.3682\n",
      "Epoch 44/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3813 - val_loss: 0.3640\n",
      "Epoch 45/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3755 - val_loss: 0.3595\n",
      "Epoch 46/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3711 - val_loss: 0.3537\n",
      "Epoch 47/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3661 - val_loss: 0.3516\n",
      "Epoch 48/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3624 - val_loss: 0.3468\n",
      "Epoch 49/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3585 - val_loss: 0.3423\n",
      "Epoch 50/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3544 - val_loss: 0.3417\n",
      "Epoch 51/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3512 - val_loss: 0.3371\n",
      "Epoch 52/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3474 - val_loss: 0.3343\n",
      "Epoch 53/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3448 - val_loss: 0.3316\n",
      "Epoch 54/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3410 - val_loss: 0.3285\n",
      "Epoch 55/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.3392 - val_loss: 0.3254\n",
      "Epoch 56/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.3371 - val_loss: 0.3255\n",
      "Epoch 57/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.3345 - val_loss: 0.3217\n",
      "Epoch 58/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3318 - val_loss: 0.3209\n",
      "Epoch 59/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3298 - val_loss: 0.3185\n",
      "Epoch 60/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3280 - val_loss: 0.3178\n",
      "Epoch 61/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3269 - val_loss: 0.3141\n",
      "Epoch 62/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3238 - val_loss: 0.3148\n",
      "Epoch 63/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3220 - val_loss: 0.3112\n",
      "Epoch 64/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3193 - val_loss: 0.3113\n",
      "Epoch 65/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3169 - val_loss: 0.3080\n",
      "Epoch 66/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3153 - val_loss: 0.3055\n",
      "Epoch 67/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3137 - val_loss: 0.3035\n",
      "Epoch 68/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3121 - val_loss: 0.3070\n",
      "Epoch 69/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3109 - val_loss: 0.3012\n",
      "Epoch 70/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3103 - val_loss: 0.3089\n",
      "Epoch 71/1000\n",
      "1791/1791 [==============================] - 0s 60us/sample - loss: 0.3109 - val_loss: 0.3010\n",
      "Epoch 72/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3084 - val_loss: 0.3031\n",
      "Epoch 73/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3075 - val_loss: 0.3000\n",
      "Epoch 74/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3066 - val_loss: 0.2996\n",
      "Epoch 75/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3053 - val_loss: 0.2990\n",
      "Epoch 76/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3041 - val_loss: 0.2974\n",
      "Epoch 77/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3041 - val_loss: 0.3012\n",
      "Epoch 78/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3037 - val_loss: 0.2964\n",
      "Epoch 79/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3041 - val_loss: 0.2942\n",
      "Epoch 80/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3017 - val_loss: 0.2979\n",
      "Epoch 81/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3007 - val_loss: 0.2953\n",
      "Epoch 82/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2999 - val_loss: 0.2938\n",
      "Epoch 83/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2996 - val_loss: 0.2935\n",
      "Epoch 84/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2984 - val_loss: 0.2934\n",
      "Epoch 85/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2984 - val_loss: 0.2942\n",
      "Epoch 86/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2973 - val_loss: 0.2920\n",
      "Epoch 87/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2966 - val_loss: 0.2922\n",
      "Epoch 88/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2970 - val_loss: 0.2916\n",
      "Epoch 89/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2954 - val_loss: 0.2903\n",
      "Epoch 90/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2957 - val_loss: 0.2890\n",
      "Epoch 91/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2947 - val_loss: 0.2895\n",
      "Epoch 92/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2939 - val_loss: 0.2906\n",
      "Epoch 93/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2936 - val_loss: 0.2880\n",
      "Epoch 94/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2935 - val_loss: 0.2879\n",
      "Epoch 95/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2924 - val_loss: 0.2912\n",
      "Epoch 96/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2932 - val_loss: 0.2849\n",
      "Epoch 97/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2918 - val_loss: 0.2919\n",
      "Epoch 98/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2925 - val_loss: 0.2847\n",
      "Epoch 99/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2909 - val_loss: 0.2880\n",
      "Epoch 100/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2899 - val_loss: 0.2889\n",
      "Epoch 101/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2895 - val_loss: 0.2866\n",
      "Epoch 102/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2890 - val_loss: 0.2869\n",
      "Epoch 103/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2883 - val_loss: 0.2845\n",
      "Epoch 104/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2874 - val_loss: 0.2866\n",
      "Epoch 105/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2872 - val_loss: 0.2862\n",
      "Epoch 106/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2863 - val_loss: 0.2830\n",
      "Epoch 107/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2860 - val_loss: 0.2821\n",
      "Epoch 108/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2855 - val_loss: 0.2850\n",
      "Epoch 109/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2850 - val_loss: 0.2819\n",
      "Epoch 110/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2845 - val_loss: 0.2821\n",
      "Epoch 111/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2842 - val_loss: 0.2813\n",
      "Epoch 112/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2835 - val_loss: 0.2848\n",
      "Epoch 113/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2832 - val_loss: 0.2808\n",
      "Epoch 114/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2846 - val_loss: 0.2843\n",
      "Epoch 115/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2818 - val_loss: 0.2813\n",
      "Epoch 116/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2822 - val_loss: 0.2823\n",
      "Epoch 117/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2811 - val_loss: 0.2799\n",
      "Epoch 118/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2810 - val_loss: 0.2812\n",
      "Epoch 119/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2801 - val_loss: 0.2800\n",
      "Epoch 120/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2799 - val_loss: 0.2807\n",
      "Epoch 121/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2796 - val_loss: 0.2808\n",
      "Epoch 122/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2800 - val_loss: 0.2770\n",
      "Epoch 123/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2795 - val_loss: 0.2800\n",
      "Epoch 124/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2787 - val_loss: 0.2788\n",
      "Epoch 125/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2780 - val_loss: 0.2784\n",
      "Epoch 126/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2776 - val_loss: 0.2786\n",
      "Epoch 127/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2773 - val_loss: 0.2776\n",
      "Epoch 128/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2776 - val_loss: 0.2798\n",
      "Epoch 129/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2764 - val_loss: 0.2764\n",
      "Epoch 130/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2784 - val_loss: 0.2815\n",
      "Epoch 131/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2770 - val_loss: 0.2752\n",
      "Epoch 132/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2753 - val_loss: 0.2764\n",
      "Epoch 133/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2752 - val_loss: 0.2770\n",
      "Epoch 134/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2756 - val_loss: 0.2776\n",
      "Epoch 135/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2750 - val_loss: 0.2734\n",
      "Epoch 136/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.2741 - val_loss: 0.2754\n",
      "Epoch 137/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2732 - val_loss: 0.2755\n",
      "Epoch 138/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2730 - val_loss: 0.2750\n",
      "Epoch 139/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2730 - val_loss: 0.2720\n",
      "Epoch 140/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2719 - val_loss: 0.2736\n",
      "Epoch 141/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2714 - val_loss: 0.2764\n",
      "Epoch 142/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2711 - val_loss: 0.2718\n",
      "Epoch 143/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2712 - val_loss: 0.2727\n",
      "Epoch 144/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2703 - val_loss: 0.2720\n",
      "Epoch 145/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2701 - val_loss: 0.2716\n",
      "Epoch 146/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2701 - val_loss: 0.2722\n",
      "Epoch 147/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2694 - val_loss: 0.2715\n",
      "Epoch 148/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2687 - val_loss: 0.2705\n",
      "Epoch 149/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2687 - val_loss: 0.2713\n",
      "Epoch 150/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2677 - val_loss: 0.2711\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2682 - val_loss: 0.2706\n",
      "Epoch 152/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2668 - val_loss: 0.2680\n",
      "Epoch 153/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2668 - val_loss: 0.2689\n",
      "Epoch 154/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2666 - val_loss: 0.2699\n",
      "Epoch 155/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2667 - val_loss: 0.2687\n",
      "Epoch 156/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2673 - val_loss: 0.2700\n",
      "Epoch 157/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2651 - val_loss: 0.2679\n",
      "Epoch 158/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2648 - val_loss: 0.2681\n",
      "Epoch 159/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2643 - val_loss: 0.2672\n",
      "Epoch 160/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2645 - val_loss: 0.2693\n",
      "Epoch 161/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2635 - val_loss: 0.2662\n",
      "Epoch 162/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2632 - val_loss: 0.2663\n",
      "Epoch 163/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2633 - val_loss: 0.2667\n",
      "Epoch 164/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 165/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2621 - val_loss: 0.2664\n",
      "Epoch 166/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2612 - val_loss: 0.2629\n",
      "Epoch 167/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2616 - val_loss: 0.2634\n",
      "Epoch 168/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2604 - val_loss: 0.2640\n",
      "Epoch 169/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 170/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2609 - val_loss: 0.2654\n",
      "Epoch 171/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2594 - val_loss: 0.2629\n",
      "Epoch 172/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2594 - val_loss: 0.2604\n",
      "Epoch 173/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2587 - val_loss: 0.2631\n",
      "Epoch 174/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2577 - val_loss: 0.2599\n",
      "Epoch 175/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2577 - val_loss: 0.2625\n",
      "Epoch 176/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2580 - val_loss: 0.2589\n",
      "Epoch 177/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2576 - val_loss: 0.2584\n",
      "Epoch 178/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2560 - val_loss: 0.2605\n",
      "Epoch 179/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2558 - val_loss: 0.2603\n",
      "Epoch 180/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2550 - val_loss: 0.2582\n",
      "Epoch 181/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2551 - val_loss: 0.2581\n",
      "Epoch 182/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2539 - val_loss: 0.2553\n",
      "Epoch 183/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2536 - val_loss: 0.2587\n",
      "Epoch 184/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2539 - val_loss: 0.2565\n",
      "Epoch 185/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2528 - val_loss: 0.2558\n",
      "Epoch 186/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2528 - val_loss: 0.2581\n",
      "Epoch 187/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2524 - val_loss: 0.2530\n",
      "Epoch 188/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2529 - val_loss: 0.2587\n",
      "Epoch 189/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2519 - val_loss: 0.2539\n",
      "Epoch 190/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2506 - val_loss: 0.2542\n",
      "Epoch 191/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2503 - val_loss: 0.2533\n",
      "Epoch 192/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2500 - val_loss: 0.2518\n",
      "Epoch 193/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2516 - val_loss: 0.2523\n",
      "Epoch 194/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2496 - val_loss: 0.2514\n",
      "Epoch 195/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2488 - val_loss: 0.2516\n",
      "Epoch 196/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2480 - val_loss: 0.2514\n",
      "Epoch 197/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2490 - val_loss: 0.2551\n",
      "Epoch 198/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2474 - val_loss: 0.2489\n",
      "Epoch 199/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2473 - val_loss: 0.2532\n",
      "Epoch 200/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2462 - val_loss: 0.2475\n",
      "Epoch 201/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2464 - val_loss: 0.2514\n",
      "Epoch 202/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2460 - val_loss: 0.2469\n",
      "Epoch 203/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2462 - val_loss: 0.2523\n",
      "Epoch 204/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2452 - val_loss: 0.2457\n",
      "Epoch 205/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2457 - val_loss: 0.2517\n",
      "Epoch 206/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2457 - val_loss: 0.2450\n",
      "Epoch 207/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2447 - val_loss: 0.2487\n",
      "Epoch 208/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2436 - val_loss: 0.2440\n",
      "Epoch 209/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2430 - val_loss: 0.2458\n",
      "Epoch 210/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2428 - val_loss: 0.2473\n",
      "Epoch 211/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2427 - val_loss: 0.2442\n",
      "Epoch 212/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2418 - val_loss: 0.2443\n",
      "Epoch 213/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2412 - val_loss: 0.2473\n",
      "Epoch 214/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2410 - val_loss: 0.2433\n",
      "Epoch 215/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2405 - val_loss: 0.2437\n",
      "Epoch 216/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2395 - val_loss: 0.2409\n",
      "Epoch 217/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2398 - val_loss: 0.2444\n",
      "Epoch 218/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2390 - val_loss: 0.2410\n",
      "Epoch 219/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2385 - val_loss: 0.2413\n",
      "Epoch 220/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2379 - val_loss: 0.2418\n",
      "Epoch 221/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2389 - val_loss: 0.2398\n",
      "Epoch 222/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2376 - val_loss: 0.2435\n",
      "Epoch 223/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2369 - val_loss: 0.2394\n",
      "Epoch 224/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2364 - val_loss: 0.2412\n",
      "Epoch 225/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2358 - val_loss: 0.2398\n",
      "Epoch 226/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2355 - val_loss: 0.2419\n",
      "Epoch 227/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2360 - val_loss: 0.2396\n",
      "Epoch 228/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2365 - val_loss: 0.2373\n",
      "Epoch 229/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2349 - val_loss: 0.2388\n",
      "Epoch 230/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2370 - val_loss: 0.2437\n",
      "Epoch 231/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2341 - val_loss: 0.2358\n",
      "Epoch 232/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2334 - val_loss: 0.2383\n",
      "Epoch 233/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2329 - val_loss: 0.2367\n",
      "Epoch 234/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2330 - val_loss: 0.2358\n",
      "Epoch 235/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2315 - val_loss: 0.2381\n",
      "Epoch 236/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2310 - val_loss: 0.2339\n",
      "Epoch 237/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2317 - val_loss: 0.2388\n",
      "Epoch 238/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2307 - val_loss: 0.2338\n",
      "Epoch 239/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2303 - val_loss: 0.2366\n",
      "Epoch 240/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2295 - val_loss: 0.2355\n",
      "Epoch 241/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2290 - val_loss: 0.2347\n",
      "Epoch 242/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2297 - val_loss: 0.2334\n",
      "Epoch 243/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2283 - val_loss: 0.2359\n",
      "Epoch 244/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2281 - val_loss: 0.2335\n",
      "Epoch 245/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2280 - val_loss: 0.2336\n",
      "Epoch 246/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2270 - val_loss: 0.2342\n",
      "Epoch 247/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2270 - val_loss: 0.2314\n",
      "Epoch 248/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2264 - val_loss: 0.2322\n",
      "Epoch 249/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2263 - val_loss: 0.2313\n",
      "Epoch 250/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2256 - val_loss: 0.2319\n",
      "Epoch 251/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2254 - val_loss: 0.2328\n",
      "Epoch 252/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2255 - val_loss: 0.2335\n",
      "Epoch 253/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2260 - val_loss: 0.2326\n",
      "Epoch 254/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2244 - val_loss: 0.2288\n",
      "Epoch 255/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2244 - val_loss: 0.2315\n",
      "Epoch 256/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2243 - val_loss: 0.2285\n",
      "Epoch 257/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2236 - val_loss: 0.2339\n",
      "Epoch 258/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2240 - val_loss: 0.2295\n",
      "Epoch 259/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2224 - val_loss: 0.2301\n",
      "Epoch 260/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2225 - val_loss: 0.2290\n",
      "Epoch 261/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2228 - val_loss: 0.2265\n",
      "Epoch 262/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2213 - val_loss: 0.2297\n",
      "Epoch 263/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2217 - val_loss: 0.2267\n",
      "Epoch 264/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2203 - val_loss: 0.2273\n",
      "Epoch 265/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2204 - val_loss: 0.2291\n",
      "Epoch 266/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2204 - val_loss: 0.2250\n",
      "Epoch 267/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2192 - val_loss: 0.2281\n",
      "Epoch 268/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2195 - val_loss: 0.2268\n",
      "Epoch 269/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2188 - val_loss: 0.2251\n",
      "Epoch 270/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2186 - val_loss: 0.2246\n",
      "Epoch 271/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2181 - val_loss: 0.2246\n",
      "Epoch 272/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2179 - val_loss: 0.2244\n",
      "Epoch 273/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2180 - val_loss: 0.2257\n",
      "Epoch 274/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2184 - val_loss: 0.2237\n",
      "Epoch 275/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2177 - val_loss: 0.2256\n",
      "Epoch 276/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.209 - 0s 34us/sample - loss: 0.2168 - val_loss: 0.2231\n",
      "Epoch 277/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2169 - val_loss: 0.2223\n",
      "Epoch 278/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2180 - val_loss: 0.2296\n",
      "Epoch 279/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2178 - val_loss: 0.2204\n",
      "Epoch 280/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2164 - val_loss: 0.2239\n",
      "Epoch 281/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2154 - val_loss: 0.2228\n",
      "Epoch 282/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2157 - val_loss: 0.2197\n",
      "Epoch 283/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2149 - val_loss: 0.2209\n",
      "Epoch 284/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2143 - val_loss: 0.2216\n",
      "Epoch 285/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.263 - 0s 27us/sample - loss: 0.2152 - val_loss: 0.2183\n",
      "Epoch 286/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2141 - val_loss: 0.2221\n",
      "Epoch 287/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2146 - val_loss: 0.2210\n",
      "Epoch 288/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2137 - val_loss: 0.2181\n",
      "Epoch 289/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2139 - val_loss: 0.2184\n",
      "Epoch 290/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2124 - val_loss: 0.2202\n",
      "Epoch 291/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2127 - val_loss: 0.2184\n",
      "Epoch 292/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2134 - val_loss: 0.2205\n",
      "Epoch 293/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2116 - val_loss: 0.2182\n",
      "Epoch 294/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.2115 - val_loss: 0.2199\n",
      "Epoch 295/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2118 - val_loss: 0.2190\n",
      "Epoch 296/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2116 - val_loss: 0.2164\n",
      "Epoch 297/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2107 - val_loss: 0.2196\n",
      "Epoch 298/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2109 - val_loss: 0.2147\n",
      "Epoch 299/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2111 - val_loss: 0.2201\n",
      "Epoch 300/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2107 - val_loss: 0.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2112 - val_loss: 0.2161\n",
      "Epoch 302/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2095 - val_loss: 0.2143\n",
      "Epoch 303/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2102 - val_loss: 0.2141\n",
      "Epoch 304/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2093 - val_loss: 0.2149\n",
      "Epoch 305/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2085 - val_loss: 0.2163\n",
      "Epoch 306/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2082 - val_loss: 0.2137\n",
      "Epoch 307/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2084 - val_loss: 0.2163\n",
      "Epoch 308/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2082 - val_loss: 0.2137\n",
      "Epoch 309/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2080 - val_loss: 0.2130\n",
      "Epoch 310/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2077 - val_loss: 0.2128\n",
      "Epoch 311/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2080 - val_loss: 0.2128\n",
      "Epoch 312/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2070 - val_loss: 0.2115\n",
      "Epoch 313/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2072 - val_loss: 0.2139\n",
      "Epoch 314/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2079 - val_loss: 0.2092\n",
      "Epoch 315/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2076 - val_loss: 0.2142\n",
      "Epoch 316/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2063 - val_loss: 0.2112\n",
      "Epoch 317/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2062 - val_loss: 0.2120\n",
      "Epoch 318/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2067 - val_loss: 0.2090\n",
      "Epoch 319/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2056 - val_loss: 0.2111\n",
      "Epoch 320/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2050 - val_loss: 0.2090\n",
      "Epoch 321/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2050 - val_loss: 0.2100\n",
      "Epoch 322/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2046 - val_loss: 0.2092\n",
      "Epoch 323/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2049 - val_loss: 0.2099\n",
      "Epoch 324/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2056 - val_loss: 0.2076\n",
      "Epoch 325/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2056 - val_loss: 0.2083\n",
      "Epoch 326/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2040 - val_loss: 0.2087\n",
      "Epoch 327/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2038 - val_loss: 0.2078\n",
      "Epoch 328/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2040 - val_loss: 0.2099\n",
      "Epoch 329/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2031 - val_loss: 0.2048\n",
      "Epoch 330/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2041 - val_loss: 0.2153\n",
      "Epoch 331/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2046 - val_loss: 0.2049\n",
      "Epoch 332/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2026 - val_loss: 0.2067\n",
      "Epoch 333/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2024 - val_loss: 0.2074\n",
      "Epoch 334/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2032 - val_loss: 0.2053\n",
      "Epoch 335/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2022 - val_loss: 0.2056\n",
      "Epoch 336/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.216 - 0s 25us/sample - loss: 0.2018 - val_loss: 0.2070\n",
      "Epoch 337/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2020 - val_loss: 0.2047\n",
      "Epoch 338/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2024 - val_loss: 0.2045\n",
      "Epoch 339/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2011 - val_loss: 0.2042\n",
      "Epoch 340/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2021 - val_loss: 0.2034\n",
      "Epoch 341/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2021 - val_loss: 0.2056\n",
      "Epoch 342/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2007 - val_loss: 0.2021\n",
      "Epoch 343/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2017 - val_loss: 0.2036\n",
      "Epoch 344/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2005 - val_loss: 0.2034\n",
      "Epoch 345/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2007 - val_loss: 0.2015\n",
      "Epoch 346/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1997 - val_loss: 0.2017\n",
      "Epoch 347/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2005 - val_loss: 0.2003\n",
      "Epoch 348/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1996 - val_loss: 0.2006\n",
      "Epoch 349/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1990 - val_loss: 0.2015\n",
      "Epoch 350/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1986 - val_loss: 0.2024\n",
      "Epoch 351/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1989 - val_loss: 0.1997\n",
      "Epoch 352/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1994 - val_loss: 0.1995\n",
      "Epoch 353/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1981 - val_loss: 0.2014\n",
      "Epoch 354/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1982 - val_loss: 0.1989\n",
      "Epoch 355/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1975 - val_loss: 0.1996\n",
      "Epoch 356/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1977 - val_loss: 0.2022\n",
      "Epoch 357/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1981 - val_loss: 0.1983\n",
      "Epoch 358/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1982 - val_loss: 0.1974\n",
      "Epoch 359/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1970 - val_loss: 0.1996\n",
      "Epoch 360/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1972 - val_loss: 0.2003\n",
      "Epoch 361/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1967 - val_loss: 0.1978\n",
      "Epoch 362/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1965 - val_loss: 0.1999\n",
      "Epoch 363/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1963 - val_loss: 0.1956\n",
      "Epoch 364/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1966 - val_loss: 0.1977\n",
      "Epoch 365/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1959 - val_loss: 0.1976\n",
      "Epoch 366/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1968 - val_loss: 0.1965\n",
      "Epoch 367/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1958 - val_loss: 0.2005\n",
      "Epoch 368/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1960 - val_loss: 0.1971\n",
      "Epoch 369/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1955 - val_loss: 0.1983\n",
      "Epoch 370/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1942 - val_loss: 0.1946\n",
      "Epoch 371/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1942 - val_loss: 0.1974\n",
      "Epoch 372/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1955 - val_loss: 0.1978\n",
      "Epoch 373/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1953 - val_loss: 0.1959\n",
      "Epoch 374/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1943 - val_loss: 0.1958\n",
      "Epoch 375/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1930 - val_loss: 0.1934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1930 - val_loss: 0.1938\n",
      "Epoch 377/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1928 - val_loss: 0.1938\n",
      "Epoch 378/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1932 - val_loss: 0.1925\n",
      "Epoch 379/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1931 - val_loss: 0.1928\n",
      "Epoch 380/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1922 - val_loss: 0.1933\n",
      "Epoch 381/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1923 - val_loss: 0.1933\n",
      "Epoch 382/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1929 - val_loss: 0.1907\n",
      "Epoch 383/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1918 - val_loss: 0.1933\n",
      "Epoch 384/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1916 - val_loss: 0.1925\n",
      "Epoch 385/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1912 - val_loss: 0.1918\n",
      "Epoch 386/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1911 - val_loss: 0.1907\n",
      "Epoch 387/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1908 - val_loss: 0.1909\n",
      "Epoch 388/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1924 - val_loss: 0.1897\n",
      "Epoch 389/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1914 - val_loss: 0.1912\n",
      "Epoch 390/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1905 - val_loss: 0.1896\n",
      "Epoch 391/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1910 - val_loss: 0.1898\n",
      "Epoch 392/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1899 - val_loss: 0.1907\n",
      "Epoch 393/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1902 - val_loss: 0.1927\n",
      "Epoch 394/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1896 - val_loss: 0.1872\n",
      "Epoch 395/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1905 - val_loss: 0.1889\n",
      "Epoch 396/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1898 - val_loss: 0.1882\n",
      "Epoch 397/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1884 - val_loss: 0.1901\n",
      "Epoch 398/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1890 - val_loss: 0.1873\n",
      "Epoch 399/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1887 - val_loss: 0.1898\n",
      "Epoch 400/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1882 - val_loss: 0.1857\n",
      "Epoch 401/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1886 - val_loss: 0.1902\n",
      "Epoch 402/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1881 - val_loss: 0.1883\n",
      "Epoch 403/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1876 - val_loss: 0.1870\n",
      "Epoch 404/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1875 - val_loss: 0.1865\n",
      "Epoch 405/1000\n",
      "1791/1791 [==============================] - 0s 53us/sample - loss: 0.1873 - val_loss: 0.1867\n",
      "Epoch 406/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1876 - val_loss: 0.1863\n",
      "Epoch 407/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1872 - val_loss: 0.1864\n",
      "Epoch 408/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1888 - val_loss: 0.1913\n",
      "Epoch 409/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1881 - val_loss: 0.1842\n",
      "Epoch 410/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1875 - val_loss: 0.1873\n",
      "Epoch 411/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1860 - val_loss: 0.1838\n",
      "Epoch 412/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1865 - val_loss: 0.1851\n",
      "Epoch 413/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1859 - val_loss: 0.1844\n",
      "Epoch 414/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1854 - val_loss: 0.1837\n",
      "Epoch 415/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1857 - val_loss: 0.1851\n",
      "Epoch 416/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1858 - val_loss: 0.1870\n",
      "Epoch 417/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1853 - val_loss: 0.1832\n",
      "Epoch 418/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1851 - val_loss: 0.1847\n",
      "Epoch 419/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1850 - val_loss: 0.1842\n",
      "Epoch 420/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1848 - val_loss: 0.1823\n",
      "Epoch 421/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1852 - val_loss: 0.1873\n",
      "Epoch 422/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1851 - val_loss: 0.1836\n",
      "Epoch 423/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1848 - val_loss: 0.1829\n",
      "Epoch 424/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1839 - val_loss: 0.1841\n",
      "Epoch 425/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1855 - val_loss: 0.1803\n",
      "Epoch 426/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1837 - val_loss: 0.1848\n",
      "Epoch 427/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1832 - val_loss: 0.1821\n",
      "Epoch 428/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1834 - val_loss: 0.1841\n",
      "Epoch 429/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1841 - val_loss: 0.1807\n",
      "Epoch 430/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1825 - val_loss: 0.1867\n",
      "Epoch 431/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1839 - val_loss: 0.1799\n",
      "Epoch 432/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1828 - val_loss: 0.1825\n",
      "Epoch 433/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1825 - val_loss: 0.1811\n",
      "Epoch 434/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1821 - val_loss: 0.1811\n",
      "Epoch 435/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1821 - val_loss: 0.1812\n",
      "Epoch 436/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1827 - val_loss: 0.1802\n",
      "Epoch 437/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1822 - val_loss: 0.1808\n",
      "Epoch 438/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1818 - val_loss: 0.1850\n",
      "Epoch 439/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1818 - val_loss: 0.1786\n",
      "Epoch 440/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1816 - val_loss: 0.1787\n",
      "Epoch 441/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1808 - val_loss: 0.1789\n",
      "Epoch 442/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1810 - val_loss: 0.1812\n",
      "Epoch 443/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1809 - val_loss: 0.1782\n",
      "Epoch 444/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1801 - val_loss: 0.1836\n",
      "Epoch 445/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1828 - val_loss: 0.1775\n",
      "Epoch 446/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1807 - val_loss: 0.1804\n",
      "Epoch 447/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1801 - val_loss: 0.1786\n",
      "Epoch 448/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1808 - val_loss: 0.1760\n",
      "Epoch 449/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1800 - val_loss: 0.1828\n",
      "Epoch 450/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1814 - val_loss: 0.1766\n",
      "Epoch 451/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1792 - val_loss: 0.1794\n",
      "Epoch 452/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1791 - val_loss: 0.1775\n",
      "Epoch 453/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1788 - val_loss: 0.1771\n",
      "Epoch 454/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1792 - val_loss: 0.1793\n",
      "Epoch 455/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1817 - val_loss: 0.1752\n",
      "Epoch 456/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1775 - val_loss: 0.1812\n",
      "Epoch 457/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1797 - val_loss: 0.1758\n",
      "Epoch 458/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1787 - val_loss: 0.1801\n",
      "Epoch 459/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1779 - val_loss: 0.1753\n",
      "Epoch 460/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1779 - val_loss: 0.1762\n",
      "Epoch 461/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1782 - val_loss: 0.1804\n",
      "Epoch 462/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1797 - val_loss: 0.1745\n",
      "Epoch 463/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1774 - val_loss: 0.1755\n",
      "Epoch 464/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1771 - val_loss: 0.1778\n",
      "Epoch 465/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1767 - val_loss: 0.1752\n",
      "Epoch 466/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1780 - val_loss: 0.1794\n",
      "Epoch 467/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1774 - val_loss: 0.1756\n",
      "Epoch 468/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1766 - val_loss: 0.1754\n",
      "Epoch 469/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1764 - val_loss: 0.1746\n",
      "Epoch 470/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1765 - val_loss: 0.1740\n",
      "Epoch 471/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1762 - val_loss: 0.1767\n",
      "Epoch 472/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1766 - val_loss: 0.1732\n",
      "Epoch 473/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1758 - val_loss: 0.1756\n",
      "Epoch 474/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1759 - val_loss: 0.1735\n",
      "Epoch 475/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1754 - val_loss: 0.1745\n",
      "Epoch 476/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1754 - val_loss: 0.1737\n",
      "Epoch 477/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1760 - val_loss: 0.1748\n",
      "Epoch 478/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1751 - val_loss: 0.1728\n",
      "Epoch 479/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1749 - val_loss: 0.1732\n",
      "Epoch 480/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1754 - val_loss: 0.1770\n",
      "Epoch 481/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1746 - val_loss: 0.1720\n",
      "Epoch 482/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1761 - val_loss: 0.1762\n",
      "Epoch 483/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1750 - val_loss: 0.1710\n",
      "Epoch 484/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1736 - val_loss: 0.1731\n",
      "Epoch 485/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1747 - val_loss: 0.1745\n",
      "Epoch 486/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1742 - val_loss: 0.1710\n",
      "Epoch 487/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1746 - val_loss: 0.1721\n",
      "Epoch 488/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1731 - val_loss: 0.1715\n",
      "Epoch 489/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1732 - val_loss: 0.1708\n",
      "Epoch 490/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1737 - val_loss: 0.1710\n",
      "Epoch 491/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1727 - val_loss: 0.1708\n",
      "Epoch 492/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1727 - val_loss: 0.1705\n",
      "Epoch 493/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1721 - val_loss: 0.1706\n",
      "Epoch 494/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1722 - val_loss: 0.1710\n",
      "Epoch 495/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1720 - val_loss: 0.1707\n",
      "Epoch 496/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1719 - val_loss: 0.1701\n",
      "Epoch 497/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1717 - val_loss: 0.1714\n",
      "Epoch 498/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1722 - val_loss: 0.1689\n",
      "Epoch 499/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1727 - val_loss: 0.1739\n",
      "Epoch 500/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1713 - val_loss: 0.1701\n",
      "Epoch 501/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1712 - val_loss: 0.1708\n",
      "Epoch 502/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1708 - val_loss: 0.1691\n",
      "Epoch 503/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1712 - val_loss: 0.1681\n",
      "Epoch 504/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1714 - val_loss: 0.1742\n",
      "Epoch 505/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1729 - val_loss: 0.1676\n",
      "Epoch 506/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1710 - val_loss: 0.1703\n",
      "Epoch 507/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1699 - val_loss: 0.1689\n",
      "Epoch 508/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1696 - val_loss: 0.1681\n",
      "Epoch 509/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1697 - val_loss: 0.1722\n",
      "Epoch 510/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1704 - val_loss: 0.1686\n",
      "Epoch 511/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1689 - val_loss: 0.1693\n",
      "Epoch 512/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1699 - val_loss: 0.1703\n",
      "Epoch 513/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1690 - val_loss: 0.1682\n",
      "Epoch 514/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1686 - val_loss: 0.1692\n",
      "Epoch 515/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1688 - val_loss: 0.1693\n",
      "Epoch 516/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1696 - val_loss: 0.1691\n",
      "Epoch 517/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1680 - val_loss: 0.1673\n",
      "Epoch 518/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1680 - val_loss: 0.1687\n",
      "Epoch 519/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1677 - val_loss: 0.1672\n",
      "Epoch 520/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1676 - val_loss: 0.1679\n",
      "Epoch 521/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1680 - val_loss: 0.1665\n",
      "Epoch 522/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1686 - val_loss: 0.1667\n",
      "Epoch 523/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1672 - val_loss: 0.1689\n",
      "Epoch 524/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1678 - val_loss: 0.1686\n",
      "Epoch 525/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1670 - val_loss: 0.1657\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1679 - val_loss: 0.1676\n",
      "Epoch 527/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1668 - val_loss: 0.1672\n",
      "Epoch 528/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1677 - val_loss: 0.1665\n",
      "Epoch 529/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1676 - val_loss: 0.1654\n",
      "Epoch 530/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1665 - val_loss: 0.1667\n",
      "Epoch 531/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1660 - val_loss: 0.1675\n",
      "Epoch 532/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1661 - val_loss: 0.1654\n",
      "Epoch 533/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1658 - val_loss: 0.1667\n",
      "Epoch 534/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1653 - val_loss: 0.1655\n",
      "Epoch 535/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1656 - val_loss: 0.1646\n",
      "Epoch 536/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1653 - val_loss: 0.1670\n",
      "Epoch 537/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1661 - val_loss: 0.1662\n",
      "Epoch 538/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1653 - val_loss: 0.1650\n",
      "Epoch 539/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1657 - val_loss: 0.1658\n",
      "Epoch 540/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1650 - val_loss: 0.1649\n",
      "Epoch 541/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1643 - val_loss: 0.1662\n",
      "Epoch 542/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1652 - val_loss: 0.1648\n",
      "Epoch 543/1000\n",
      "1791/1791 [==============================] - 0s 44us/sample - loss: 0.1652 - val_loss: 0.1715\n",
      "Epoch 544/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1673 - val_loss: 0.1638\n",
      "Epoch 545/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1667 - val_loss: 0.1637\n",
      "Epoch 546/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1642 - val_loss: 0.1658\n",
      "Epoch 547/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1648 - val_loss: 0.1628\n",
      "Epoch 548/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1655 - val_loss: 0.1640\n",
      "Epoch 549/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1638 - val_loss: 0.1634\n",
      "Epoch 550/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1637 - val_loss: 0.1641\n",
      "Epoch 551/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1637 - val_loss: 0.1633\n",
      "Epoch 552/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1633 - val_loss: 0.1632\n",
      "Epoch 553/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.1628 - val_loss: 0.1647\n",
      "Epoch 554/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.1627 - val_loss: 0.1628\n",
      "Epoch 555/1000\n",
      "1791/1791 [==============================] - 0s 52us/sample - loss: 0.1636 - val_loss: 0.1673\n",
      "Epoch 556/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1656 - val_loss: 0.1622\n",
      "Epoch 557/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1633 - val_loss: 0.1623\n",
      "Epoch 558/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1624 - val_loss: 0.1643\n",
      "Epoch 559/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1626 - val_loss: 0.1622\n",
      "Epoch 560/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1617 - val_loss: 0.1652\n",
      "Epoch 561/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1633 - val_loss: 0.1624\n",
      "Epoch 562/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1641 - val_loss: 0.1625\n",
      "Epoch 563/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1621 - val_loss: 0.1620\n",
      "Epoch 564/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1632 - val_loss: 0.1687\n",
      "Epoch 565/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1623 - val_loss: 0.1619\n",
      "Epoch 566/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1622 - val_loss: 0.1620\n",
      "Epoch 567/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1618 - val_loss: 0.1613\n",
      "Epoch 568/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1612 - val_loss: 0.1628\n",
      "Epoch 569/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1612 - val_loss: 0.1628\n",
      "Epoch 570/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1611 - val_loss: 0.1639\n",
      "Epoch 571/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1622 - val_loss: 0.1622\n",
      "Epoch 572/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1614 - val_loss: 0.1623\n",
      "Epoch 573/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1612 - val_loss: 0.1618\n",
      "Epoch 574/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1617 - val_loss: 0.1632\n",
      "Epoch 575/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.1612 - val_loss: 0.1615\n",
      "Epoch 576/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1609 - val_loss: 0.1603\n",
      "Epoch 577/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1600 - val_loss: 0.1635\n",
      "Epoch 578/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1604 - val_loss: 0.1623\n",
      "Epoch 579/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1606 - val_loss: 0.1609\n",
      "Epoch 580/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1602 - val_loss: 0.1607\n",
      "Epoch 581/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1605 - val_loss: 0.1628\n",
      "Epoch 582/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1599 - val_loss: 0.1602\n",
      "Epoch 583/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1599 - val_loss: 0.1627\n",
      "Epoch 584/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1600 - val_loss: 0.1604\n",
      "Epoch 585/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1595 - val_loss: 0.1606\n",
      "Epoch 586/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1596 - val_loss: 0.1616\n",
      "Epoch 587/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1607 - val_loss: 0.1620\n",
      "Epoch 588/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1625 - val_loss: 0.1600\n",
      "Epoch 589/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.1589 - val_loss: 0.1637\n",
      "Epoch 590/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1590 - val_loss: 0.1593\n",
      "Epoch 591/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1589 - val_loss: 0.1595\n",
      "Epoch 592/1000\n",
      "1791/1791 [==============================] - 0s 46us/sample - loss: 0.1585 - val_loss: 0.1591\n",
      "Epoch 593/1000\n",
      "1791/1791 [==============================] - 0s 50us/sample - loss: 0.1585 - val_loss: 0.1598\n",
      "Epoch 594/1000\n",
      "1791/1791 [==============================] - 0s 54us/sample - loss: 0.1588 - val_loss: 0.1624\n",
      "Epoch 595/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1596 - val_loss: 0.1585\n",
      "Epoch 596/1000\n",
      "1791/1791 [==============================] - 0s 45us/sample - loss: 0.1593 - val_loss: 0.1598\n",
      "Epoch 597/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1595 - val_loss: 0.1605\n",
      "Epoch 598/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1581 - val_loss: 0.1589\n",
      "Epoch 599/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1582 - val_loss: 0.1597\n",
      "Epoch 600/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1582 - val_loss: 0.1609\n",
      "Epoch 601/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1582 - val_loss: 0.1597\n",
      "Epoch 602/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1579 - val_loss: 0.1577\n",
      "Epoch 603/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1595 - val_loss: 0.1588\n",
      "Epoch 604/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1579 - val_loss: 0.1583\n",
      "Epoch 605/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1585 - val_loss: 0.1594\n",
      "Epoch 606/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1580 - val_loss: 0.1600\n",
      "Epoch 607/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1573 - val_loss: 0.1581\n",
      "Epoch 608/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1573 - val_loss: 0.1647\n",
      "Epoch 609/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1606 - val_loss: 0.1577\n",
      "Epoch 610/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1583 - val_loss: 0.1577\n",
      "Epoch 611/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1576 - val_loss: 0.1575\n",
      "Epoch 612/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1578 - val_loss: 0.1590\n",
      "Epoch 613/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1573 - val_loss: 0.1598\n",
      "Epoch 614/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1566 - val_loss: 0.1567\n",
      "Epoch 615/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1569 - val_loss: 0.1576\n",
      "Epoch 616/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1566 - val_loss: 0.1574\n",
      "Epoch 617/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1562 - val_loss: 0.1610\n",
      "Epoch 618/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1573 - val_loss: 0.1569\n",
      "Epoch 619/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1563 - val_loss: 0.1578\n",
      "Epoch 620/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1565 - val_loss: 0.1580\n",
      "Epoch 621/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1564 - val_loss: 0.1583\n",
      "Epoch 622/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1559 - val_loss: 0.1596\n",
      "Epoch 623/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1558 - val_loss: 0.1582\n",
      "Epoch 624/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1566 - val_loss: 0.1599\n",
      "Epoch 625/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1556 - val_loss: 0.1563\n",
      "Epoch 626/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1561 - val_loss: 0.1587\n",
      "Epoch 627/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1556 - val_loss: 0.1599\n",
      "Epoch 628/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1560 - val_loss: 0.1577\n",
      "Epoch 629/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1554 - val_loss: 0.1601\n",
      "Epoch 630/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1554 - val_loss: 0.1564\n",
      "Epoch 631/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1558 - val_loss: 0.1596\n",
      "Epoch 632/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1551 - val_loss: 0.1573\n",
      "Epoch 633/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1553 - val_loss: 0.1571\n",
      "Epoch 634/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1559 - val_loss: 0.1600\n",
      "Epoch 635/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1559 - val_loss: 0.1563\n",
      "Epoch 636/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1549 - val_loss: 0.1590\n",
      "Epoch 637/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1548 - val_loss: 0.1575\n",
      "Epoch 638/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1546 - val_loss: 0.1559\n",
      "Epoch 639/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1541 - val_loss: 0.1573\n",
      "Epoch 640/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1539 - val_loss: 0.1567\n",
      "Epoch 641/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1546 - val_loss: 0.1599\n",
      "Epoch 642/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1539 - val_loss: 0.1559\n",
      "Epoch 643/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1550 - val_loss: 0.1585\n",
      "Epoch 644/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1539 - val_loss: 0.1564\n",
      "Epoch 645/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1535 - val_loss: 0.1566\n",
      "Epoch 646/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1533 - val_loss: 0.1563\n",
      "Epoch 647/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.1543 - val_loss: 0.1569\n",
      "Epoch 648/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1535 - val_loss: 0.1572\n",
      "Epoch 649/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1539 - val_loss: 0.1557\n",
      "Epoch 650/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1533 - val_loss: 0.1559\n",
      "Epoch 651/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1527 - val_loss: 0.1570\n",
      "Epoch 652/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1546 - val_loss: 0.1563\n",
      "Epoch 653/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1541 - val_loss: 0.1565\n",
      "Epoch 654/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1523 - val_loss: 0.1588\n",
      "Epoch 655/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1546 - val_loss: 0.1557\n",
      "Epoch 656/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1525 - val_loss: 0.1556\n",
      "Epoch 657/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1522 - val_loss: 0.1570\n",
      "Epoch 658/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.1521 - val_loss: 0.1569\n",
      "Epoch 659/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.1525 - val_loss: 0.1555\n",
      "Epoch 660/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1530 - val_loss: 0.1582\n",
      "Epoch 661/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1526 - val_loss: 0.1554\n",
      "Epoch 662/1000\n",
      "1791/1791 [==============================] - 0s 47us/sample - loss: 0.1536 - val_loss: 0.1579\n",
      "Epoch 663/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1539 - val_loss: 0.1579\n",
      "Epoch 664/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1531 - val_loss: 0.1566\n",
      "Epoch 665/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1541 - val_loss: 0.1544\n",
      "Epoch 666/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1524 - val_loss: 0.1559\n",
      "Epoch 667/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1517 - val_loss: 0.1561\n",
      "Epoch 668/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1518 - val_loss: 0.1562\n",
      "Epoch 669/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1519 - val_loss: 0.1557\n",
      "Epoch 670/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1522 - val_loss: 0.1585\n",
      "Epoch 671/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1521 - val_loss: 0.1551\n",
      "Epoch 672/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1533 - val_loss: 0.1554\n",
      "Epoch 673/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1530 - val_loss: 0.1591\n",
      "Epoch 674/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1526 - val_loss: 0.1550\n",
      "Epoch 675/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1529 - val_loss: 0.1553\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1508 - val_loss: 0.1569\n",
      "Epoch 677/1000\n",
      "1791/1791 [==============================] - 0s 45us/sample - loss: 0.1524 - val_loss: 0.1547\n",
      "Epoch 678/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.1510 - val_loss: 0.1555\n",
      "Epoch 679/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1525 - val_loss: 0.1541\n",
      "Epoch 680/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1525 - val_loss: 0.1602\n",
      "Epoch 681/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1515 - val_loss: 0.1547\n",
      "Epoch 682/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1518 - val_loss: 0.1565\n",
      "Epoch 683/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1503 - val_loss: 0.1543\n",
      "Epoch 684/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1502 - val_loss: 0.1565\n",
      "Epoch 685/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1505 - val_loss: 0.1541\n",
      "Epoch 686/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1512 - val_loss: 0.1569\n",
      "Epoch 687/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1505 - val_loss: 0.1549\n",
      "Epoch 688/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1505 - val_loss: 0.1560\n",
      "Epoch 689/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1507 - val_loss: 0.1542\n",
      "Epoch 690/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1513 - val_loss: 0.1577\n",
      "Epoch 691/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1515 - val_loss: 0.1571\n",
      "Epoch 692/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1502 - val_loss: 0.1543\n",
      "Epoch 693/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1500 - val_loss: 0.1552\n",
      "Epoch 694/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1499 - val_loss: 0.1559\n",
      "Epoch 695/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.1512 - val_loss: 0.1543\n",
      "Epoch 696/1000\n",
      "1791/1791 [==============================] - 0s 49us/sample - loss: 0.1522 - val_loss: 0.1540\n",
      "Epoch 697/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1532 - val_loss: 0.1592\n",
      "Epoch 698/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1498 - val_loss: 0.1538\n",
      "Epoch 699/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1492 - val_loss: 0.1555\n",
      "Epoch 700/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1490 - val_loss: 0.1538\n",
      "Epoch 701/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1496 - val_loss: 0.1557\n",
      "Epoch 702/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1489 - val_loss: 0.1551\n",
      "Epoch 703/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1495 - val_loss: 0.1535\n",
      "Epoch 704/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1482 - val_loss: 0.1574\n",
      "Epoch 705/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1496 - val_loss: 0.1542\n",
      "Epoch 706/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1499 - val_loss: 0.1557\n",
      "Epoch 707/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1489 - val_loss: 0.1537\n",
      "Epoch 708/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.149 - 0s 23us/sample - loss: 0.1484 - val_loss: 0.1555\n",
      "Epoch 709/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1482 - val_loss: 0.1549\n",
      "Epoch 710/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1484 - val_loss: 0.1543\n",
      "Epoch 711/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1487 - val_loss: 0.1565\n",
      "Epoch 712/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1504 - val_loss: 0.1537\n",
      "Epoch 713/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1480 - val_loss: 0.1550\n",
      "Epoch 714/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1487 - val_loss: 0.1557\n",
      "Epoch 715/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1477 - val_loss: 0.1537\n",
      "Epoch 716/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1479 - val_loss: 0.1577\n",
      "Epoch 717/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1488 - val_loss: 0.1544\n",
      "Epoch 718/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1485 - val_loss: 0.1533\n",
      "Epoch 719/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1483 - val_loss: 0.1545\n",
      "Epoch 720/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1478 - val_loss: 0.1555\n",
      "Epoch 721/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1478 - val_loss: 0.1540\n",
      "Epoch 722/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1474 - val_loss: 0.1573\n",
      "Epoch 723/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1491 - val_loss: 0.1539\n",
      "Epoch 724/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1467 - val_loss: 0.1558\n",
      "Epoch 725/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1496 - val_loss: 0.1575\n",
      "Epoch 726/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1484 - val_loss: 0.1536\n",
      "Epoch 727/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1497 - val_loss: 0.1597\n",
      "Epoch 728/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1486 - val_loss: 0.1539\n",
      "Epoch 729/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1486 - val_loss: 0.1530\n",
      "Epoch 730/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.1464 - val_loss: 0.1543\n",
      "Epoch 731/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1466 - val_loss: 0.1561\n",
      "Epoch 732/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1473 - val_loss: 0.1545\n",
      "Epoch 733/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1465 - val_loss: 0.1545\n",
      "Epoch 734/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1469 - val_loss: 0.1539\n",
      "Epoch 735/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1460 - val_loss: 0.1561\n",
      "Epoch 736/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1472 - val_loss: 0.1535\n",
      "Epoch 737/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1475 - val_loss: 0.1539\n",
      "Epoch 738/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1465 - val_loss: 0.1557\n",
      "Epoch 739/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1462 - val_loss: 0.1535\n",
      "Epoch 740/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1469 - val_loss: 0.1539\n",
      "Epoch 741/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.1470 - val_loss: 0.1534\n",
      "Epoch 742/1000\n",
      "1791/1791 [==============================] - 0s 59us/sample - loss: 0.1470 - val_loss: 0.1562\n",
      "Epoch 743/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1466 - val_loss: 0.1547\n",
      "Epoch 744/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1462 - val_loss: 0.1552\n",
      "Epoch 745/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1463 - val_loss: 0.1551\n",
      "Epoch 746/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1456 - val_loss: 0.1542\n",
      "Epoch 747/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1460 - val_loss: 0.1545\n",
      "Epoch 748/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.1455 - val_loss: 0.1546\n",
      "Epoch 749/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1452 - val_loss: 0.1533\n",
      "Epoch 750/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.1461 - val_loss: 0.1540\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1465 - val_loss: 0.1555\n",
      "Epoch 752/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1450 - val_loss: 0.1532\n",
      "Epoch 753/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1452 - val_loss: 0.1538\n",
      "Epoch 754/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1451 - val_loss: 0.1533\n",
      "Epoch 00754: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2622952a588>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=1000,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop],batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2622a629188>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[335  14]\n",
      " [ 19 229]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       349\n",
      "           1       0.94      0.92      0.93       248\n",
      "\n",
      "    accuracy                           0.94       597\n",
      "   macro avg       0.94      0.94      0.94       597\n",
      "weighted avg       0.94      0.94      0.94       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_ANN_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = df.drop('Cancer Positive',axis=1).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    31.000000\n",
       "BMI                    10.204207\n",
       "BreastFeeding           1.000000\n",
       "Marital Status          1.000000\n",
       "Alcohol                 0.000000\n",
       "Smoking                 0.000000\n",
       "BreastCancerHistory     0.000000\n",
       "Age at firstPeriod     12.000000\n",
       "MenstrualCycle          1.000000\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = scaler.transform(new_data.values.reshape(-1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28125   , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30769231, 1.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00187474]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18747384892776608"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(new_data)[0][0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "later_model = load_model('final_ANN_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00187474]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "later_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
