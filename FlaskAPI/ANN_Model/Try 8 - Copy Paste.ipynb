{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BreastCancerData (4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BreastFeeding</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>BreastCancerHistory</th>\n",
       "      <th>Age at firstPeriod</th>\n",
       "      <th>MenstrualCycle</th>\n",
       "      <th>Cancer Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>8.543723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10.204207</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>13.807133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>14.088867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>14.494061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  BreastFeeding  Marital Status  Alcohol  Smoking  \\\n",
       "0   48   8.543723              1               1        0        0   \n",
       "1   31  10.204207              1               1        0        0   \n",
       "2   31  13.807133              1               1        0        0   \n",
       "3   33  14.088867              1               1        1        0   \n",
       "4   49  14.494061              1               1        0        0   \n",
       "\n",
       "   BreastCancerHistory  Age at firstPeriod  MenstrualCycle  Cancer Positive  \n",
       "0                    0                  15               1                0  \n",
       "1                    0                  12               1                0  \n",
       "2                    0                  14               1                0  \n",
       "3                    0                  12               1                0  \n",
       "4                    0                  15               1                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>41.029313</td>\n",
       "      <td>7.694522</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BMI</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>24.723056</td>\n",
       "      <td>4.939623</td>\n",
       "      <td>8.543723</td>\n",
       "      <td>21.168699</td>\n",
       "      <td>24.453841</td>\n",
       "      <td>27.657793</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BreastFeeding</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.891122</td>\n",
       "      <td>0.311551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marital Status</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>1.126466</td>\n",
       "      <td>0.455754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Alcohol</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.351340</td>\n",
       "      <td>0.477489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Smoking</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.154941</td>\n",
       "      <td>0.361925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BreastCancerHistory</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>0.168718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age at firstPeriod</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>13.104690</td>\n",
       "      <td>1.684577</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MenstrualCycle</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.413093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cancer Positive</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.404523</td>\n",
       "      <td>0.490902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean       std        min        25%  \\\n",
       "Age                  2388.0  41.029313  7.694522  21.000000  35.000000   \n",
       "BMI                  2388.0  24.723056  4.939623   8.543723  21.168699   \n",
       "BreastFeeding        2388.0   0.891122  0.311551   0.000000   1.000000   \n",
       "Marital Status       2388.0   1.126466  0.455754   1.000000   1.000000   \n",
       "Alcohol              2388.0   0.351340  0.477489   0.000000   0.000000   \n",
       "Smoking              2388.0   0.154941  0.361925   0.000000   0.000000   \n",
       "BreastCancerHistory  2388.0   0.029313  0.168718   0.000000   0.000000   \n",
       "Age at firstPeriod   2388.0  13.104690  1.684577   8.000000  12.000000   \n",
       "MenstrualCycle       2388.0   0.781826  0.413093   0.000000   1.000000   \n",
       "Cancer Positive      2388.0   0.404523  0.490902   0.000000   0.000000   \n",
       "\n",
       "                           50%        75%   max  \n",
       "Age                  41.000000  48.000000  54.0  \n",
       "BMI                  24.453841  27.657793  69.5  \n",
       "BreastFeeding         1.000000   1.000000   1.0  \n",
       "Marital Status        1.000000   1.000000   3.0  \n",
       "Alcohol               0.000000   1.000000   1.0  \n",
       "Smoking               0.000000   0.000000   1.0  \n",
       "BreastCancerHistory   0.000000   0.000000   1.0  \n",
       "Age at firstPeriod   13.000000  14.000000  21.0  \n",
       "MenstrualCycle        1.000000   1.000000   1.0  \n",
       "Cancer Positive       0.000000   1.000000   1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2388 entries, 0 to 2387\n",
      "Data columns (total 10 columns):\n",
      "Age                    2388 non-null int64\n",
      "BMI                    2388 non-null float64\n",
      "BreastFeeding          2388 non-null int64\n",
      "Marital Status         2388 non-null int64\n",
      "Alcohol                2388 non-null int64\n",
      "Smoking                2388 non-null int64\n",
      "BreastCancerHistory    2388 non-null int64\n",
      "Age at firstPeriod     2388 non-null int64\n",
      "MenstrualCycle         2388 non-null int64\n",
      "Cancer Positive        2388 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 186.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2156f6e3788>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Cancer Positive',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MenstrualCycle        -0.527303\n",
       "Age at firstPeriod    -0.143939\n",
       "BreastFeeding         -0.125521\n",
       "Alcohol                0.040402\n",
       "Smoking                0.047929\n",
       "BreastCancerHistory    0.145085\n",
       "Marital Status         0.230007\n",
       "BMI                    0.360163\n",
       "Age                    0.387485\n",
       "Name: Cancer Positive, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Cancer Positive'][:-1].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Cancer Positive',axis=1).values\n",
    "y = df['Cancer Positive'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.        ,  8.5437225 ,  1.        , ...,  0.        ,\n",
       "        15.        ,  1.        ],\n",
       "       [31.        , 10.20420723,  1.        , ...,  0.        ,\n",
       "        12.        ,  1.        ],\n",
       "       [31.        , 13.80713296,  1.        , ...,  0.        ,\n",
       "        14.        ,  1.        ],\n",
       "       ...,\n",
       "       [51.        , 44.17113007,  0.        , ...,  1.        ,\n",
       "        14.        ,  0.        ],\n",
       "       [41.        , 57.76097459,  1.        , ...,  0.        ,\n",
       "        13.        ,  1.        ],\n",
       "       [35.        , 69.5       ,  1.        , ...,  1.        ,\n",
       "        15.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1791, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9,activation='relu',input_shape=(9, )))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1791 samples, validate on 597 samples\n",
      "Epoch 1/1000\n",
      "1791/1791 [==============================] - 1s 533us/sample - loss: 0.6916 - val_loss: 0.6826\n",
      "Epoch 2/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.6698 - val_loss: 0.6654\n",
      "Epoch 3/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.6536 - val_loss: 0.6496\n",
      "Epoch 4/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.6379 - val_loss: 0.6335\n",
      "Epoch 5/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.6219 - val_loss: 0.6161\n",
      "Epoch 6/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.6052 - val_loss: 0.5975\n",
      "Epoch 7/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.5877 - val_loss: 0.5784\n",
      "Epoch 8/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.5711 - val_loss: 0.5608\n",
      "Epoch 9/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.5560 - val_loss: 0.5457\n",
      "Epoch 10/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.5425 - val_loss: 0.5295\n",
      "Epoch 11/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.5280 - val_loss: 0.5135\n",
      "Epoch 12/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5169 - val_loss: 0.5015\n",
      "Epoch 13/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5082 - val_loss: 0.4916\n",
      "Epoch 14/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5006 - val_loss: 0.4833\n",
      "Epoch 15/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4946 - val_loss: 0.4760\n",
      "Epoch 16/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4886 - val_loss: 0.4688\n",
      "Epoch 17/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4829 - val_loss: 0.4629\n",
      "Epoch 18/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4785 - val_loss: 0.4580\n",
      "Epoch 19/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.4749 - val_loss: 0.4535\n",
      "Epoch 20/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4708 - val_loss: 0.4494\n",
      "Epoch 21/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4672 - val_loss: 0.4452\n",
      "Epoch 22/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4642 - val_loss: 0.4410\n",
      "Epoch 23/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4611 - val_loss: 0.4385\n",
      "Epoch 24/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4579 - val_loss: 0.4345\n",
      "Epoch 25/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4552 - val_loss: 0.4315\n",
      "Epoch 26/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4527 - val_loss: 0.4290\n",
      "Epoch 27/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4505 - val_loss: 0.4258\n",
      "Epoch 28/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4472 - val_loss: 0.4240\n",
      "Epoch 29/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4449 - val_loss: 0.4208\n",
      "Epoch 30/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4425 - val_loss: 0.4182\n",
      "Epoch 31/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4400 - val_loss: 0.4155\n",
      "Epoch 32/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4375 - val_loss: 0.4134\n",
      "Epoch 33/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4354 - val_loss: 0.4118\n",
      "Epoch 34/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4325 - val_loss: 0.4083\n",
      "Epoch 35/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4303 - val_loss: 0.4061\n",
      "Epoch 36/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4277 - val_loss: 0.4035\n",
      "Epoch 37/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4256 - val_loss: 0.4007\n",
      "Epoch 38/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4236 - val_loss: 0.3988\n",
      "Epoch 39/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4206 - val_loss: 0.3953\n",
      "Epoch 40/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4182 - val_loss: 0.3927\n",
      "Epoch 41/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4158 - val_loss: 0.3900\n",
      "Epoch 42/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4137 - val_loss: 0.3891\n",
      "Epoch 43/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4108 - val_loss: 0.3846\n",
      "Epoch 44/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4078 - val_loss: 0.3824\n",
      "Epoch 45/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4052 - val_loss: 0.3799\n",
      "Epoch 46/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4042 - val_loss: 0.3773\n",
      "Epoch 47/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4007 - val_loss: 0.3744\n",
      "Epoch 48/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3980 - val_loss: 0.3722\n",
      "Epoch 49/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3966 - val_loss: 0.3698\n",
      "Epoch 50/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3933 - val_loss: 0.3670\n",
      "Epoch 51/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3906 - val_loss: 0.3653\n",
      "Epoch 52/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3887 - val_loss: 0.3620\n",
      "Epoch 53/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3856 - val_loss: 0.3582\n",
      "Epoch 54/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3821 - val_loss: 0.3556\n",
      "Epoch 55/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3789 - val_loss: 0.3513\n",
      "Epoch 56/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3754 - val_loss: 0.3492\n",
      "Epoch 57/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3724 - val_loss: 0.3456\n",
      "Epoch 58/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3696 - val_loss: 0.3439\n",
      "Epoch 59/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3681 - val_loss: 0.3408\n",
      "Epoch 60/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3646 - val_loss: 0.3384\n",
      "Epoch 61/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3616 - val_loss: 0.3358\n",
      "Epoch 62/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3587 - val_loss: 0.3340\n",
      "Epoch 63/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3565 - val_loss: 0.3319\n",
      "Epoch 64/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3546 - val_loss: 0.3288\n",
      "Epoch 65/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3529 - val_loss: 0.3272\n",
      "Epoch 66/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3502 - val_loss: 0.3246\n",
      "Epoch 67/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3476 - val_loss: 0.3236\n",
      "Epoch 68/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3456 - val_loss: 0.3201\n",
      "Epoch 69/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3427 - val_loss: 0.3211\n",
      "Epoch 70/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3408 - val_loss: 0.3164\n",
      "Epoch 71/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3406 - val_loss: 0.3177\n",
      "Epoch 72/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3374 - val_loss: 0.3140\n",
      "Epoch 73/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3366 - val_loss: 0.3126\n",
      "Epoch 74/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3370 - val_loss: 0.3131\n",
      "Epoch 75/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3344 - val_loss: 0.3100\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3321 - val_loss: 0.3102\n",
      "Epoch 77/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3302 - val_loss: 0.3088\n",
      "Epoch 78/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3291 - val_loss: 0.3071\n",
      "Epoch 79/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3282 - val_loss: 0.3074\n",
      "Epoch 80/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3265 - val_loss: 0.3043\n",
      "Epoch 81/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3251 - val_loss: 0.3054\n",
      "Epoch 82/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3239 - val_loss: 0.3035\n",
      "Epoch 83/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3229 - val_loss: 0.3031\n",
      "Epoch 84/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3220 - val_loss: 0.3049\n",
      "Epoch 85/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3211 - val_loss: 0.3007\n",
      "Epoch 86/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3204 - val_loss: 0.3005\n",
      "Epoch 87/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3189 - val_loss: 0.3009\n",
      "Epoch 88/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.3177 - val_loss: 0.2996\n",
      "Epoch 89/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3163 - val_loss: 0.2993\n",
      "Epoch 90/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3158 - val_loss: 0.2977\n",
      "Epoch 91/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3144 - val_loss: 0.2987\n",
      "Epoch 92/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3145 - val_loss: 0.2967\n",
      "Epoch 93/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3135 - val_loss: 0.2962\n",
      "Epoch 94/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3122 - val_loss: 0.2955\n",
      "Epoch 95/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3116 - val_loss: 0.2936\n",
      "Epoch 96/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3102 - val_loss: 0.2959\n",
      "Epoch 97/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3104 - val_loss: 0.2932\n",
      "Epoch 98/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3085 - val_loss: 0.2951\n",
      "Epoch 99/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3082 - val_loss: 0.2926\n",
      "Epoch 100/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3084 - val_loss: 0.2927\n",
      "Epoch 101/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3070 - val_loss: 0.2910\n",
      "Epoch 102/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3055 - val_loss: 0.2902\n",
      "Epoch 103/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3050 - val_loss: 0.2907\n",
      "Epoch 104/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3044 - val_loss: 0.2904\n",
      "Epoch 105/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3039 - val_loss: 0.2894\n",
      "Epoch 106/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3030 - val_loss: 0.2890\n",
      "Epoch 107/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3021 - val_loss: 0.2875\n",
      "Epoch 108/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3029 - val_loss: 0.2892\n",
      "Epoch 109/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3014 - val_loss: 0.2867\n",
      "Epoch 110/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3015 - val_loss: 0.2882\n",
      "Epoch 111/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2998 - val_loss: 0.2866\n",
      "Epoch 112/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2994 - val_loss: 0.2866\n",
      "Epoch 113/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2982 - val_loss: 0.2860\n",
      "Epoch 114/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2980 - val_loss: 0.2875\n",
      "Epoch 115/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2974 - val_loss: 0.2839\n",
      "Epoch 116/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2970 - val_loss: 0.2853\n",
      "Epoch 117/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2957 - val_loss: 0.2853\n",
      "Epoch 118/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2956 - val_loss: 0.2842\n",
      "Epoch 119/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2944 - val_loss: 0.2842\n",
      "Epoch 120/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2946 - val_loss: 0.2846\n",
      "Epoch 121/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2942 - val_loss: 0.2833\n",
      "Epoch 122/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2933 - val_loss: 0.2814\n",
      "Epoch 123/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2919 - val_loss: 0.2833\n",
      "Epoch 124/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2914 - val_loss: 0.2812\n",
      "Epoch 125/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2914 - val_loss: 0.2825\n",
      "Epoch 126/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2910 - val_loss: 0.2803\n",
      "Epoch 127/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2898 - val_loss: 0.2802\n",
      "Epoch 128/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2897 - val_loss: 0.2846\n",
      "Epoch 129/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.2891 - val_loss: 0.2790\n",
      "Epoch 130/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2907 - val_loss: 0.2792\n",
      "Epoch 131/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2887 - val_loss: 0.2809\n",
      "Epoch 132/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2880 - val_loss: 0.2785\n",
      "Epoch 133/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2883 - val_loss: 0.2817\n",
      "Epoch 134/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2869 - val_loss: 0.2786\n",
      "Epoch 135/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2861 - val_loss: 0.2775\n",
      "Epoch 136/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2862 - val_loss: 0.2780\n",
      "Epoch 137/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2854 - val_loss: 0.2776\n",
      "Epoch 138/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2860 - val_loss: 0.2761\n",
      "Epoch 139/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2842 - val_loss: 0.2773\n",
      "Epoch 140/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2831 - val_loss: 0.2776\n",
      "Epoch 141/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2828 - val_loss: 0.2768\n",
      "Epoch 142/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2827 - val_loss: 0.2767\n",
      "Epoch 143/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2834 - val_loss: 0.2757\n",
      "Epoch 144/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2835 - val_loss: 0.2743\n",
      "Epoch 145/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2810 - val_loss: 0.2757\n",
      "Epoch 146/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2823 - val_loss: 0.2747\n",
      "Epoch 147/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2809 - val_loss: 0.2758\n",
      "Epoch 148/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2802 - val_loss: 0.2769\n",
      "Epoch 149/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2795 - val_loss: 0.2741\n",
      "Epoch 150/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2792 - val_loss: 0.2749\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2803 - val_loss: 0.2740\n",
      "Epoch 152/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2789 - val_loss: 0.2739\n",
      "Epoch 153/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2778 - val_loss: 0.2743\n",
      "Epoch 154/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2768 - val_loss: 0.2742\n",
      "Epoch 155/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2768 - val_loss: 0.2734\n",
      "Epoch 156/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2762 - val_loss: 0.2745\n",
      "Epoch 157/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2758 - val_loss: 0.2731\n",
      "Epoch 158/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2751 - val_loss: 0.2725\n",
      "Epoch 159/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2743 - val_loss: 0.2720\n",
      "Epoch 160/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2747 - val_loss: 0.2732\n",
      "Epoch 161/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2750 - val_loss: 0.2705\n",
      "Epoch 162/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2740 - val_loss: 0.2710\n",
      "Epoch 163/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2731 - val_loss: 0.2739\n",
      "Epoch 164/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2735 - val_loss: 0.2699\n",
      "Epoch 165/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2732 - val_loss: 0.2758\n",
      "Epoch 166/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2733 - val_loss: 0.2700\n",
      "Epoch 167/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2720 - val_loss: 0.2711\n",
      "Epoch 168/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2712 - val_loss: 0.2705\n",
      "Epoch 169/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2713 - val_loss: 0.2697\n",
      "Epoch 170/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2702 - val_loss: 0.2695\n",
      "Epoch 171/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2697 - val_loss: 0.2694\n",
      "Epoch 172/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2694 - val_loss: 0.2702\n",
      "Epoch 173/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2696 - val_loss: 0.2676\n",
      "Epoch 174/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2703 - val_loss: 0.2692\n",
      "Epoch 175/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2687 - val_loss: 0.2683\n",
      "Epoch 176/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2677 - val_loss: 0.2680\n",
      "Epoch 177/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2675 - val_loss: 0.2673\n",
      "Epoch 178/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2679 - val_loss: 0.2702\n",
      "Epoch 179/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2675 - val_loss: 0.2661\n",
      "Epoch 180/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2663 - val_loss: 0.2673\n",
      "Epoch 181/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2666 - val_loss: 0.2664\n",
      "Epoch 182/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2680 - val_loss: 0.2648\n",
      "Epoch 183/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2654 - val_loss: 0.2632\n",
      "Epoch 184/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2655 - val_loss: 0.2634\n",
      "Epoch 185/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2635 - val_loss: 0.2644\n",
      "Epoch 186/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2623 - val_loss: 0.2625\n",
      "Epoch 187/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2627 - val_loss: 0.2638\n",
      "Epoch 188/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2622 - val_loss: 0.2645\n",
      "Epoch 189/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2612 - val_loss: 0.2620\n",
      "Epoch 190/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2608 - val_loss: 0.2600\n",
      "Epoch 191/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2604 - val_loss: 0.2595\n",
      "Epoch 192/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2603 - val_loss: 0.2617\n",
      "Epoch 193/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2590 - val_loss: 0.2616\n",
      "Epoch 194/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2579 - val_loss: 0.2579\n",
      "Epoch 195/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2578 - val_loss: 0.2584\n",
      "Epoch 196/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2572 - val_loss: 0.2580\n",
      "Epoch 197/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2569 - val_loss: 0.2602\n",
      "Epoch 198/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2556 - val_loss: 0.2565\n",
      "Epoch 199/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2552 - val_loss: 0.2576\n",
      "Epoch 200/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2551 - val_loss: 0.2587\n",
      "Epoch 201/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2537 - val_loss: 0.2541\n",
      "Epoch 202/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2530 - val_loss: 0.2549\n",
      "Epoch 203/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2520 - val_loss: 0.2569\n",
      "Epoch 204/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2518 - val_loss: 0.2539\n",
      "Epoch 205/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2516 - val_loss: 0.2549\n",
      "Epoch 206/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2505 - val_loss: 0.2502\n",
      "Epoch 207/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2494 - val_loss: 0.2529\n",
      "Epoch 208/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2490 - val_loss: 0.2501\n",
      "Epoch 209/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2501 - val_loss: 0.2537\n",
      "Epoch 210/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2496 - val_loss: 0.2470\n",
      "Epoch 211/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2468 - val_loss: 0.2473\n",
      "Epoch 212/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2454 - val_loss: 0.2472\n",
      "Epoch 213/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2456 - val_loss: 0.2457\n",
      "Epoch 214/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2442 - val_loss: 0.2448\n",
      "Epoch 215/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2437 - val_loss: 0.2448\n",
      "Epoch 216/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2438 - val_loss: 0.2429\n",
      "Epoch 217/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2425 - val_loss: 0.2423\n",
      "Epoch 218/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2410 - val_loss: 0.2446\n",
      "Epoch 219/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2405 - val_loss: 0.2409\n",
      "Epoch 220/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2396 - val_loss: 0.2415\n",
      "Epoch 221/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2395 - val_loss: 0.2390\n",
      "Epoch 222/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2398 - val_loss: 0.2391\n",
      "Epoch 223/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2389 - val_loss: 0.2408\n",
      "Epoch 224/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2383 - val_loss: 0.2396\n",
      "Epoch 225/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2371 - val_loss: 0.2393\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2364 - val_loss: 0.2370\n",
      "Epoch 227/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2363 - val_loss: 0.2396\n",
      "Epoch 228/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2352 - val_loss: 0.2352\n",
      "Epoch 229/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2355 - val_loss: 0.2404\n",
      "Epoch 230/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2356 - val_loss: 0.2351\n",
      "Epoch 231/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2339 - val_loss: 0.2351\n",
      "Epoch 232/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2334 - val_loss: 0.2350\n",
      "Epoch 233/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2329 - val_loss: 0.2324\n",
      "Epoch 234/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2331 - val_loss: 0.2345\n",
      "Epoch 235/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2319 - val_loss: 0.2328\n",
      "Epoch 236/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2319 - val_loss: 0.2316\n",
      "Epoch 237/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2316 - val_loss: 0.2336\n",
      "Epoch 238/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2301 - val_loss: 0.2303\n",
      "Epoch 239/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2307 - val_loss: 0.2331\n",
      "Epoch 240/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2307 - val_loss: 0.2286\n",
      "Epoch 241/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2288 - val_loss: 0.2326\n",
      "Epoch 242/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2299 - val_loss: 0.2280\n",
      "Epoch 243/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2285 - val_loss: 0.2279\n",
      "Epoch 244/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2295 - val_loss: 0.2261\n",
      "Epoch 245/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2282 - val_loss: 0.2337\n",
      "Epoch 246/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2283 - val_loss: 0.2254\n",
      "Epoch 247/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2273 - val_loss: 0.2289\n",
      "Epoch 248/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2258 - val_loss: 0.2281\n",
      "Epoch 249/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2269 - val_loss: 0.2238\n",
      "Epoch 250/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2257 - val_loss: 0.2260\n",
      "Epoch 251/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2254 - val_loss: 0.2270\n",
      "Epoch 252/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2260 - val_loss: 0.2225\n",
      "Epoch 253/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2247 - val_loss: 0.2243\n",
      "Epoch 254/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2233 - val_loss: 0.2227\n",
      "Epoch 255/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2229 - val_loss: 0.2266\n",
      "Epoch 256/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2228 - val_loss: 0.2213\n",
      "Epoch 257/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2217 - val_loss: 0.2224\n",
      "Epoch 258/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2216 - val_loss: 0.2219\n",
      "Epoch 259/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2214 - val_loss: 0.2203\n",
      "Epoch 260/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2209 - val_loss: 0.2199\n",
      "Epoch 261/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2218 - val_loss: 0.2196\n",
      "Epoch 262/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2203 - val_loss: 0.2199\n",
      "Epoch 263/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2204 - val_loss: 0.2184\n",
      "Epoch 264/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2191 - val_loss: 0.2226\n",
      "Epoch 265/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2199 - val_loss: 0.2166\n",
      "Epoch 266/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2200 - val_loss: 0.2236\n",
      "Epoch 267/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2177 - val_loss: 0.2168\n",
      "Epoch 268/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2179 - val_loss: 0.2181\n",
      "Epoch 269/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2173 - val_loss: 0.2175\n",
      "Epoch 270/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2166 - val_loss: 0.2173\n",
      "Epoch 271/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2165 - val_loss: 0.2158\n",
      "Epoch 272/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2166 - val_loss: 0.2167\n",
      "Epoch 273/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2177 - val_loss: 0.2135\n",
      "Epoch 274/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2173 - val_loss: 0.2208\n",
      "Epoch 275/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2159 - val_loss: 0.2141\n",
      "Epoch 276/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2150 - val_loss: 0.2175\n",
      "Epoch 277/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2149 - val_loss: 0.2146\n",
      "Epoch 278/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2139 - val_loss: 0.2153\n",
      "Epoch 279/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2151 - val_loss: 0.2146\n",
      "Epoch 280/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2153 - val_loss: 0.2117\n",
      "Epoch 281/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2134 - val_loss: 0.2129\n",
      "Epoch 282/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2144 - val_loss: 0.2114\n",
      "Epoch 283/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2131 - val_loss: 0.2131\n",
      "Epoch 284/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2123 - val_loss: 0.2127\n",
      "Epoch 285/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2122 - val_loss: 0.2120\n",
      "Epoch 286/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2130 - val_loss: 0.2104\n",
      "Epoch 287/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2120 - val_loss: 0.2125\n",
      "Epoch 288/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2122 - val_loss: 0.2098\n",
      "Epoch 289/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2110 - val_loss: 0.2113\n",
      "Epoch 290/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2106 - val_loss: 0.2103\n",
      "Epoch 291/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2103 - val_loss: 0.2103\n",
      "Epoch 292/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2104 - val_loss: 0.2125\n",
      "Epoch 293/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2103 - val_loss: 0.2084\n",
      "Epoch 294/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2114 - val_loss: 0.2138\n",
      "Epoch 295/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2090 - val_loss: 0.2074\n",
      "Epoch 296/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2089 - val_loss: 0.2093\n",
      "Epoch 297/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2092 - val_loss: 0.2076\n",
      "Epoch 298/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2090 - val_loss: 0.2087\n",
      "Epoch 299/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2085 - val_loss: 0.2078\n",
      "Epoch 300/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2099 - val_loss: 0.2063\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2080 - val_loss: 0.2084\n",
      "Epoch 302/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2090 - val_loss: 0.2058\n",
      "Epoch 303/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2076 - val_loss: 0.2082\n",
      "Epoch 304/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2076 - val_loss: 0.2083\n",
      "Epoch 305/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2077 - val_loss: 0.2079\n",
      "Epoch 306/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2075 - val_loss: 0.2045\n",
      "Epoch 307/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2056 - val_loss: 0.2071\n",
      "Epoch 308/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2061 - val_loss: 0.2048\n",
      "Epoch 309/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2057 - val_loss: 0.2067\n",
      "Epoch 310/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2049 - val_loss: 0.2045\n",
      "Epoch 311/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2044 - val_loss: 0.2037\n",
      "Epoch 312/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2047 - val_loss: 0.2034\n",
      "Epoch 313/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2041 - val_loss: 0.2042\n",
      "Epoch 314/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2044 - val_loss: 0.2011\n",
      "Epoch 315/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2068 - val_loss: 0.2087\n",
      "Epoch 316/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2019 - val_loss: 0.2004\n",
      "Epoch 317/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2038 - val_loss: 0.2036\n",
      "Epoch 318/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2032 - val_loss: 0.2012\n",
      "Epoch 319/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2036 - val_loss: 0.2037\n",
      "Epoch 320/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2042 - val_loss: 0.1999\n",
      "Epoch 321/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2017 - val_loss: 0.2029\n",
      "Epoch 322/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2024 - val_loss: 0.2012\n",
      "Epoch 323/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2023 - val_loss: 0.2019\n",
      "Epoch 324/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2031 - val_loss: 0.1986\n",
      "Epoch 325/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2014 - val_loss: 0.2025\n",
      "Epoch 326/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2026 - val_loss: 0.1983\n",
      "Epoch 327/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2005 - val_loss: 0.2010\n",
      "Epoch 328/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2011 - val_loss: 0.1994\n",
      "Epoch 329/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2006 - val_loss: 0.1989\n",
      "Epoch 330/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2002 - val_loss: 0.1986\n",
      "Epoch 331/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2003 - val_loss: 0.1993\n",
      "Epoch 332/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2001 - val_loss: 0.2002\n",
      "Epoch 333/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1999 - val_loss: 0.1979\n",
      "Epoch 334/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1995 - val_loss: 0.1993\n",
      "Epoch 335/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1997 - val_loss: 0.1957\n",
      "Epoch 336/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1988 - val_loss: 0.1995\n",
      "Epoch 337/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1990 - val_loss: 0.1956\n",
      "Epoch 338/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1988 - val_loss: 0.1979\n",
      "Epoch 339/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1993 - val_loss: 0.1953\n",
      "Epoch 340/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1983 - val_loss: 0.1985\n",
      "Epoch 341/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2009 - val_loss: 0.1962\n",
      "Epoch 342/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1993 - val_loss: 0.1948\n",
      "Epoch 343/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1977 - val_loss: 0.1947\n",
      "Epoch 344/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1972 - val_loss: 0.1947\n",
      "Epoch 345/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1973 - val_loss: 0.1963\n",
      "Epoch 346/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1988 - val_loss: 0.1936\n",
      "Epoch 347/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1975 - val_loss: 0.1956\n",
      "Epoch 348/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1969 - val_loss: 0.1952\n",
      "Epoch 349/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1972 - val_loss: 0.1936\n",
      "Epoch 350/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1969 - val_loss: 0.1937\n",
      "Epoch 351/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1963 - val_loss: 0.1932\n",
      "Epoch 352/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1961 - val_loss: 0.1929\n",
      "Epoch 353/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1957 - val_loss: 0.1929\n",
      "Epoch 354/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1957 - val_loss: 0.1930\n",
      "Epoch 355/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1950 - val_loss: 0.1913\n",
      "Epoch 356/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1953 - val_loss: 0.1947\n",
      "Epoch 357/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1952 - val_loss: 0.1913\n",
      "Epoch 358/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1943 - val_loss: 0.1922\n",
      "Epoch 359/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1945 - val_loss: 0.1900\n",
      "Epoch 360/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1943 - val_loss: 0.1912\n",
      "Epoch 361/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1934 - val_loss: 0.1907\n",
      "Epoch 362/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1932 - val_loss: 0.1912\n",
      "Epoch 363/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1945 - val_loss: 0.1886\n",
      "Epoch 364/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1934 - val_loss: 0.1907\n",
      "Epoch 365/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1927 - val_loss: 0.1895\n",
      "Epoch 366/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1923 - val_loss: 0.1888\n",
      "Epoch 367/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1920 - val_loss: 0.1891\n",
      "Epoch 368/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1929 - val_loss: 0.1884\n",
      "Epoch 369/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1927 - val_loss: 0.1902\n",
      "Epoch 370/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1923 - val_loss: 0.1887\n",
      "Epoch 371/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1920 - val_loss: 0.1870\n",
      "Epoch 372/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1917 - val_loss: 0.1909\n",
      "Epoch 373/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1909 - val_loss: 0.1868\n",
      "Epoch 374/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1913 - val_loss: 0.1890\n",
      "Epoch 375/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1915 - val_loss: 0.1863\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1903 - val_loss: 0.1886\n",
      "Epoch 377/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1907 - val_loss: 0.1864\n",
      "Epoch 378/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1903 - val_loss: 0.1863\n",
      "Epoch 379/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1898 - val_loss: 0.1877\n",
      "Epoch 380/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1903 - val_loss: 0.1848\n",
      "Epoch 381/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1908 - val_loss: 0.1890\n",
      "Epoch 382/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1899 - val_loss: 0.1852\n",
      "Epoch 383/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1908 - val_loss: 0.1878\n",
      "Epoch 384/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1896 - val_loss: 0.1860\n",
      "Epoch 385/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1894 - val_loss: 0.1859\n",
      "Epoch 386/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1894 - val_loss: 0.1867\n",
      "Epoch 387/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1891 - val_loss: 0.1851\n",
      "Epoch 388/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1897 - val_loss: 0.1842\n",
      "Epoch 389/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1883 - val_loss: 0.1864\n",
      "Epoch 390/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1886 - val_loss: 0.1827\n",
      "Epoch 391/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1894 - val_loss: 0.1854\n",
      "Epoch 392/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1885 - val_loss: 0.1847\n",
      "Epoch 393/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1878 - val_loss: 0.1843\n",
      "Epoch 394/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1888 - val_loss: 0.1827\n",
      "Epoch 395/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1886 - val_loss: 0.1879\n",
      "Epoch 396/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1889 - val_loss: 0.1830\n",
      "Epoch 397/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1877 - val_loss: 0.1845\n",
      "Epoch 398/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1878 - val_loss: 0.1831\n",
      "Epoch 399/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1870 - val_loss: 0.1836\n",
      "Epoch 400/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1876 - val_loss: 0.1842\n",
      "Epoch 401/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1875 - val_loss: 0.1842\n",
      "Epoch 402/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1882 - val_loss: 0.1804\n",
      "Epoch 403/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1879 - val_loss: 0.1834\n",
      "Epoch 404/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1862 - val_loss: 0.1817\n",
      "Epoch 405/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1862 - val_loss: 0.1830\n",
      "Epoch 406/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1860 - val_loss: 0.1814\n",
      "Epoch 407/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1859 - val_loss: 0.1818\n",
      "Epoch 408/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1861 - val_loss: 0.1803\n",
      "Epoch 409/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1860 - val_loss: 0.1806\n",
      "Epoch 410/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1855 - val_loss: 0.1816\n",
      "Epoch 411/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1860 - val_loss: 0.1803\n",
      "Epoch 412/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1863 - val_loss: 0.1833\n",
      "Epoch 413/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1860 - val_loss: 0.1797\n",
      "Epoch 414/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1871 - val_loss: 0.1803\n",
      "Epoch 415/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1865 - val_loss: 0.1835\n",
      "Epoch 416/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1852 - val_loss: 0.1794\n",
      "Epoch 417/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1859 - val_loss: 0.1826\n",
      "Epoch 418/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1848 - val_loss: 0.1795\n",
      "Epoch 419/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1845 - val_loss: 0.1796\n",
      "Epoch 420/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1854 - val_loss: 0.1806\n",
      "Epoch 421/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1847 - val_loss: 0.1780\n",
      "Epoch 422/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1843 - val_loss: 0.1819\n",
      "Epoch 423/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1837 - val_loss: 0.1789\n",
      "Epoch 424/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1840 - val_loss: 0.1803\n",
      "Epoch 425/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1840 - val_loss: 0.1770\n",
      "Epoch 426/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1839 - val_loss: 0.1825\n",
      "Epoch 427/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1847 - val_loss: 0.1771\n",
      "Epoch 428/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1839 - val_loss: 0.1788\n",
      "Epoch 429/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1838 - val_loss: 0.1781\n",
      "Epoch 430/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1830 - val_loss: 0.1769\n",
      "Epoch 431/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1829 - val_loss: 0.1783\n",
      "Epoch 432/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1829 - val_loss: 0.1765\n",
      "Epoch 433/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1829 - val_loss: 0.1765\n",
      "Epoch 434/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1823 - val_loss: 0.1776\n",
      "Epoch 435/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1820 - val_loss: 0.1780\n",
      "Epoch 436/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1818 - val_loss: 0.1759\n",
      "Epoch 437/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1821 - val_loss: 0.1782\n",
      "Epoch 438/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1822 - val_loss: 0.1760\n",
      "Epoch 439/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1812 - val_loss: 0.1776\n",
      "Epoch 440/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1827 - val_loss: 0.1753\n",
      "Epoch 441/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1821 - val_loss: 0.1763\n",
      "Epoch 442/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1818 - val_loss: 0.1752\n",
      "Epoch 443/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1811 - val_loss: 0.1761\n",
      "Epoch 444/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1814 - val_loss: 0.1767\n",
      "Epoch 445/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1808 - val_loss: 0.1747\n",
      "Epoch 446/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1826 - val_loss: 0.1787\n",
      "Epoch 447/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1817 - val_loss: 0.1740\n",
      "Epoch 448/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1813 - val_loss: 0.1761\n",
      "Epoch 449/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1805 - val_loss: 0.1735\n",
      "Epoch 450/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1801 - val_loss: 0.1745\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1800 - val_loss: 0.1754\n",
      "Epoch 452/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1808 - val_loss: 0.1751\n",
      "Epoch 453/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1806 - val_loss: 0.1736\n",
      "Epoch 454/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1811 - val_loss: 0.1757\n",
      "Epoch 455/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1799 - val_loss: 0.1739\n",
      "Epoch 456/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1797 - val_loss: 0.1734\n",
      "Epoch 457/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1807 - val_loss: 0.1774\n",
      "Epoch 458/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1806 - val_loss: 0.1733\n",
      "Epoch 459/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1788 - val_loss: 0.1736\n",
      "Epoch 460/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1792 - val_loss: 0.1737\n",
      "Epoch 461/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1785 - val_loss: 0.1723\n",
      "Epoch 462/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1789 - val_loss: 0.1757\n",
      "Epoch 463/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1792 - val_loss: 0.1719\n",
      "Epoch 464/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1790 - val_loss: 0.1706\n",
      "Epoch 465/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1788 - val_loss: 0.1756\n",
      "Epoch 466/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1790 - val_loss: 0.1721\n",
      "Epoch 467/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1800 - val_loss: 0.1756\n",
      "Epoch 468/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1786 - val_loss: 0.1708\n",
      "Epoch 469/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1787 - val_loss: 0.1726\n",
      "Epoch 470/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1776 - val_loss: 0.1716\n",
      "Epoch 471/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1777 - val_loss: 0.1706\n",
      "Epoch 472/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1780 - val_loss: 0.1715\n",
      "Epoch 473/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1774 - val_loss: 0.1705\n",
      "Epoch 474/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1773 - val_loss: 0.1737\n",
      "Epoch 475/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1786 - val_loss: 0.1711\n",
      "Epoch 476/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1791 - val_loss: 0.1697\n",
      "Epoch 477/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1801 - val_loss: 0.1743\n",
      "Epoch 478/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1773 - val_loss: 0.1694\n",
      "Epoch 479/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1766 - val_loss: 0.1717\n",
      "Epoch 480/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1767 - val_loss: 0.1712\n",
      "Epoch 481/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1769 - val_loss: 0.1713\n",
      "Epoch 482/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1768 - val_loss: 0.1693\n",
      "Epoch 483/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1765 - val_loss: 0.1700\n",
      "Epoch 484/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1767 - val_loss: 0.1681\n",
      "Epoch 485/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1771 - val_loss: 0.1706\n",
      "Epoch 486/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1761 - val_loss: 0.1703\n",
      "Epoch 487/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1755 - val_loss: 0.1702\n",
      "Epoch 488/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1762 - val_loss: 0.1687\n",
      "Epoch 489/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1759 - val_loss: 0.1690\n",
      "Epoch 490/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1755 - val_loss: 0.1680\n",
      "Epoch 491/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1754 - val_loss: 0.1676\n",
      "Epoch 492/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1768 - val_loss: 0.1733\n",
      "Epoch 493/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1774 - val_loss: 0.1690\n",
      "Epoch 494/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1765 - val_loss: 0.1673\n",
      "Epoch 495/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1755 - val_loss: 0.1697\n",
      "Epoch 496/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1754 - val_loss: 0.1695\n",
      "Epoch 497/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1755 - val_loss: 0.1683\n",
      "Epoch 498/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1758 - val_loss: 0.1686\n",
      "Epoch 499/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1749 - val_loss: 0.1688\n",
      "Epoch 500/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1745 - val_loss: 0.1667\n",
      "Epoch 501/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1754 - val_loss: 0.1675\n",
      "Epoch 502/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1745 - val_loss: 0.1670\n",
      "Epoch 503/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1750 - val_loss: 0.1686\n",
      "Epoch 504/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1746 - val_loss: 0.1698\n",
      "Epoch 505/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1738 - val_loss: 0.1668\n",
      "Epoch 506/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1743 - val_loss: 0.1660\n",
      "Epoch 507/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1746 - val_loss: 0.1671\n",
      "Epoch 508/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1743 - val_loss: 0.1669\n",
      "Epoch 509/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1740 - val_loss: 0.1664\n",
      "Epoch 510/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1734 - val_loss: 0.1666\n",
      "Epoch 511/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1736 - val_loss: 0.1670\n",
      "Epoch 512/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1736 - val_loss: 0.1658\n",
      "Epoch 513/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1733 - val_loss: 0.1662\n",
      "Epoch 514/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1735 - val_loss: 0.1661\n",
      "Epoch 515/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1730 - val_loss: 0.1658\n",
      "Epoch 516/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1730 - val_loss: 0.1657\n",
      "Epoch 517/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1730 - val_loss: 0.1660\n",
      "Epoch 518/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1728 - val_loss: 0.1660\n",
      "Epoch 519/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1730 - val_loss: 0.1649\n",
      "Epoch 520/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1721 - val_loss: 0.1680\n",
      "Epoch 521/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1728 - val_loss: 0.1647\n",
      "Epoch 522/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1727 - val_loss: 0.1648\n",
      "Epoch 523/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1738 - val_loss: 0.1665\n",
      "Epoch 524/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1720 - val_loss: 0.1640\n",
      "Epoch 525/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.1726 - val_loss: 0.1641\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1743 - val_loss: 0.1686\n",
      "Epoch 527/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1730 - val_loss: 0.1649\n",
      "Epoch 528/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1724 - val_loss: 0.1658\n",
      "Epoch 529/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1721 - val_loss: 0.1641\n",
      "Epoch 530/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1716 - val_loss: 0.1638\n",
      "Epoch 531/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1715 - val_loss: 0.1643\n",
      "Epoch 532/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1719 - val_loss: 0.1635\n",
      "Epoch 533/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1723 - val_loss: 0.1664\n",
      "Epoch 534/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1714 - val_loss: 0.1630\n",
      "Epoch 535/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1715 - val_loss: 0.1658\n",
      "Epoch 536/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1713 - val_loss: 0.1625\n",
      "Epoch 537/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1716 - val_loss: 0.1653\n",
      "Epoch 538/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1743 - val_loss: 0.1677\n",
      "Epoch 539/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1722 - val_loss: 0.1624\n",
      "Epoch 540/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1707 - val_loss: 0.1627\n",
      "Epoch 541/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1711 - val_loss: 0.1634\n",
      "Epoch 542/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1700 - val_loss: 0.1628\n",
      "Epoch 543/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1701 - val_loss: 0.1619\n",
      "Epoch 544/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1701 - val_loss: 0.1628\n",
      "Epoch 545/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1700 - val_loss: 0.1627\n",
      "Epoch 546/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1710 - val_loss: 0.1622\n",
      "Epoch 547/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1713 - val_loss: 0.1620\n",
      "Epoch 548/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1699 - val_loss: 0.1638\n",
      "Epoch 549/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1708 - val_loss: 0.1616\n",
      "Epoch 550/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1706 - val_loss: 0.1649\n",
      "Epoch 551/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1717 - val_loss: 0.1623\n",
      "Epoch 552/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1697 - val_loss: 0.1621\n",
      "Epoch 553/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1691 - val_loss: 0.1613\n",
      "Epoch 554/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1690 - val_loss: 0.1628\n",
      "Epoch 555/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1693 - val_loss: 0.1620\n",
      "Epoch 556/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1692 - val_loss: 0.1606\n",
      "Epoch 557/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1693 - val_loss: 0.1636\n",
      "Epoch 558/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1699 - val_loss: 0.1600\n",
      "Epoch 559/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1690 - val_loss: 0.1648\n",
      "Epoch 560/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1690 - val_loss: 0.1603\n",
      "Epoch 561/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1691 - val_loss: 0.1635\n",
      "Epoch 562/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1694 - val_loss: 0.1595\n",
      "Epoch 563/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1690 - val_loss: 0.1646\n",
      "Epoch 564/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1681 - val_loss: 0.1602\n",
      "Epoch 565/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1683 - val_loss: 0.1606\n",
      "Epoch 566/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1679 - val_loss: 0.1602\n",
      "Epoch 567/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1680 - val_loss: 0.1602\n",
      "Epoch 568/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1680 - val_loss: 0.1624\n",
      "Epoch 569/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1688 - val_loss: 0.1602\n",
      "Epoch 570/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1692 - val_loss: 0.1596\n",
      "Epoch 571/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1693 - val_loss: 0.1605\n",
      "Epoch 572/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1680 - val_loss: 0.1602\n",
      "Epoch 573/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1673 - val_loss: 0.1607\n",
      "Epoch 574/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1677 - val_loss: 0.1597\n",
      "Epoch 575/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1673 - val_loss: 0.1602\n",
      "Epoch 576/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1686 - val_loss: 0.1590\n",
      "Epoch 577/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1673 - val_loss: 0.1610\n",
      "Epoch 578/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1682 - val_loss: 0.1582\n",
      "Epoch 579/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1679 - val_loss: 0.1603\n",
      "Epoch 580/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1670 - val_loss: 0.1593\n",
      "Epoch 581/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1671 - val_loss: 0.1615\n",
      "Epoch 582/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1669 - val_loss: 0.1601\n",
      "Epoch 583/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1671 - val_loss: 0.1591\n",
      "Epoch 584/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1668 - val_loss: 0.1586\n",
      "Epoch 585/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1660 - val_loss: 0.1593\n",
      "Epoch 586/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1662 - val_loss: 0.1586\n",
      "Epoch 587/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1668 - val_loss: 0.1584\n",
      "Epoch 588/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1659 - val_loss: 0.1589\n",
      "Epoch 589/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.1663 - val_loss: 0.1580\n",
      "Epoch 590/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1660 - val_loss: 0.1592\n",
      "Epoch 591/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1657 - val_loss: 0.1588\n",
      "Epoch 592/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1655 - val_loss: 0.1596\n",
      "Epoch 593/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1652 - val_loss: 0.1598\n",
      "Epoch 594/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1655 - val_loss: 0.1576\n",
      "Epoch 595/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1657 - val_loss: 0.1587\n",
      "Epoch 596/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1650 - val_loss: 0.1578\n",
      "Epoch 597/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1659 - val_loss: 0.1604\n",
      "Epoch 598/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1656 - val_loss: 0.1567\n",
      "Epoch 599/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1649 - val_loss: 0.1589\n",
      "Epoch 600/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1651 - val_loss: 0.1585\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1648 - val_loss: 0.1587\n",
      "Epoch 602/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1649 - val_loss: 0.1569\n",
      "Epoch 603/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1645 - val_loss: 0.1582\n",
      "Epoch 604/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1649 - val_loss: 0.1592\n",
      "Epoch 605/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1665 - val_loss: 0.1572\n",
      "Epoch 606/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1656 - val_loss: 0.1572\n",
      "Epoch 607/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1645 - val_loss: 0.1571\n",
      "Epoch 608/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1641 - val_loss: 0.1570\n",
      "Epoch 609/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1641 - val_loss: 0.1572\n",
      "Epoch 610/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1633 - val_loss: 0.1580\n",
      "Epoch 611/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1641 - val_loss: 0.1566\n",
      "Epoch 612/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1637 - val_loss: 0.1581\n",
      "Epoch 613/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1632 - val_loss: 0.1565\n",
      "Epoch 614/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1639 - val_loss: 0.1566\n",
      "Epoch 615/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1644 - val_loss: 0.1582\n",
      "Epoch 616/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1641 - val_loss: 0.1560\n",
      "Epoch 617/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1633 - val_loss: 0.1583\n",
      "Epoch 618/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1647 - val_loss: 0.1559\n",
      "Epoch 619/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1627 - val_loss: 0.1602\n",
      "Epoch 620/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1649 - val_loss: 0.1560\n",
      "Epoch 621/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1634 - val_loss: 0.1589\n",
      "Epoch 622/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1646 - val_loss: 0.1586\n",
      "Epoch 623/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1637 - val_loss: 0.1548\n",
      "Epoch 624/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1630 - val_loss: 0.1578\n",
      "Epoch 625/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1628 - val_loss: 0.1553\n",
      "Epoch 626/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1636 - val_loss: 0.1552\n",
      "Epoch 627/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1620 - val_loss: 0.1573\n",
      "Epoch 628/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1634 - val_loss: 0.1576\n",
      "Epoch 629/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1624 - val_loss: 0.1570\n",
      "Epoch 630/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1628 - val_loss: 0.1567\n",
      "Epoch 631/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1624 - val_loss: 0.1571\n",
      "Epoch 632/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1622 - val_loss: 0.1562\n",
      "Epoch 633/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1622 - val_loss: 0.1560\n",
      "Epoch 634/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1623 - val_loss: 0.1547\n",
      "Epoch 635/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1639 - val_loss: 0.1591\n",
      "Epoch 636/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1611 - val_loss: 0.1558\n",
      "Epoch 637/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1641 - val_loss: 0.1580\n",
      "Epoch 638/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1631 - val_loss: 0.1556\n",
      "Epoch 639/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1617 - val_loss: 0.1557\n",
      "Epoch 640/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1609 - val_loss: 0.1547\n",
      "Epoch 641/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1617 - val_loss: 0.1577\n",
      "Epoch 642/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1609 - val_loss: 0.1547\n",
      "Epoch 643/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1611 - val_loss: 0.1554\n",
      "Epoch 644/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1622 - val_loss: 0.1542\n",
      "Epoch 645/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1616 - val_loss: 0.1590\n",
      "Epoch 646/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1602 - val_loss: 0.1542\n",
      "Epoch 647/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1609 - val_loss: 0.1580\n",
      "Epoch 648/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1618 - val_loss: 0.1540\n",
      "Epoch 649/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1617 - val_loss: 0.1542\n",
      "Epoch 650/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1612 - val_loss: 0.1549\n",
      "Epoch 651/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1598 - val_loss: 0.1544\n",
      "Epoch 652/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1596 - val_loss: 0.1565\n",
      "Epoch 653/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1610 - val_loss: 0.1530\n",
      "Epoch 654/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1597 - val_loss: 0.1554\n",
      "Epoch 655/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1595 - val_loss: 0.1547\n",
      "Epoch 656/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1599 - val_loss: 0.1550\n",
      "Epoch 657/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1592 - val_loss: 0.1533\n",
      "Epoch 658/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1594 - val_loss: 0.1540\n",
      "Epoch 659/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1598 - val_loss: 0.1560\n",
      "Epoch 660/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1605 - val_loss: 0.1526\n",
      "Epoch 661/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1599 - val_loss: 0.1561\n",
      "Epoch 662/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1590 - val_loss: 0.1531\n",
      "Epoch 663/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1604 - val_loss: 0.1541\n",
      "Epoch 664/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1590 - val_loss: 0.1536\n",
      "Epoch 665/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1590 - val_loss: 0.1525\n",
      "Epoch 666/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1589 - val_loss: 0.1525\n",
      "Epoch 667/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1601 - val_loss: 0.1555\n",
      "Epoch 668/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1587 - val_loss: 0.1536\n",
      "Epoch 669/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1587 - val_loss: 0.1530\n",
      "Epoch 670/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1593 - val_loss: 0.1530\n",
      "Epoch 671/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1584 - val_loss: 0.1533\n",
      "Epoch 672/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1587 - val_loss: 0.1535\n",
      "Epoch 673/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1580 - val_loss: 0.1541\n",
      "Epoch 674/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1578 - val_loss: 0.1525\n",
      "Epoch 675/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1582 - val_loss: 0.1530\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1575 - val_loss: 0.1536\n",
      "Epoch 677/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1573 - val_loss: 0.1530\n",
      "Epoch 678/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1579 - val_loss: 0.1525\n",
      "Epoch 679/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1578 - val_loss: 0.1524\n",
      "Epoch 680/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1578 - val_loss: 0.1523\n",
      "Epoch 681/1000\n",
      "1791/1791 [==============================] - 0s 19us/sample - loss: 0.1571 - val_loss: 0.1519\n",
      "Epoch 682/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1571 - val_loss: 0.1548\n",
      "Epoch 683/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1589 - val_loss: 0.1516\n",
      "Epoch 684/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1582 - val_loss: 0.1582\n",
      "Epoch 685/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1568 - val_loss: 0.1517\n",
      "Epoch 686/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1586 - val_loss: 0.1583\n",
      "Epoch 687/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1588 - val_loss: 0.1508\n",
      "Epoch 688/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1564 - val_loss: 0.1541\n",
      "Epoch 689/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1577 - val_loss: 0.1543\n",
      "Epoch 690/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1565 - val_loss: 0.1510\n",
      "Epoch 691/1000\n",
      "1791/1791 [==============================] - 0s 20us/sample - loss: 0.1560 - val_loss: 0.1511\n",
      "Epoch 692/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1559 - val_loss: 0.1516\n",
      "Epoch 693/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1563 - val_loss: 0.1551\n",
      "Epoch 694/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1571 - val_loss: 0.1507\n",
      "Epoch 695/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1571 - val_loss: 0.1548\n",
      "Epoch 696/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1559 - val_loss: 0.1525\n",
      "Epoch 697/1000\n",
      "1791/1791 [==============================] - 0s 52us/sample - loss: 0.1553 - val_loss: 0.1514\n",
      "Epoch 698/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1560 - val_loss: 0.1502\n",
      "Epoch 699/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1552 - val_loss: 0.1515\n",
      "Epoch 700/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1551 - val_loss: 0.1549\n",
      "Epoch 701/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1553 - val_loss: 0.1507\n",
      "Epoch 702/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1555 - val_loss: 0.1507\n",
      "Epoch 703/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1555 - val_loss: 0.1529\n",
      "Epoch 704/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1545 - val_loss: 0.1523\n",
      "Epoch 705/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1543 - val_loss: 0.1505\n",
      "Epoch 706/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1542 - val_loss: 0.1533\n",
      "Epoch 707/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1544 - val_loss: 0.1513\n",
      "Epoch 708/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1546 - val_loss: 0.1505\n",
      "Epoch 709/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1545 - val_loss: 0.1515\n",
      "Epoch 710/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1535 - val_loss: 0.1504\n",
      "Epoch 711/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1543 - val_loss: 0.1553\n",
      "Epoch 712/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1540 - val_loss: 0.1512\n",
      "Epoch 713/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1535 - val_loss: 0.1524\n",
      "Epoch 714/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1533 - val_loss: 0.1493\n",
      "Epoch 715/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.114 - 0s 27us/sample - loss: 0.1538 - val_loss: 0.1512\n",
      "Epoch 716/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1537 - val_loss: 0.1528\n",
      "Epoch 717/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1530 - val_loss: 0.1504\n",
      "Epoch 718/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1529 - val_loss: 0.1518\n",
      "Epoch 719/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1536 - val_loss: 0.1500\n",
      "Epoch 720/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1525 - val_loss: 0.1525\n",
      "Epoch 721/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1532 - val_loss: 0.1524\n",
      "Epoch 722/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1523 - val_loss: 0.1502\n",
      "Epoch 723/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1532 - val_loss: 0.1510\n",
      "Epoch 724/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1524 - val_loss: 0.1512\n",
      "Epoch 725/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1525 - val_loss: 0.1498\n",
      "Epoch 726/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1537 - val_loss: 0.1511\n",
      "Epoch 727/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1522 - val_loss: 0.1498\n",
      "Epoch 728/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1532 - val_loss: 0.1524\n",
      "Epoch 729/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1519 - val_loss: 0.1501\n",
      "Epoch 730/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1518 - val_loss: 0.1498\n",
      "Epoch 731/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1521 - val_loss: 0.1501\n",
      "Epoch 732/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1522 - val_loss: 0.1491\n",
      "Epoch 733/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1517 - val_loss: 0.1496\n",
      "Epoch 734/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1517 - val_loss: 0.1501\n",
      "Epoch 735/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1517 - val_loss: 0.1503\n",
      "Epoch 736/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1514 - val_loss: 0.1495\n",
      "Epoch 737/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1520 - val_loss: 0.1502\n",
      "Epoch 738/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1516 - val_loss: 0.1511\n",
      "Epoch 739/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1523 - val_loss: 0.1498\n",
      "Epoch 740/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1516 - val_loss: 0.1484\n",
      "Epoch 741/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1539 - val_loss: 0.1586\n",
      "Epoch 742/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1521 - val_loss: 0.1489\n",
      "Epoch 743/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 744/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1515 - val_loss: 0.1479\n",
      "Epoch 745/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1508 - val_loss: 0.1494\n",
      "Epoch 746/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1506 - val_loss: 0.1511\n",
      "Epoch 747/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1507 - val_loss: 0.1504\n",
      "Epoch 748/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1507 - val_loss: 0.1493\n",
      "Epoch 749/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1508 - val_loss: 0.1505\n",
      "Epoch 750/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1522 - val_loss: 0.1491\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1509 - val_loss: 0.1506\n",
      "Epoch 752/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1499 - val_loss: 0.1482\n",
      "Epoch 753/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1497 - val_loss: 0.1485\n",
      "Epoch 754/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1498 - val_loss: 0.1510\n",
      "Epoch 755/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1505 - val_loss: 0.1491\n",
      "Epoch 756/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1496 - val_loss: 0.1494\n",
      "Epoch 757/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1495 - val_loss: 0.1487\n",
      "Epoch 758/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1505 - val_loss: 0.1499\n",
      "Epoch 759/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1506 - val_loss: 0.1507\n",
      "Epoch 760/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1500 - val_loss: 0.1476\n",
      "Epoch 761/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1491 - val_loss: 0.1499\n",
      "Epoch 762/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1496 - val_loss: 0.1482\n",
      "Epoch 763/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1497 - val_loss: 0.1475\n",
      "Epoch 764/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1505 - val_loss: 0.1479\n",
      "Epoch 765/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1493 - val_loss: 0.1503\n",
      "Epoch 766/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1498 - val_loss: 0.1475\n",
      "Epoch 767/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1489 - val_loss: 0.1522\n",
      "Epoch 768/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1490 - val_loss: 0.1484\n",
      "Epoch 769/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1489 - val_loss: 0.1492\n",
      "Epoch 770/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1485 - val_loss: 0.1478\n",
      "Epoch 771/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1489 - val_loss: 0.1507\n",
      "Epoch 772/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1491 - val_loss: 0.1476\n",
      "Epoch 773/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1514 - val_loss: 0.1564\n",
      "Epoch 774/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1523 - val_loss: 0.1476\n",
      "Epoch 775/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1498 - val_loss: 0.1484\n",
      "Epoch 776/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1485 - val_loss: 0.1501\n",
      "Epoch 777/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1481 - val_loss: 0.1478\n",
      "Epoch 778/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1480 - val_loss: 0.1484\n",
      "Epoch 779/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1478 - val_loss: 0.1490\n",
      "Epoch 780/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1490 - val_loss: 0.1463\n",
      "Epoch 781/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1482 - val_loss: 0.1495\n",
      "Epoch 782/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1483 - val_loss: 0.1481\n",
      "Epoch 783/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1506 - val_loss: 0.1472\n",
      "Epoch 784/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1495 - val_loss: 0.1554\n",
      "Epoch 785/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1485 - val_loss: 0.1468\n",
      "Epoch 786/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1487 - val_loss: 0.1505\n",
      "Epoch 787/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1466 - val_loss: 0.1463\n",
      "Epoch 788/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1475 - val_loss: 0.1480\n",
      "Epoch 789/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1472 - val_loss: 0.1483\n",
      "Epoch 790/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1489 - val_loss: 0.1529\n",
      "Epoch 791/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1472 - val_loss: 0.1472\n",
      "Epoch 792/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1492 - val_loss: 0.1496\n",
      "Epoch 793/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1471 - val_loss: 0.1468\n",
      "Epoch 794/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1471 - val_loss: 0.1490\n",
      "Epoch 795/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1489 - val_loss: 0.1509\n",
      "Epoch 796/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1478 - val_loss: 0.1485\n",
      "Epoch 797/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1485 - val_loss: 0.1467\n",
      "Epoch 798/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1467 - val_loss: 0.1489\n",
      "Epoch 799/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1472 - val_loss: 0.1474\n",
      "Epoch 800/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1470 - val_loss: 0.1475\n",
      "Epoch 801/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1488 - val_loss: 0.1520\n",
      "Epoch 802/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1478 - val_loss: 0.1478\n",
      "Epoch 803/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1474 - val_loss: 0.1477\n",
      "Epoch 804/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1475 - val_loss: 0.1465\n",
      "Epoch 805/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1466 - val_loss: 0.1491\n",
      "Epoch 806/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1467 - val_loss: 0.1464\n",
      "Epoch 807/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1458 - val_loss: 0.1497\n",
      "Epoch 808/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1464 - val_loss: 0.1471\n",
      "Epoch 809/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1462 - val_loss: 0.1497\n",
      "Epoch 810/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1463 - val_loss: 0.1478\n",
      "Epoch 811/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1462 - val_loss: 0.1475\n",
      "Epoch 812/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1461 - val_loss: 0.1471\n",
      "Epoch 813/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1463 - val_loss: 0.1471\n",
      "Epoch 814/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1455 - val_loss: 0.1473\n",
      "Epoch 815/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1461 - val_loss: 0.1469\n",
      "Epoch 816/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1458 - val_loss: 0.1474\n",
      "Epoch 817/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1459 - val_loss: 0.1490\n",
      "Epoch 818/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1458 - val_loss: 0.1484\n",
      "Epoch 819/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1457 - val_loss: 0.1473\n",
      "Epoch 820/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1454 - val_loss: 0.1483\n",
      "Epoch 821/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1459 - val_loss: 0.1456\n",
      "Epoch 822/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1466 - val_loss: 0.1476\n",
      "Epoch 823/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1456 - val_loss: 0.1490\n",
      "Epoch 824/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1451 - val_loss: 0.1486\n",
      "Epoch 825/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1457 - val_loss: 0.1485\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1462 - val_loss: 0.1477\n",
      "Epoch 827/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1456 - val_loss: 0.1481\n",
      "Epoch 828/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1449 - val_loss: 0.1473\n",
      "Epoch 829/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1447 - val_loss: 0.1482\n",
      "Epoch 830/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1447 - val_loss: 0.1472\n",
      "Epoch 831/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1447 - val_loss: 0.1483\n",
      "Epoch 832/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1445 - val_loss: 0.1462\n",
      "Epoch 833/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1446 - val_loss: 0.1479\n",
      "Epoch 834/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1443 - val_loss: 0.1472\n",
      "Epoch 835/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1446 - val_loss: 0.1471\n",
      "Epoch 836/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1446 - val_loss: 0.1486\n",
      "Epoch 837/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1457 - val_loss: 0.1492\n",
      "Epoch 838/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1449 - val_loss: 0.1460\n",
      "Epoch 839/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1440 - val_loss: 0.1488\n",
      "Epoch 840/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1443 - val_loss: 0.1456\n",
      "Epoch 841/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1469 - val_loss: 0.1517\n",
      "Epoch 842/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1448 - val_loss: 0.1479\n",
      "Epoch 843/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1443 - val_loss: 0.1465\n",
      "Epoch 844/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1451 - val_loss: 0.1472\n",
      "Epoch 845/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1463 - val_loss: 0.1451\n",
      "Epoch 846/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1441 - val_loss: 0.1494\n",
      "Epoch 847/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1455 - val_loss: 0.1456\n",
      "Epoch 848/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1446 - val_loss: 0.1521\n",
      "Epoch 849/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1450 - val_loss: 0.1454\n",
      "Epoch 850/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1440 - val_loss: 0.1493\n",
      "Epoch 851/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1441 - val_loss: 0.1472\n",
      "Epoch 852/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1436 - val_loss: 0.1475\n",
      "Epoch 853/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1440 - val_loss: 0.1481\n",
      "Epoch 854/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1433 - val_loss: 0.1451\n",
      "Epoch 855/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1458 - val_loss: 0.1518\n",
      "Epoch 856/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1443 - val_loss: 0.1448\n",
      "Epoch 857/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1442 - val_loss: 0.1471\n",
      "Epoch 858/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1435 - val_loss: 0.1452\n",
      "Epoch 859/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1439 - val_loss: 0.1518\n",
      "Epoch 860/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1443 - val_loss: 0.1464\n",
      "Epoch 861/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1432 - val_loss: 0.1468\n",
      "Epoch 862/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1438 - val_loss: 0.1456\n",
      "Epoch 863/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1433 - val_loss: 0.1475\n",
      "Epoch 864/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1452 - val_loss: 0.1445\n",
      "Epoch 865/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1432 - val_loss: 0.1488\n",
      "Epoch 866/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1432 - val_loss: 0.1459\n",
      "Epoch 867/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1427 - val_loss: 0.1483\n",
      "Epoch 868/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1436 - val_loss: 0.1450\n",
      "Epoch 869/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1432 - val_loss: 0.1460\n",
      "Epoch 870/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1424 - val_loss: 0.1458\n",
      "Epoch 871/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1427 - val_loss: 0.1471\n",
      "Epoch 872/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1436 - val_loss: 0.1481\n",
      "Epoch 873/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1428 - val_loss: 0.1455\n",
      "Epoch 874/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1424 - val_loss: 0.1459\n",
      "Epoch 875/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1426 - val_loss: 0.1485\n",
      "Epoch 876/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1428 - val_loss: 0.1458\n",
      "Epoch 877/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1426 - val_loss: 0.1456\n",
      "Epoch 878/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1438 - val_loss: 0.1444\n",
      "Epoch 879/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1422 - val_loss: 0.1480\n",
      "Epoch 880/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1428 - val_loss: 0.1474\n",
      "Epoch 881/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1429 - val_loss: 0.1458\n",
      "Epoch 882/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1419 - val_loss: 0.1460\n",
      "Epoch 883/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1424 - val_loss: 0.1453\n",
      "Epoch 884/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1423 - val_loss: 0.1475\n",
      "Epoch 885/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1426 - val_loss: 0.1451\n",
      "Epoch 886/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1426 - val_loss: 0.1441\n",
      "Epoch 887/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1424 - val_loss: 0.1481\n",
      "Epoch 888/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1420 - val_loss: 0.1442\n",
      "Epoch 889/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1419 - val_loss: 0.1524\n",
      "Epoch 890/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1447 - val_loss: 0.1448\n",
      "Epoch 891/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1419 - val_loss: 0.1473\n",
      "Epoch 892/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1424 - val_loss: 0.1474\n",
      "Epoch 893/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1416 - val_loss: 0.1448\n",
      "Epoch 894/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1416 - val_loss: 0.1452\n",
      "Epoch 895/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1422 - val_loss: 0.1459\n",
      "Epoch 896/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1428 - val_loss: 0.1507\n",
      "Epoch 897/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1431 - val_loss: 0.1464\n",
      "Epoch 898/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1437 - val_loss: 0.1454\n",
      "Epoch 899/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1409 - val_loss: 0.1500\n",
      "Epoch 900/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1434 - val_loss: 0.1450\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1437 - val_loss: 0.1537\n",
      "Epoch 902/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1420 - val_loss: 0.1443\n",
      "Epoch 903/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1411 - val_loss: 0.1500\n",
      "Epoch 904/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1408 - val_loss: 0.1445\n",
      "Epoch 905/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1417 - val_loss: 0.1519\n",
      "Epoch 906/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1432 - val_loss: 0.1443\n",
      "Epoch 907/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1418 - val_loss: 0.1459\n",
      "Epoch 908/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1417 - val_loss: 0.1464\n",
      "Epoch 909/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1420 - val_loss: 0.1470\n",
      "Epoch 910/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1404 - val_loss: 0.1440\n",
      "Epoch 911/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1413 - val_loss: 0.1482\n",
      "Epoch 912/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1408 - val_loss: 0.1457\n",
      "Epoch 913/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1406 - val_loss: 0.1450\n",
      "Epoch 914/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1407 - val_loss: 0.1451\n",
      "Epoch 915/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1406 - val_loss: 0.1468\n",
      "Epoch 916/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1423 - val_loss: 0.1438\n",
      "Epoch 917/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1406 - val_loss: 0.1484\n",
      "Epoch 918/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1399 - val_loss: 0.1434\n",
      "Epoch 919/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1413 - val_loss: 0.1474\n",
      "Epoch 920/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1404 - val_loss: 0.1442\n",
      "Epoch 921/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1406 - val_loss: 0.1461\n",
      "Epoch 922/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1403 - val_loss: 0.1456\n",
      "Epoch 923/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1406 - val_loss: 0.1471\n",
      "Epoch 924/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1401 - val_loss: 0.1448\n",
      "Epoch 925/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1398 - val_loss: 0.1464\n",
      "Epoch 926/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1402 - val_loss: 0.1472\n",
      "Epoch 927/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1420 - val_loss: 0.1442\n",
      "Epoch 928/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1394 - val_loss: 0.1491\n",
      "Epoch 929/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1419 - val_loss: 0.1488\n",
      "Epoch 930/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1405 - val_loss: 0.1455\n",
      "Epoch 931/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1406 - val_loss: 0.1435\n",
      "Epoch 932/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1405 - val_loss: 0.1467\n",
      "Epoch 933/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1394 - val_loss: 0.1452\n",
      "Epoch 934/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1394 - val_loss: 0.1464\n",
      "Epoch 935/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1396 - val_loss: 0.1450\n",
      "Epoch 936/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1400 - val_loss: 0.1466\n",
      "Epoch 937/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1404 - val_loss: 0.1445\n",
      "Epoch 938/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1401 - val_loss: 0.1462\n",
      "Epoch 939/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1394 - val_loss: 0.1456\n",
      "Epoch 940/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1391 - val_loss: 0.1466\n",
      "Epoch 941/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1400 - val_loss: 0.1457\n",
      "Epoch 942/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1398 - val_loss: 0.1440\n",
      "Epoch 943/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1400 - val_loss: 0.1449\n",
      "Epoch 944/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1413 - val_loss: 0.1523\n",
      "Epoch 945/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1407 - val_loss: 0.1451\n",
      "Epoch 946/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1413 - val_loss: 0.1450\n",
      "Epoch 947/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1404 - val_loss: 0.1456\n",
      "Epoch 948/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1390 - val_loss: 0.1450\n",
      "Epoch 949/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1394 - val_loss: 0.1465\n",
      "Epoch 950/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1394 - val_loss: 0.1470\n",
      "Epoch 951/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1382 - val_loss: 0.1442\n",
      "Epoch 952/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1391 - val_loss: 0.1523\n",
      "Epoch 953/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1422 - val_loss: 0.1450\n",
      "Epoch 954/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1390 - val_loss: 0.1456\n",
      "Epoch 955/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1391 - val_loss: 0.1443\n",
      "Epoch 956/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1392 - val_loss: 0.1467\n",
      "Epoch 957/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1397 - val_loss: 0.1442\n",
      "Epoch 958/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1405 - val_loss: 0.1460\n",
      "Epoch 959/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1389 - val_loss: 0.1460\n",
      "Epoch 960/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1385 - val_loss: 0.1454\n",
      "Epoch 961/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1381 - val_loss: 0.1468\n",
      "Epoch 962/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1383 - val_loss: 0.1451\n",
      "Epoch 963/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1381 - val_loss: 0.1464\n",
      "Epoch 964/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1386 - val_loss: 0.1462\n",
      "Epoch 965/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1380 - val_loss: 0.1444\n",
      "Epoch 966/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1384 - val_loss: 0.1513\n",
      "Epoch 967/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1396 - val_loss: 0.1437\n",
      "Epoch 968/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1381 - val_loss: 0.1462\n",
      "Epoch 969/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1378 - val_loss: 0.1455\n",
      "Epoch 970/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1382 - val_loss: 0.1457\n",
      "Epoch 971/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1384 - val_loss: 0.1459\n",
      "Epoch 972/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1380 - val_loss: 0.1468\n",
      "Epoch 973/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1395 - val_loss: 0.1459\n",
      "Epoch 974/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1414 - val_loss: 0.1431\n",
      "Epoch 975/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1412 - val_loss: 0.1498\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1388 - val_loss: 0.1448\n",
      "Epoch 977/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1383 - val_loss: 0.1437\n",
      "Epoch 978/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1383 - val_loss: 0.1450\n",
      "Epoch 979/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1386 - val_loss: 0.1448\n",
      "Epoch 980/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1376 - val_loss: 0.1457\n",
      "Epoch 981/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1374 - val_loss: 0.1440\n",
      "Epoch 982/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1376 - val_loss: 0.1456\n",
      "Epoch 983/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1380 - val_loss: 0.1455\n",
      "Epoch 984/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1378 - val_loss: 0.1460\n",
      "Epoch 985/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1386 - val_loss: 0.1479\n",
      "Epoch 986/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1378 - val_loss: 0.1432\n",
      "Epoch 987/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1380 - val_loss: 0.1467\n",
      "Epoch 988/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1371 - val_loss: 0.1442\n",
      "Epoch 989/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1386 - val_loss: 0.1471\n",
      "Epoch 990/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1371 - val_loss: 0.1446\n",
      "Epoch 991/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1370 - val_loss: 0.1453\n",
      "Epoch 992/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1368 - val_loss: 0.1478\n",
      "Epoch 993/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1372 - val_loss: 0.1435\n",
      "Epoch 994/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1380 - val_loss: 0.1480\n",
      "Epoch 995/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1377 - val_loss: 0.1429\n",
      "Epoch 996/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1364 - val_loss: 0.1490\n",
      "Epoch 997/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1412 - val_loss: 0.1431\n",
      "Epoch 998/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1383 - val_loss: 0.1455\n",
      "Epoch 999/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1368 - val_loss: 0.1460\n",
      "Epoch 1000/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1377 - val_loss: 0.1432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215103534c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=1000,validation_data=(X_test,y_test),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.691628</td>\n",
       "      <td>0.682584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669787</td>\n",
       "      <td>0.665394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.653566</td>\n",
       "      <td>0.649646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.637872</td>\n",
       "      <td>0.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.621924</td>\n",
       "      <td>0.616128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.136354</td>\n",
       "      <td>0.149050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.141163</td>\n",
       "      <td>0.143070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.138270</td>\n",
       "      <td>0.145497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.136764</td>\n",
       "      <td>0.146046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.137662</td>\n",
       "      <td>0.143180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.691628  0.682584\n",
       "1    0.669787  0.665394\n",
       "2    0.653566  0.649646\n",
       "3    0.637872  0.633500\n",
       "4    0.621924  0.616128\n",
       "..        ...       ...\n",
       "995  0.136354  0.149050\n",
       "996  0.141163  0.143070\n",
       "997  0.138270  0.145497\n",
       "998  0.136764  0.146046\n",
       "999  0.137662  0.143180\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21510353708>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9,activation='relu',input_shape=(9, )))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1791 samples, validate on 597 samples\n",
      "Epoch 1/1000\n",
      "1791/1791 [==============================] - 1s 407us/sample - loss: 0.9421 - val_loss: 0.8957\n",
      "Epoch 2/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.8887 - val_loss: 0.8502\n",
      "Epoch 3/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.8410 - val_loss: 0.8047\n",
      "Epoch 4/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.7936 - val_loss: 0.7586\n",
      "Epoch 5/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.7493 - val_loss: 0.7184\n",
      "Epoch 6/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.752 - 0s 31us/sample - loss: 0.7100 - val_loss: 0.6832\n",
      "Epoch 7/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.6760 - val_loss: 0.6510\n",
      "Epoch 8/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.6455 - val_loss: 0.6202\n",
      "Epoch 9/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.6158 - val_loss: 0.5922\n",
      "Epoch 10/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.5918 - val_loss: 0.5697\n",
      "Epoch 11/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.5728 - val_loss: 0.5506\n",
      "Epoch 12/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.5562 - val_loss: 0.5350\n",
      "Epoch 13/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.5420 - val_loss: 0.5212\n",
      "Epoch 14/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.5284 - val_loss: 0.5072\n",
      "Epoch 15/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.5161 - val_loss: 0.4955\n",
      "Epoch 16/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.5063 - val_loss: 0.4857\n",
      "Epoch 17/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4975 - val_loss: 0.4779\n",
      "Epoch 18/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4905 - val_loss: 0.4700\n",
      "Epoch 19/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4831 - val_loss: 0.4623\n",
      "Epoch 20/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.4749 - val_loss: 0.4538\n",
      "Epoch 21/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.4681 - val_loss: 0.4474\n",
      "Epoch 22/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4622 - val_loss: 0.4418\n",
      "Epoch 23/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4569 - val_loss: 0.4367\n",
      "Epoch 24/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4520 - val_loss: 0.4318\n",
      "Epoch 25/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4469 - val_loss: 0.4260\n",
      "Epoch 26/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4414 - val_loss: 0.4211\n",
      "Epoch 27/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4358 - val_loss: 0.4155\n",
      "Epoch 28/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4298 - val_loss: 0.4105\n",
      "Epoch 29/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4239 - val_loss: 0.4041\n",
      "Epoch 30/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4179 - val_loss: 0.3993\n",
      "Epoch 31/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4123 - val_loss: 0.3934\n",
      "Epoch 32/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.4061 - val_loss: 0.3877\n",
      "Epoch 33/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.4002 - val_loss: 0.3821\n",
      "Epoch 34/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3936 - val_loss: 0.3763\n",
      "Epoch 35/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3886 - val_loss: 0.3715\n",
      "Epoch 36/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3834 - val_loss: 0.3682\n",
      "Epoch 37/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3780 - val_loss: 0.3629\n",
      "Epoch 38/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3735 - val_loss: 0.3588\n",
      "Epoch 39/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3695 - val_loss: 0.3549\n",
      "Epoch 40/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3653 - val_loss: 0.3506\n",
      "Epoch 41/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3615 - val_loss: 0.3468\n",
      "Epoch 42/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3576 - val_loss: 0.3435\n",
      "Epoch 43/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3531 - val_loss: 0.3392\n",
      "Epoch 44/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3494 - val_loss: 0.3359\n",
      "Epoch 45/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3460 - val_loss: 0.3330\n",
      "Epoch 46/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3425 - val_loss: 0.3304\n",
      "Epoch 47/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3398 - val_loss: 0.3297\n",
      "Epoch 48/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3366 - val_loss: 0.3260\n",
      "Epoch 49/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3341 - val_loss: 0.3232\n",
      "Epoch 50/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3330 - val_loss: 0.3235\n",
      "Epoch 51/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3311 - val_loss: 0.3200\n",
      "Epoch 52/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3280 - val_loss: 0.3188\n",
      "Epoch 53/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3259 - val_loss: 0.3168\n",
      "Epoch 54/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3234 - val_loss: 0.3152\n",
      "Epoch 55/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3218 - val_loss: 0.3135\n",
      "Epoch 56/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3200 - val_loss: 0.3133\n",
      "Epoch 57/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3185 - val_loss: 0.3109\n",
      "Epoch 58/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3171 - val_loss: 0.3108\n",
      "Epoch 59/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3153 - val_loss: 0.3081\n",
      "Epoch 60/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3140 - val_loss: 0.3083\n",
      "Epoch 61/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3127 - val_loss: 0.3085\n",
      "Epoch 62/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3117 - val_loss: 0.3042\n",
      "Epoch 63/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3108 - val_loss: 0.3048\n",
      "Epoch 64/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3105 - val_loss: 0.3055\n",
      "Epoch 65/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3082 - val_loss: 0.3044\n",
      "Epoch 66/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3067 - val_loss: 0.3010\n",
      "Epoch 67/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3063 - val_loss: 0.3023\n",
      "Epoch 68/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3052 - val_loss: 0.3018\n",
      "Epoch 69/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3036 - val_loss: 0.2982\n",
      "Epoch 70/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.3033 - val_loss: 0.3010\n",
      "Epoch 71/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3019 - val_loss: 0.2974\n",
      "Epoch 72/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3019 - val_loss: 0.2988\n",
      "Epoch 73/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3015 - val_loss: 0.2955\n",
      "Epoch 74/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2996 - val_loss: 0.2995\n",
      "Epoch 75/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2992 - val_loss: 0.2955\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2981 - val_loss: 0.2952\n",
      "Epoch 77/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2970 - val_loss: 0.2947\n",
      "Epoch 78/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2962 - val_loss: 0.2959\n",
      "Epoch 79/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2956 - val_loss: 0.2950\n",
      "Epoch 80/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2954 - val_loss: 0.2935\n",
      "Epoch 81/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.2946 - val_loss: 0.2943\n",
      "Epoch 82/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2938 - val_loss: 0.2939\n",
      "Epoch 83/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2929 - val_loss: 0.2913\n",
      "Epoch 84/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2934 - val_loss: 0.2929\n",
      "Epoch 85/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2927 - val_loss: 0.2918\n",
      "Epoch 86/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.2917 - val_loss: 0.2916\n",
      "Epoch 87/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2903 - val_loss: 0.2920\n",
      "Epoch 88/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2895 - val_loss: 0.2914\n",
      "Epoch 89/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2889 - val_loss: 0.2913\n",
      "Epoch 90/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2882 - val_loss: 0.2885\n",
      "Epoch 91/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2884 - val_loss: 0.2923\n",
      "Epoch 92/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2875 - val_loss: 0.2891\n",
      "Epoch 93/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2873 - val_loss: 0.2914\n",
      "Epoch 94/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.335 - 0s 30us/sample - loss: 0.2862 - val_loss: 0.2889\n",
      "Epoch 95/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2861 - val_loss: 0.2892\n",
      "Epoch 96/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2857 - val_loss: 0.2872\n",
      "Epoch 97/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2845 - val_loss: 0.2865\n",
      "Epoch 98/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2843 - val_loss: 0.2872\n",
      "Epoch 99/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2836 - val_loss: 0.2851\n",
      "Epoch 100/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2824 - val_loss: 0.2877\n",
      "Epoch 101/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2832 - val_loss: 0.2834\n",
      "Epoch 102/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2830 - val_loss: 0.2876\n",
      "Epoch 103/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2812 - val_loss: 0.2833\n",
      "Epoch 104/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2809 - val_loss: 0.2840\n",
      "Epoch 105/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2799 - val_loss: 0.2850\n",
      "Epoch 106/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2788 - val_loss: 0.2811\n",
      "Epoch 107/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2792 - val_loss: 0.2811\n",
      "Epoch 108/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2787 - val_loss: 0.2819\n",
      "Epoch 109/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2780 - val_loss: 0.2818\n",
      "Epoch 110/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2772 - val_loss: 0.2793\n",
      "Epoch 111/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2769 - val_loss: 0.2801\n",
      "Epoch 112/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2763 - val_loss: 0.2775\n",
      "Epoch 113/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2771 - val_loss: 0.2779\n",
      "Epoch 114/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2750 - val_loss: 0.2775\n",
      "Epoch 115/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2744 - val_loss: 0.2801\n",
      "Epoch 116/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2753 - val_loss: 0.2738\n",
      "Epoch 117/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2731 - val_loss: 0.2776\n",
      "Epoch 118/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2730 - val_loss: 0.2753\n",
      "Epoch 119/1000\n",
      "1791/1791 [==============================] - 0s 55us/sample - loss: 0.2723 - val_loss: 0.2755\n",
      "Epoch 120/1000\n",
      "1791/1791 [==============================] - 0s 47us/sample - loss: 0.2722 - val_loss: 0.2761\n",
      "Epoch 121/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2722 - val_loss: 0.2747\n",
      "Epoch 122/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2713 - val_loss: 0.2758\n",
      "Epoch 123/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2713 - val_loss: 0.2735\n",
      "Epoch 124/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2705 - val_loss: 0.2720\n",
      "Epoch 125/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2700 - val_loss: 0.2738\n",
      "Epoch 126/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2695 - val_loss: 0.2718\n",
      "Epoch 127/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2692 - val_loss: 0.2741\n",
      "Epoch 128/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2688 - val_loss: 0.2701\n",
      "Epoch 129/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2695 - val_loss: 0.2741\n",
      "Epoch 130/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2693 - val_loss: 0.2701\n",
      "Epoch 131/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2673 - val_loss: 0.2701\n",
      "Epoch 132/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2671 - val_loss: 0.2708\n",
      "Epoch 133/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2664 - val_loss: 0.2692\n",
      "Epoch 134/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2668 - val_loss: 0.2712\n",
      "Epoch 135/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2658 - val_loss: 0.2700\n",
      "Epoch 136/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2653 - val_loss: 0.2699\n",
      "Epoch 137/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2654 - val_loss: 0.2677\n",
      "Epoch 138/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2659 - val_loss: 0.2684\n",
      "Epoch 139/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2654 - val_loss: 0.2704\n",
      "Epoch 140/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2648 - val_loss: 0.2670\n",
      "Epoch 141/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2647 - val_loss: 0.2661\n",
      "Epoch 142/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2633 - val_loss: 0.2713\n",
      "Epoch 143/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2635 - val_loss: 0.2691\n",
      "Epoch 144/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2633 - val_loss: 0.2671\n",
      "Epoch 145/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2628 - val_loss: 0.2648\n",
      "Epoch 146/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2627 - val_loss: 0.2686\n",
      "Epoch 147/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2620 - val_loss: 0.2663\n",
      "Epoch 148/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2619 - val_loss: 0.2672\n",
      "Epoch 149/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2616 - val_loss: 0.2674\n",
      "Epoch 150/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2622 - val_loss: 0.2651\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2605 - val_loss: 0.2680\n",
      "Epoch 152/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2605 - val_loss: 0.2660\n",
      "Epoch 153/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2602 - val_loss: 0.2670\n",
      "Epoch 154/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2612 - val_loss: 0.2644\n",
      "Epoch 155/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2602 - val_loss: 0.2644\n",
      "Epoch 156/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2596 - val_loss: 0.2678\n",
      "Epoch 157/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2588 - val_loss: 0.2618\n",
      "Epoch 158/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2591 - val_loss: 0.2645\n",
      "Epoch 159/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2594 - val_loss: 0.2627\n",
      "Epoch 160/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2586 - val_loss: 0.2623\n",
      "Epoch 161/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2585 - val_loss: 0.2615\n",
      "Epoch 162/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2579 - val_loss: 0.2630\n",
      "Epoch 163/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2569 - val_loss: 0.2609\n",
      "Epoch 164/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2570 - val_loss: 0.2619\n",
      "Epoch 165/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2568 - val_loss: 0.2604\n",
      "Epoch 166/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2570 - val_loss: 0.2594\n",
      "Epoch 167/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2560 - val_loss: 0.2597\n",
      "Epoch 168/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2553 - val_loss: 0.2609\n",
      "Epoch 169/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2552 - val_loss: 0.2597\n",
      "Epoch 170/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2545 - val_loss: 0.2613\n",
      "Epoch 171/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2541 - val_loss: 0.2590\n",
      "Epoch 172/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2548 - val_loss: 0.2599\n",
      "Epoch 173/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2530 - val_loss: 0.2562\n",
      "Epoch 174/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2531 - val_loss: 0.2590\n",
      "Epoch 175/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2533 - val_loss: 0.2578\n",
      "Epoch 176/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2526 - val_loss: 0.2593\n",
      "Epoch 177/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2542 - val_loss: 0.2584\n",
      "Epoch 178/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2534 - val_loss: 0.2548\n",
      "Epoch 179/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2522 - val_loss: 0.2597\n",
      "Epoch 180/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2527 - val_loss: 0.2548\n",
      "Epoch 181/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2506 - val_loss: 0.2578\n",
      "Epoch 182/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2511 - val_loss: 0.2529\n",
      "Epoch 183/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2505 - val_loss: 0.2567\n",
      "Epoch 184/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2503 - val_loss: 0.2564\n",
      "Epoch 185/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2497 - val_loss: 0.2533\n",
      "Epoch 186/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2490 - val_loss: 0.2539\n",
      "Epoch 187/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2494 - val_loss: 0.2553\n",
      "Epoch 188/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2490 - val_loss: 0.2555\n",
      "Epoch 189/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2487 - val_loss: 0.2528\n",
      "Epoch 190/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2483 - val_loss: 0.2537\n",
      "Epoch 191/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2476 - val_loss: 0.2535\n",
      "Epoch 192/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2473 - val_loss: 0.2523\n",
      "Epoch 193/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2473 - val_loss: 0.2505\n",
      "Epoch 194/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2469 - val_loss: 0.2539\n",
      "Epoch 195/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2467 - val_loss: 0.2494\n",
      "Epoch 196/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2460 - val_loss: 0.2502\n",
      "Epoch 197/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2465 - val_loss: 0.2544\n",
      "Epoch 198/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2472 - val_loss: 0.2477\n",
      "Epoch 199/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2460 - val_loss: 0.2478\n",
      "Epoch 200/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2454 - val_loss: 0.2510\n",
      "Epoch 201/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2459 - val_loss: 0.2480\n",
      "Epoch 202/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2447 - val_loss: 0.2490\n",
      "Epoch 203/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2447 - val_loss: 0.2512\n",
      "Epoch 204/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2451 - val_loss: 0.2456\n",
      "Epoch 205/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2437 - val_loss: 0.2481\n",
      "Epoch 206/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2430 - val_loss: 0.2459\n",
      "Epoch 207/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2430 - val_loss: 0.2462\n",
      "Epoch 208/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2429 - val_loss: 0.2457\n",
      "Epoch 209/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2427 - val_loss: 0.2468\n",
      "Epoch 210/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2422 - val_loss: 0.2470\n",
      "Epoch 211/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2419 - val_loss: 0.2451\n",
      "Epoch 212/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2426 - val_loss: 0.2479\n",
      "Epoch 213/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2421 - val_loss: 0.2461\n",
      "Epoch 214/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2413 - val_loss: 0.2466\n",
      "Epoch 215/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2411 - val_loss: 0.2456\n",
      "Epoch 216/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2405 - val_loss: 0.2423\n",
      "Epoch 217/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2411 - val_loss: 0.2461\n",
      "Epoch 218/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2407 - val_loss: 0.2414\n",
      "Epoch 219/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2408 - val_loss: 0.2489\n",
      "Epoch 220/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2402 - val_loss: 0.2392\n",
      "Epoch 221/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2407 - val_loss: 0.2482\n",
      "Epoch 222/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2392 - val_loss: 0.2409\n",
      "Epoch 223/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2391 - val_loss: 0.2458\n",
      "Epoch 224/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2389 - val_loss: 0.2414\n",
      "Epoch 225/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2386 - val_loss: 0.2439\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2385 - val_loss: 0.2395\n",
      "Epoch 227/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2385 - val_loss: 0.2470\n",
      "Epoch 228/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2383 - val_loss: 0.2380\n",
      "Epoch 229/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2374 - val_loss: 0.2409\n",
      "Epoch 230/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2376 - val_loss: 0.2384\n",
      "Epoch 231/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2379 - val_loss: 0.2371\n",
      "Epoch 232/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2370 - val_loss: 0.2391\n",
      "Epoch 233/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2365 - val_loss: 0.2381\n",
      "Epoch 234/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2363 - val_loss: 0.2420\n",
      "Epoch 235/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2377 - val_loss: 0.2361\n",
      "Epoch 236/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2372 - val_loss: 0.2404\n",
      "Epoch 237/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2366 - val_loss: 0.2349\n",
      "Epoch 238/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2366 - val_loss: 0.2366\n",
      "Epoch 239/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2352 - val_loss: 0.2380\n",
      "Epoch 240/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2352 - val_loss: 0.2372\n",
      "Epoch 241/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2355 - val_loss: 0.2364\n",
      "Epoch 242/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2348 - val_loss: 0.2346\n",
      "Epoch 243/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2346 - val_loss: 0.2383\n",
      "Epoch 244/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2342 - val_loss: 0.2357\n",
      "Epoch 245/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2341 - val_loss: 0.2359\n",
      "Epoch 246/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2346 - val_loss: 0.2386\n",
      "Epoch 247/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2348 - val_loss: 0.2322\n",
      "Epoch 248/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2334 - val_loss: 0.2372\n",
      "Epoch 249/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2333 - val_loss: 0.2349\n",
      "Epoch 250/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2330 - val_loss: 0.2332\n",
      "Epoch 251/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2329 - val_loss: 0.2372\n",
      "Epoch 252/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2328 - val_loss: 0.2324\n",
      "Epoch 253/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2322 - val_loss: 0.2355\n",
      "Epoch 254/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2325 - val_loss: 0.2312\n",
      "Epoch 255/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2333 - val_loss: 0.2399\n",
      "Epoch 256/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2315 - val_loss: 0.2303\n",
      "Epoch 257/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2316 - val_loss: 0.2328\n",
      "Epoch 258/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2311 - val_loss: 0.2312\n",
      "Epoch 259/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2320 - val_loss: 0.2360\n",
      "Epoch 260/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2314 - val_loss: 0.2303\n",
      "Epoch 261/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2308 - val_loss: 0.2310\n",
      "Epoch 262/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2317 - val_loss: 0.2294\n",
      "Epoch 263/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2309 - val_loss: 0.2297\n",
      "Epoch 264/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2304 - val_loss: 0.2305\n",
      "Epoch 265/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2299 - val_loss: 0.2295\n",
      "Epoch 266/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2305 - val_loss: 0.2305\n",
      "Epoch 267/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2304 - val_loss: 0.2300\n",
      "Epoch 268/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2297 - val_loss: 0.2311\n",
      "Epoch 269/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2290 - val_loss: 0.2315\n",
      "Epoch 270/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2291 - val_loss: 0.2294\n",
      "Epoch 271/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2290 - val_loss: 0.2283\n",
      "Epoch 272/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2288 - val_loss: 0.2310\n",
      "Epoch 273/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2292 - val_loss: 0.2337\n",
      "Epoch 274/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2298 - val_loss: 0.2265\n",
      "Epoch 275/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2294 - val_loss: 0.2281\n",
      "Epoch 276/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2287 - val_loss: 0.2288\n",
      "Epoch 277/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2278 - val_loss: 0.2293\n",
      "Epoch 278/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2275 - val_loss: 0.2284\n",
      "Epoch 279/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2275 - val_loss: 0.2280\n",
      "Epoch 280/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2273 - val_loss: 0.2281\n",
      "Epoch 281/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2278 - val_loss: 0.2269\n",
      "Epoch 282/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2272 - val_loss: 0.2248\n",
      "Epoch 283/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2274 - val_loss: 0.2331\n",
      "Epoch 284/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2271 - val_loss: 0.2261\n",
      "Epoch 285/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2271 - val_loss: 0.2249\n",
      "Epoch 286/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2270 - val_loss: 0.2257\n",
      "Epoch 287/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2259 - val_loss: 0.2256\n",
      "Epoch 288/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2255 - val_loss: 0.2276\n",
      "Epoch 289/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2257 - val_loss: 0.2269\n",
      "Epoch 290/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2265 - val_loss: 0.2289\n",
      "Epoch 291/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2275 - val_loss: 0.2241\n",
      "Epoch 292/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2250 - val_loss: 0.2276\n",
      "Epoch 293/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2249 - val_loss: 0.2243\n",
      "Epoch 294/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2251 - val_loss: 0.2303\n",
      "Epoch 295/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2246 - val_loss: 0.2215\n",
      "Epoch 296/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2275 - val_loss: 0.2280\n",
      "Epoch 297/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2241 - val_loss: 0.2221\n",
      "Epoch 298/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2250 - val_loss: 0.2230\n",
      "Epoch 299/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2244 - val_loss: 0.2264\n",
      "Epoch 300/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2246 - val_loss: 0.2212\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2246 - val_loss: 0.2224\n",
      "Epoch 302/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2233 - val_loss: 0.2237\n",
      "Epoch 303/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2235 - val_loss: 0.2213\n",
      "Epoch 304/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2230 - val_loss: 0.2216\n",
      "Epoch 305/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2233 - val_loss: 0.2238\n",
      "Epoch 306/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2227 - val_loss: 0.2217\n",
      "Epoch 307/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2235 - val_loss: 0.2278\n",
      "Epoch 308/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2224 - val_loss: 0.2208\n",
      "Epoch 309/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2225 - val_loss: 0.2285\n",
      "Epoch 310/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2234 - val_loss: 0.2192\n",
      "Epoch 311/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2217 - val_loss: 0.2239\n",
      "Epoch 312/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2221 - val_loss: 0.2201\n",
      "Epoch 313/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2211 - val_loss: 0.2235\n",
      "Epoch 314/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2207 - val_loss: 0.2197\n",
      "Epoch 315/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2214 - val_loss: 0.2246\n",
      "Epoch 316/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2216 - val_loss: 0.2189\n",
      "Epoch 317/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2218 - val_loss: 0.2201\n",
      "Epoch 318/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2203 - val_loss: 0.2190\n",
      "Epoch 319/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2199 - val_loss: 0.2233\n",
      "Epoch 320/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2218 - val_loss: 0.2187\n",
      "Epoch 321/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2214 - val_loss: 0.2172\n",
      "Epoch 322/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2205 - val_loss: 0.2183\n",
      "Epoch 323/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2196 - val_loss: 0.2186\n",
      "Epoch 324/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2196 - val_loss: 0.2188\n",
      "Epoch 325/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2203 - val_loss: 0.2250\n",
      "Epoch 326/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2213 - val_loss: 0.2171\n",
      "Epoch 327/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2203 - val_loss: 0.2163\n",
      "Epoch 328/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2189 - val_loss: 0.2180\n",
      "Epoch 329/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2197 - val_loss: 0.2186\n",
      "Epoch 330/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2182 - val_loss: 0.2168\n",
      "Epoch 331/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2185 - val_loss: 0.2219\n",
      "Epoch 332/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2181 - val_loss: 0.2162\n",
      "Epoch 333/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2178 - val_loss: 0.2193\n",
      "Epoch 334/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2179 - val_loss: 0.2168\n",
      "Epoch 335/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2184 - val_loss: 0.2207\n",
      "Epoch 336/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2175 - val_loss: 0.2162\n",
      "Epoch 337/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2173 - val_loss: 0.2143\n",
      "Epoch 338/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2186 - val_loss: 0.2240\n",
      "Epoch 339/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2189 - val_loss: 0.2139\n",
      "Epoch 340/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2163 - val_loss: 0.2163\n",
      "Epoch 341/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2160 - val_loss: 0.2150\n",
      "Epoch 342/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2170 - val_loss: 0.2143\n",
      "Epoch 343/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2170 - val_loss: 0.2181\n",
      "Epoch 344/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2161 - val_loss: 0.2130\n",
      "Epoch 345/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2173 - val_loss: 0.2128\n",
      "Epoch 346/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2172 - val_loss: 0.2219\n",
      "Epoch 347/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2176 - val_loss: 0.2117\n",
      "Epoch 348/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2163 - val_loss: 0.2160\n",
      "Epoch 349/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2143 - val_loss: 0.2136\n",
      "Epoch 350/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2148 - val_loss: 0.2132\n",
      "Epoch 351/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2144 - val_loss: 0.2142\n",
      "Epoch 352/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2142 - val_loss: 0.2140\n",
      "Epoch 353/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2142 - val_loss: 0.2133\n",
      "Epoch 354/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2140 - val_loss: 0.2141\n",
      "Epoch 355/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2138 - val_loss: 0.2152\n",
      "Epoch 356/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2137 - val_loss: 0.2107\n",
      "Epoch 357/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2147 - val_loss: 0.2108\n",
      "Epoch 358/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2135 - val_loss: 0.2170\n",
      "Epoch 359/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2135 - val_loss: 0.2140\n",
      "Epoch 360/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2132 - val_loss: 0.2124\n",
      "Epoch 361/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2130 - val_loss: 0.2125\n",
      "Epoch 362/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2127 - val_loss: 0.2131\n",
      "Epoch 363/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2125 - val_loss: 0.2123\n",
      "Epoch 364/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2122 - val_loss: 0.2115\n",
      "Epoch 365/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2122 - val_loss: 0.2124\n",
      "Epoch 366/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2114 - val_loss: 0.2098\n",
      "Epoch 367/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2118 - val_loss: 0.2187\n",
      "Epoch 368/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2134 - val_loss: 0.2086\n",
      "Epoch 369/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2127 - val_loss: 0.2114\n",
      "Epoch 370/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2115 - val_loss: 0.2085\n",
      "Epoch 371/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2113 - val_loss: 0.2103\n",
      "Epoch 372/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2107 - val_loss: 0.2084\n",
      "Epoch 373/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2109 - val_loss: 0.2150\n",
      "Epoch 374/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2105 - val_loss: 0.2098\n",
      "Epoch 375/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2100 - val_loss: 0.2116\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2099 - val_loss: 0.2097\n",
      "Epoch 377/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2101 - val_loss: 0.2105\n",
      "Epoch 378/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2100 - val_loss: 0.2095\n",
      "Epoch 379/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2099 - val_loss: 0.2066\n",
      "Epoch 380/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2103 - val_loss: 0.2133\n",
      "Epoch 381/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2099 - val_loss: 0.2076\n",
      "Epoch 382/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2100 - val_loss: 0.2107\n",
      "Epoch 383/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2114 - val_loss: 0.2141\n",
      "Epoch 384/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2100 - val_loss: 0.2058\n",
      "Epoch 385/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2094 - val_loss: 0.2094\n",
      "Epoch 386/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2092 - val_loss: 0.2121\n",
      "Epoch 387/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2091 - val_loss: 0.2080\n",
      "Epoch 388/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2084 - val_loss: 0.2069\n",
      "Epoch 389/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2079 - val_loss: 0.2091\n",
      "Epoch 390/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2088 - val_loss: 0.2051\n",
      "Epoch 391/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2078 - val_loss: 0.2078\n",
      "Epoch 392/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2072 - val_loss: 0.2085\n",
      "Epoch 393/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2081 - val_loss: 0.2104\n",
      "Epoch 394/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2084 - val_loss: 0.2044\n",
      "Epoch 395/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2069 - val_loss: 0.2103\n",
      "Epoch 396/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2083 - val_loss: 0.2070\n",
      "Epoch 397/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2081 - val_loss: 0.2037\n",
      "Epoch 398/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2069 - val_loss: 0.2094\n",
      "Epoch 399/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2068 - val_loss: 0.2044\n",
      "Epoch 400/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2066 - val_loss: 0.2040\n",
      "Epoch 401/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2064 - val_loss: 0.2058\n",
      "Epoch 402/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2055 - val_loss: 0.2046\n",
      "Epoch 403/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2059 - val_loss: 0.2028\n",
      "Epoch 404/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2054 - val_loss: 0.2075\n",
      "Epoch 405/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2061 - val_loss: 0.2030\n",
      "Epoch 406/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2062 - val_loss: 0.2070\n",
      "Epoch 407/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2055 - val_loss: 0.2054\n",
      "Epoch 408/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2047 - val_loss: 0.2019\n",
      "Epoch 409/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2047 - val_loss: 0.2046\n",
      "Epoch 410/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2051 - val_loss: 0.2095\n",
      "Epoch 411/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2076 - val_loss: 0.2056\n",
      "Epoch 412/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2061 - val_loss: 0.2011\n",
      "Epoch 413/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2041 - val_loss: 0.2024\n",
      "Epoch 414/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2042 - val_loss: 0.2018\n",
      "Epoch 415/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2043 - val_loss: 0.2083\n",
      "Epoch 416/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2038 - val_loss: 0.2023\n",
      "Epoch 417/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2034 - val_loss: 0.2037\n",
      "Epoch 418/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2031 - val_loss: 0.2036\n",
      "Epoch 419/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2028 - val_loss: 0.2005\n",
      "Epoch 420/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2026 - val_loss: 0.2029\n",
      "Epoch 421/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2028 - val_loss: 0.2025\n",
      "Epoch 422/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2021 - val_loss: 0.1996\n",
      "Epoch 423/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2034 - val_loss: 0.2015\n",
      "Epoch 424/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2026 - val_loss: 0.2051\n",
      "Epoch 425/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2026 - val_loss: 0.1987\n",
      "Epoch 426/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2026 - val_loss: 0.1994\n",
      "Epoch 427/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2031 - val_loss: 0.2017\n",
      "Epoch 428/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2022 - val_loss: 0.1991\n",
      "Epoch 429/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2009 - val_loss: 0.1993\n",
      "Epoch 430/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2012 - val_loss: 0.2039\n",
      "Epoch 431/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2017 - val_loss: 0.2023\n",
      "Epoch 432/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2018 - val_loss: 0.1973\n",
      "Epoch 433/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2006 - val_loss: 0.1995\n",
      "Epoch 434/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2010 - val_loss: 0.2012\n",
      "Epoch 435/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2014 - val_loss: 0.1992\n",
      "Epoch 436/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2011 - val_loss: 0.2035\n",
      "Epoch 437/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1995 - val_loss: 0.1986\n",
      "Epoch 438/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1997 - val_loss: 0.2006\n",
      "Epoch 439/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1998 - val_loss: 0.2000\n",
      "Epoch 440/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1991 - val_loss: 0.1964\n",
      "Epoch 441/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1989 - val_loss: 0.1988\n",
      "Epoch 442/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1987 - val_loss: 0.2003\n",
      "Epoch 443/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1988 - val_loss: 0.1993\n",
      "Epoch 444/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1984 - val_loss: 0.2000\n",
      "Epoch 445/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1989 - val_loss: 0.1975\n",
      "Epoch 446/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1980 - val_loss: 0.1968\n",
      "Epoch 447/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1980 - val_loss: 0.1989\n",
      "Epoch 448/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2000 - val_loss: 0.1935\n",
      "Epoch 449/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1994 - val_loss: 0.1973\n",
      "Epoch 450/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1978 - val_loss: 0.1994\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1968 - val_loss: 0.1948\n",
      "Epoch 452/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1979 - val_loss: 0.1978\n",
      "Epoch 453/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1976 - val_loss: 0.1943\n",
      "Epoch 454/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1970 - val_loss: 0.1977\n",
      "Epoch 455/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1969 - val_loss: 0.1936\n",
      "Epoch 456/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1967 - val_loss: 0.1978\n",
      "Epoch 457/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1972 - val_loss: 0.1963\n",
      "Epoch 458/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1965 - val_loss: 0.1937\n",
      "Epoch 459/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1975 - val_loss: 0.2006\n",
      "Epoch 460/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1964 - val_loss: 0.1929\n",
      "Epoch 461/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1961 - val_loss: 0.1935\n",
      "Epoch 462/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1959 - val_loss: 0.1960\n",
      "Epoch 463/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1950 - val_loss: 0.1939\n",
      "Epoch 464/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1953 - val_loss: 0.1950\n",
      "Epoch 465/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1948 - val_loss: 0.1918\n",
      "Epoch 466/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1954 - val_loss: 0.1922\n",
      "Epoch 467/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1952 - val_loss: 0.1968\n",
      "Epoch 468/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1950 - val_loss: 0.1909\n",
      "Epoch 469/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1937 - val_loss: 0.1961\n",
      "Epoch 470/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1943 - val_loss: 0.1911\n",
      "Epoch 471/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1949 - val_loss: 0.1996\n",
      "Epoch 472/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1953 - val_loss: 0.1926\n",
      "Epoch 473/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1941 - val_loss: 0.1911\n",
      "Epoch 474/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1933 - val_loss: 0.1929\n",
      "Epoch 475/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1937 - val_loss: 0.1898\n",
      "Epoch 476/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1940 - val_loss: 0.2038\n",
      "Epoch 477/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1992 - val_loss: 0.1877\n",
      "Epoch 478/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1950 - val_loss: 0.1949\n",
      "Epoch 479/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1943 - val_loss: 0.1920\n",
      "Epoch 480/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1937 - val_loss: 0.1897\n",
      "Epoch 481/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1922 - val_loss: 0.1918\n",
      "Epoch 482/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1923 - val_loss: 0.1919\n",
      "Epoch 483/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1934 - val_loss: 0.1887\n",
      "Epoch 484/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1918 - val_loss: 0.1893\n",
      "Epoch 485/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1915 - val_loss: 0.1914\n",
      "Epoch 486/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1923 - val_loss: 0.1870\n",
      "Epoch 487/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1920 - val_loss: 0.1926\n",
      "Epoch 488/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1918 - val_loss: 0.1882\n",
      "Epoch 489/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1907 - val_loss: 0.1937\n",
      "Epoch 490/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1912 - val_loss: 0.1880\n",
      "Epoch 491/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1903 - val_loss: 0.1936\n",
      "Epoch 492/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1906 - val_loss: 0.1864\n",
      "Epoch 493/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1904 - val_loss: 0.1903\n",
      "Epoch 494/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1906 - val_loss: 0.1916\n",
      "Epoch 495/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1912 - val_loss: 0.1864\n",
      "Epoch 496/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1910 - val_loss: 0.1866\n",
      "Epoch 497/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1903 - val_loss: 0.1874\n",
      "Epoch 498/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1891 - val_loss: 0.1890\n",
      "Epoch 499/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1890 - val_loss: 0.1871\n",
      "Epoch 500/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1899 - val_loss: 0.1936\n",
      "Epoch 501/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1928 - val_loss: 0.1848\n",
      "Epoch 502/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1890 - val_loss: 0.1886\n",
      "Epoch 503/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1902 - val_loss: 0.1911\n",
      "Epoch 504/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1895 - val_loss: 0.1854\n",
      "Epoch 505/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1889 - val_loss: 0.1876\n",
      "Epoch 506/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1879 - val_loss: 0.1843\n",
      "Epoch 507/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1901 - val_loss: 0.1947\n",
      "Epoch 508/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1887 - val_loss: 0.1835\n",
      "Epoch 509/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1870 - val_loss: 0.1875\n",
      "Epoch 510/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1880 - val_loss: 0.1883\n",
      "Epoch 511/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1870 - val_loss: 0.1835\n",
      "Epoch 512/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1873 - val_loss: 0.1890\n",
      "Epoch 513/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1870 - val_loss: 0.1839\n",
      "Epoch 514/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1866 - val_loss: 0.1877\n",
      "Epoch 515/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1880 - val_loss: 0.1842\n",
      "Epoch 516/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1871 - val_loss: 0.1872\n",
      "Epoch 517/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1865 - val_loss: 0.1832\n",
      "Epoch 518/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1857 - val_loss: 0.1858\n",
      "Epoch 519/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1863 - val_loss: 0.1819\n",
      "Epoch 520/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1863 - val_loss: 0.1832\n",
      "Epoch 521/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1865 - val_loss: 0.1808\n",
      "Epoch 522/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1859 - val_loss: 0.1864\n",
      "Epoch 523/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1851 - val_loss: 0.1824\n",
      "Epoch 524/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1850 - val_loss: 0.1841\n",
      "Epoch 525/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1847 - val_loss: 0.1817\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1857 - val_loss: 0.1905\n",
      "Epoch 527/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1859 - val_loss: 0.1829\n",
      "Epoch 528/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1845 - val_loss: 0.1819\n",
      "Epoch 529/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1850 - val_loss: 0.1792\n",
      "Epoch 530/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1856 - val_loss: 0.1815\n",
      "Epoch 531/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1850 - val_loss: 0.1815\n",
      "Epoch 532/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1847 - val_loss: 0.1868\n",
      "Epoch 533/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1845 - val_loss: 0.1793\n",
      "Epoch 534/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1836 - val_loss: 0.1820\n",
      "Epoch 535/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1844 - val_loss: 0.1861\n",
      "Epoch 536/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1830 - val_loss: 0.1783\n",
      "Epoch 537/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1827 - val_loss: 0.1802\n",
      "Epoch 538/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1828 - val_loss: 0.1795\n",
      "Epoch 539/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1824 - val_loss: 0.1821\n",
      "Epoch 540/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1825 - val_loss: 0.1789\n",
      "Epoch 541/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1815 - val_loss: 0.1819\n",
      "Epoch 542/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1813 - val_loss: 0.1768\n",
      "Epoch 543/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1835 - val_loss: 0.1779\n",
      "Epoch 544/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1819 - val_loss: 0.1781\n",
      "Epoch 545/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1815 - val_loss: 0.1794\n",
      "Epoch 546/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1825 - val_loss: 0.1765\n",
      "Epoch 547/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1815 - val_loss: 0.1787\n",
      "Epoch 548/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1814 - val_loss: 0.1762\n",
      "Epoch 549/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1813 - val_loss: 0.1759\n",
      "Epoch 550/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1803 - val_loss: 0.1766\n",
      "Epoch 551/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1804 - val_loss: 0.1841\n",
      "Epoch 552/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1818 - val_loss: 0.1750\n",
      "Epoch 553/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1818 - val_loss: 0.1756\n",
      "Epoch 554/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1795 - val_loss: 0.1782\n",
      "Epoch 555/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1788 - val_loss: 0.1767\n",
      "Epoch 556/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1791 - val_loss: 0.1791\n",
      "Epoch 557/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1791 - val_loss: 0.1783\n",
      "Epoch 558/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1785 - val_loss: 0.1782\n",
      "Epoch 559/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1790 - val_loss: 0.1737\n",
      "Epoch 560/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1795 - val_loss: 0.1810\n",
      "Epoch 561/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1775 - val_loss: 0.1742\n",
      "Epoch 562/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1776 - val_loss: 0.1787\n",
      "Epoch 563/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1775 - val_loss: 0.1730\n",
      "Epoch 564/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1785 - val_loss: 0.1765\n",
      "Epoch 565/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1776 - val_loss: 0.1746\n",
      "Epoch 566/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1785 - val_loss: 0.1721\n",
      "Epoch 567/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1764 - val_loss: 0.1831\n",
      "Epoch 568/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1794 - val_loss: 0.1716\n",
      "Epoch 569/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1786 - val_loss: 0.1790\n",
      "Epoch 570/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1778 - val_loss: 0.1773\n",
      "Epoch 571/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1766 - val_loss: 0.1722\n",
      "Epoch 572/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1769 - val_loss: 0.1727\n",
      "Epoch 573/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1771 - val_loss: 0.1729\n",
      "Epoch 574/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1763 - val_loss: 0.1772\n",
      "Epoch 575/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1760 - val_loss: 0.1749\n",
      "Epoch 576/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1756 - val_loss: 0.1761\n",
      "Epoch 577/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1752 - val_loss: 0.1733\n",
      "Epoch 578/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1756 - val_loss: 0.1720\n",
      "Epoch 579/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1752 - val_loss: 0.1740\n",
      "Epoch 580/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1748 - val_loss: 0.1706\n",
      "Epoch 581/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1741 - val_loss: 0.1772\n",
      "Epoch 582/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1765 - val_loss: 0.1695\n",
      "Epoch 583/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1737 - val_loss: 0.1746\n",
      "Epoch 584/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1739 - val_loss: 0.1726\n",
      "Epoch 585/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1734 - val_loss: 0.1722\n",
      "Epoch 586/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1733 - val_loss: 0.1727\n",
      "Epoch 587/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1735 - val_loss: 0.1722\n",
      "Epoch 588/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1731 - val_loss: 0.1699\n",
      "Epoch 589/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1729 - val_loss: 0.1722\n",
      "Epoch 590/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1734 - val_loss: 0.1742\n",
      "Epoch 591/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1726 - val_loss: 0.1697\n",
      "Epoch 592/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1721 - val_loss: 0.1690\n",
      "Epoch 593/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1723 - val_loss: 0.1720\n",
      "Epoch 594/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1717 - val_loss: 0.1718\n",
      "Epoch 595/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1721 - val_loss: 0.1695\n",
      "Epoch 596/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1718 - val_loss: 0.1710\n",
      "Epoch 597/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1717 - val_loss: 0.1693\n",
      "Epoch 598/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1730 - val_loss: 0.1745\n",
      "Epoch 599/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1716 - val_loss: 0.1699\n",
      "Epoch 600/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1708 - val_loss: 0.1725\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1704 - val_loss: 0.1693\n",
      "Epoch 602/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1711 - val_loss: 0.1672\n",
      "Epoch 603/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1709 - val_loss: 0.1679\n",
      "Epoch 604/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1710 - val_loss: 0.1669\n",
      "Epoch 605/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1706 - val_loss: 0.1747\n",
      "Epoch 606/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1715 - val_loss: 0.1673\n",
      "Epoch 607/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1699 - val_loss: 0.1686\n",
      "Epoch 608/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1695 - val_loss: 0.1733\n",
      "Epoch 609/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1762 - val_loss: 0.1656\n",
      "Epoch 610/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1716 - val_loss: 0.1668\n",
      "Epoch 611/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1701 - val_loss: 0.1666\n",
      "Epoch 612/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1689 - val_loss: 0.1680\n",
      "Epoch 613/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1687 - val_loss: 0.1663\n",
      "Epoch 614/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1694 - val_loss: 0.1691\n",
      "Epoch 615/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1679 - val_loss: 0.1652\n",
      "Epoch 616/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1693 - val_loss: 0.1663\n",
      "Epoch 617/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1679 - val_loss: 0.1661\n",
      "Epoch 618/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1675 - val_loss: 0.1655\n",
      "Epoch 619/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1682 - val_loss: 0.1709\n",
      "Epoch 620/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1682 - val_loss: 0.1646\n",
      "Epoch 621/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1677 - val_loss: 0.1656\n",
      "Epoch 622/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1672 - val_loss: 0.1665\n",
      "Epoch 623/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1672 - val_loss: 0.1635\n",
      "Epoch 624/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1669 - val_loss: 0.1642\n",
      "Epoch 625/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1661 - val_loss: 0.1648\n",
      "Epoch 626/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1661 - val_loss: 0.1647\n",
      "Epoch 627/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1661 - val_loss: 0.1638\n",
      "Epoch 628/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1667 - val_loss: 0.1620\n",
      "Epoch 629/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1666 - val_loss: 0.1685\n",
      "Epoch 630/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1660 - val_loss: 0.1633\n",
      "Epoch 631/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1655 - val_loss: 0.1634\n",
      "Epoch 632/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1657 - val_loss: 0.1616\n",
      "Epoch 633/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1653 - val_loss: 0.1637\n",
      "Epoch 634/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1647 - val_loss: 0.1633\n",
      "Epoch 635/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1654 - val_loss: 0.1612\n",
      "Epoch 636/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1649 - val_loss: 0.1602\n",
      "Epoch 637/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1652 - val_loss: 0.1665\n",
      "Epoch 638/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1659 - val_loss: 0.1600\n",
      "Epoch 639/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1669 - val_loss: 0.1631\n",
      "Epoch 640/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1643 - val_loss: 0.1626\n",
      "Epoch 641/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1637 - val_loss: 0.1624\n",
      "Epoch 642/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1656 - val_loss: 0.1669\n",
      "Epoch 643/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1660 - val_loss: 0.1592\n",
      "Epoch 644/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1662 - val_loss: 0.1684\n",
      "Epoch 645/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1639 - val_loss: 0.1581\n",
      "Epoch 646/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1650 - val_loss: 0.1620\n",
      "Epoch 647/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1630 - val_loss: 0.1620\n",
      "Epoch 648/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1626 - val_loss: 0.1585\n",
      "Epoch 649/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1641 - val_loss: 0.1580\n",
      "Epoch 650/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1617 - val_loss: 0.1642\n",
      "Epoch 651/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1647 - val_loss: 0.1584\n",
      "Epoch 652/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1635 - val_loss: 0.1575\n",
      "Epoch 653/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1622 - val_loss: 0.1626\n",
      "Epoch 654/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1631 - val_loss: 0.1569\n",
      "Epoch 655/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1651 - val_loss: 0.1592\n",
      "Epoch 656/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1640 - val_loss: 0.1683\n",
      "Epoch 657/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1656 - val_loss: 0.1574\n",
      "Epoch 658/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1620 - val_loss: 0.1575\n",
      "Epoch 659/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1616 - val_loss: 0.1606\n",
      "Epoch 660/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1614 - val_loss: 0.1597\n",
      "Epoch 661/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1616 - val_loss: 0.1598\n",
      "Epoch 662/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1614 - val_loss: 0.1591\n",
      "Epoch 663/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1611 - val_loss: 0.1615\n",
      "Epoch 664/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1609 - val_loss: 0.1572\n",
      "Epoch 665/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1608 - val_loss: 0.1559\n",
      "Epoch 666/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1609 - val_loss: 0.1595\n",
      "Epoch 667/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1606 - val_loss: 0.1589\n",
      "Epoch 668/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1605 - val_loss: 0.1593\n",
      "Epoch 669/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1611 - val_loss: 0.1564\n",
      "Epoch 670/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1592 - val_loss: 0.1599\n",
      "Epoch 671/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1603 - val_loss: 0.1547\n",
      "Epoch 672/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1598 - val_loss: 0.1552\n",
      "Epoch 673/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1592 - val_loss: 0.1587\n",
      "Epoch 674/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1588 - val_loss: 0.1549\n",
      "Epoch 675/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1593 - val_loss: 0.1582\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1594 - val_loss: 0.1571\n",
      "Epoch 677/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1593 - val_loss: 0.1538\n",
      "Epoch 678/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1597 - val_loss: 0.1549\n",
      "Epoch 679/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1583 - val_loss: 0.1559\n",
      "Epoch 680/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1590 - val_loss: 0.1585\n",
      "Epoch 681/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1584 - val_loss: 0.1536\n",
      "Epoch 682/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1601 - val_loss: 0.1543\n",
      "Epoch 683/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1584 - val_loss: 0.1559\n",
      "Epoch 684/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1582 - val_loss: 0.1559\n",
      "Epoch 685/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1583 - val_loss: 0.1545\n",
      "Epoch 686/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1569 - val_loss: 0.1546\n",
      "Epoch 687/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1585 - val_loss: 0.1543\n",
      "Epoch 688/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1577 - val_loss: 0.1556\n",
      "Epoch 689/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1567 - val_loss: 0.1529\n",
      "Epoch 690/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1585 - val_loss: 0.1568\n",
      "Epoch 691/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1574 - val_loss: 0.1558\n",
      "Epoch 692/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1563 - val_loss: 0.1529\n",
      "Epoch 693/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1582 - val_loss: 0.1538\n",
      "Epoch 694/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1562 - val_loss: 0.1543\n",
      "Epoch 695/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1561 - val_loss: 0.1524\n",
      "Epoch 696/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1575 - val_loss: 0.1516\n",
      "Epoch 697/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1569 - val_loss: 0.1587\n",
      "Epoch 698/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1585 - val_loss: 0.1516\n",
      "Epoch 699/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1584 - val_loss: 0.1554\n",
      "Epoch 700/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1561 - val_loss: 0.1531\n",
      "Epoch 701/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1569 - val_loss: 0.1508\n",
      "Epoch 702/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1559 - val_loss: 0.1551\n",
      "Epoch 703/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1555 - val_loss: 0.1512\n",
      "Epoch 704/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1556 - val_loss: 0.1523\n",
      "Epoch 705/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1553 - val_loss: 0.1526\n",
      "Epoch 706/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1553 - val_loss: 0.1513\n",
      "Epoch 707/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1560 - val_loss: 0.1501\n",
      "Epoch 708/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1555 - val_loss: 0.1587\n",
      "Epoch 709/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1564 - val_loss: 0.1529\n",
      "Epoch 710/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1552 - val_loss: 0.1524\n",
      "Epoch 711/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1554 - val_loss: 0.1501\n",
      "Epoch 712/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1563 - val_loss: 0.1542\n",
      "Epoch 713/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1545 - val_loss: 0.1505\n",
      "Epoch 714/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1551 - val_loss: 0.1503\n",
      "Epoch 715/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1540 - val_loss: 0.1512\n",
      "Epoch 716/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1539 - val_loss: 0.1525\n",
      "Epoch 717/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1536 - val_loss: 0.1503\n",
      "Epoch 718/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1543 - val_loss: 0.1508\n",
      "Epoch 719/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1541 - val_loss: 0.1528\n",
      "Epoch 720/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1552 - val_loss: 0.1494\n",
      "Epoch 721/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1536 - val_loss: 0.1527\n",
      "Epoch 722/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1540 - val_loss: 0.1503\n",
      "Epoch 723/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1534 - val_loss: 0.1501\n",
      "Epoch 724/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1525 - val_loss: 0.1509\n",
      "Epoch 725/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1535 - val_loss: 0.1521\n",
      "Epoch 726/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1537 - val_loss: 0.1480\n",
      "Epoch 727/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1525 - val_loss: 0.1517\n",
      "Epoch 728/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1536 - val_loss: 0.1490\n",
      "Epoch 729/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1533 - val_loss: 0.1591\n",
      "Epoch 730/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1540 - val_loss: 0.1477\n",
      "Epoch 731/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1526 - val_loss: 0.1543\n",
      "Epoch 732/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1539 - val_loss: 0.1495\n",
      "Epoch 733/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1521 - val_loss: 0.1484\n",
      "Epoch 734/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1518 - val_loss: 0.1500\n",
      "Epoch 735/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1526 - val_loss: 0.1526\n",
      "Epoch 736/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1522 - val_loss: 0.1478\n",
      "Epoch 737/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1522 - val_loss: 0.1532\n",
      "Epoch 738/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1521 - val_loss: 0.1470\n",
      "Epoch 739/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1528 - val_loss: 0.1542\n",
      "Epoch 740/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1526 - val_loss: 0.1480\n",
      "Epoch 741/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1522 - val_loss: 0.1475\n",
      "Epoch 742/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1508 - val_loss: 0.1488\n",
      "Epoch 743/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1513 - val_loss: 0.1477\n",
      "Epoch 744/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1515 - val_loss: 0.1510\n",
      "Epoch 745/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1515 - val_loss: 0.1457\n",
      "Epoch 746/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1519 - val_loss: 0.1491\n",
      "Epoch 747/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1505 - val_loss: 0.1465\n",
      "Epoch 748/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1503 - val_loss: 0.1471\n",
      "Epoch 749/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1510 - val_loss: 0.1465\n",
      "Epoch 750/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1501 - val_loss: 0.1484\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1513 - val_loss: 0.1458\n",
      "Epoch 752/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1515 - val_loss: 0.1516\n",
      "Epoch 753/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1502 - val_loss: 0.1459\n",
      "Epoch 754/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1505 - val_loss: 0.1456\n",
      "Epoch 755/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1501 - val_loss: 0.1468\n",
      "Epoch 756/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1495 - val_loss: 0.1513\n",
      "Epoch 757/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1503 - val_loss: 0.1454\n",
      "Epoch 758/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1510 - val_loss: 0.1505\n",
      "Epoch 759/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1522 - val_loss: 0.1541\n",
      "Epoch 760/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1491 - val_loss: 0.1449\n",
      "Epoch 761/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1494 - val_loss: 0.1477\n",
      "Epoch 762/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1487 - val_loss: 0.1457\n",
      "Epoch 763/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1488 - val_loss: 0.1463\n",
      "Epoch 764/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1504 - val_loss: 0.1518\n",
      "Epoch 765/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1497 - val_loss: 0.1485\n",
      "Epoch 766/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1484 - val_loss: 0.1449\n",
      "Epoch 767/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1486 - val_loss: 0.1476\n",
      "Epoch 768/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1489 - val_loss: 0.1457\n",
      "Epoch 769/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1493 - val_loss: 0.1448\n",
      "Epoch 770/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1487 - val_loss: 0.1454\n",
      "Epoch 771/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1485 - val_loss: 0.1455\n",
      "Epoch 772/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1485 - val_loss: 0.1451\n",
      "Epoch 773/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1493 - val_loss: 0.1518\n",
      "Epoch 774/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.114 - 0s 32us/sample - loss: 0.1501 - val_loss: 0.1470\n",
      "Epoch 775/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1489 - val_loss: 0.1437\n",
      "Epoch 776/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1483 - val_loss: 0.1512\n",
      "Epoch 777/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1483 - val_loss: 0.1442\n",
      "Epoch 778/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1476 - val_loss: 0.1462\n",
      "Epoch 779/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1485 - val_loss: 0.1442\n",
      "Epoch 780/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1472 - val_loss: 0.1475\n",
      "Epoch 781/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1475 - val_loss: 0.1444\n",
      "Epoch 782/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1470 - val_loss: 0.1440\n",
      "Epoch 783/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1472 - val_loss: 0.1439\n",
      "Epoch 784/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1485 - val_loss: 0.1474\n",
      "Epoch 785/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1468 - val_loss: 0.1460\n",
      "Epoch 786/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1469 - val_loss: 0.1447\n",
      "Epoch 787/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1467 - val_loss: 0.1448\n",
      "Epoch 788/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1465 - val_loss: 0.1437\n",
      "Epoch 789/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1474 - val_loss: 0.1435\n",
      "Epoch 790/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1465 - val_loss: 0.1454\n",
      "Epoch 791/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1459 - val_loss: 0.1433\n",
      "Epoch 792/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1456 - val_loss: 0.1460\n",
      "Epoch 793/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1459 - val_loss: 0.1455\n",
      "Epoch 794/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1460 - val_loss: 0.1459\n",
      "Epoch 795/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1479 - val_loss: 0.1457\n",
      "Epoch 796/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1470 - val_loss: 0.1439\n",
      "Epoch 797/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1463 - val_loss: 0.1421\n",
      "Epoch 798/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1484 - val_loss: 0.1480\n",
      "Epoch 799/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1460 - val_loss: 0.1428\n",
      "Epoch 800/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1481 - val_loss: 0.1423\n",
      "Epoch 801/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1481 - val_loss: 0.1521\n",
      "Epoch 802/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1456 - val_loss: 0.1432\n",
      "Epoch 803/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1450 - val_loss: 0.1465\n",
      "Epoch 804/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1455 - val_loss: 0.1430\n",
      "Epoch 805/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1456 - val_loss: 0.1417\n",
      "Epoch 806/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1456 - val_loss: 0.1496\n",
      "Epoch 807/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1445 - val_loss: 0.1413\n",
      "Epoch 808/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1465 - val_loss: 0.1543\n",
      "Epoch 809/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1468 - val_loss: 0.1409\n",
      "Epoch 810/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1459 - val_loss: 0.1420\n",
      "Epoch 811/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1457 - val_loss: 0.1415\n",
      "Epoch 812/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1467 - val_loss: 0.1486\n",
      "Epoch 813/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1446 - val_loss: 0.1411\n",
      "Epoch 814/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1448 - val_loss: 0.1422\n",
      "Epoch 815/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1446 - val_loss: 0.1462\n",
      "Epoch 816/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1448 - val_loss: 0.1408\n",
      "Epoch 817/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1466 - val_loss: 0.1425\n",
      "Epoch 818/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1445 - val_loss: 0.1410\n",
      "Epoch 819/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1467 - val_loss: 0.1449\n",
      "Epoch 820/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1437 - val_loss: 0.1415\n",
      "Epoch 821/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1438 - val_loss: 0.1457\n",
      "Epoch 822/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1433 - val_loss: 0.1404\n",
      "Epoch 823/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1433 - val_loss: 0.1470\n",
      "Epoch 824/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1430 - val_loss: 0.1400\n",
      "Epoch 825/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1449 - val_loss: 0.1472\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1446 - val_loss: 0.1425\n",
      "Epoch 827/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1442 - val_loss: 0.1406\n",
      "Epoch 828/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1426 - val_loss: 0.1418\n",
      "Epoch 829/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1427 - val_loss: 0.1435\n",
      "Epoch 830/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1436 - val_loss: 0.1400\n",
      "Epoch 831/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1432 - val_loss: 0.1419\n",
      "Epoch 832/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1430 - val_loss: 0.1446\n",
      "Epoch 833/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1426 - val_loss: 0.1399\n",
      "Epoch 834/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1426 - val_loss: 0.1409\n",
      "Epoch 835/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1425 - val_loss: 0.1401\n",
      "Epoch 836/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1431 - val_loss: 0.1406\n",
      "Epoch 837/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1415 - val_loss: 0.1412\n",
      "Epoch 838/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1420 - val_loss: 0.1410\n",
      "Epoch 839/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1427 - val_loss: 0.1420\n",
      "Epoch 840/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1416 - val_loss: 0.1396\n",
      "Epoch 841/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1414 - val_loss: 0.1404\n",
      "Epoch 842/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1410 - val_loss: 0.1421\n",
      "Epoch 843/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1417 - val_loss: 0.1394\n",
      "Epoch 844/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1407 - val_loss: 0.1404\n",
      "Epoch 845/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1414 - val_loss: 0.1422\n",
      "Epoch 846/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1404 - val_loss: 0.1409\n",
      "Epoch 847/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1411 - val_loss: 0.1427\n",
      "Epoch 848/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1410 - val_loss: 0.1414\n",
      "Epoch 849/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1418 - val_loss: 0.1386\n",
      "Epoch 850/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1418 - val_loss: 0.1423\n",
      "Epoch 851/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1403 - val_loss: 0.1377\n",
      "Epoch 852/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1406 - val_loss: 0.1456\n",
      "Epoch 853/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1402 - val_loss: 0.1394\n",
      "Epoch 854/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1396 - val_loss: 0.1433\n",
      "Epoch 855/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1398 - val_loss: 0.1380\n",
      "Epoch 856/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1401 - val_loss: 0.1434\n",
      "Epoch 857/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1398 - val_loss: 0.1411\n",
      "Epoch 858/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1391 - val_loss: 0.1386\n",
      "Epoch 859/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1394 - val_loss: 0.1401\n",
      "Epoch 860/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1390 - val_loss: 0.1381\n",
      "Epoch 861/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1403 - val_loss: 0.1377\n",
      "Epoch 862/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1396 - val_loss: 0.1445\n",
      "Epoch 863/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1394 - val_loss: 0.1381\n",
      "Epoch 864/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1394 - val_loss: 0.1384\n",
      "Epoch 865/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1390 - val_loss: 0.1412\n",
      "Epoch 866/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1387 - val_loss: 0.1371\n",
      "Epoch 867/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1389 - val_loss: 0.1378\n",
      "Epoch 868/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1382 - val_loss: 0.1418\n",
      "Epoch 869/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1386 - val_loss: 0.1377\n",
      "Epoch 870/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1375 - val_loss: 0.1420\n",
      "Epoch 871/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1392 - val_loss: 0.1391\n",
      "Epoch 872/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1384 - val_loss: 0.1383\n",
      "Epoch 873/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1373 - val_loss: 0.1395\n",
      "Epoch 874/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1374 - val_loss: 0.1371\n",
      "Epoch 875/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1375 - val_loss: 0.1369\n",
      "Epoch 876/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1371 - val_loss: 0.1388\n",
      "Epoch 877/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1375 - val_loss: 0.1412\n",
      "Epoch 878/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1378 - val_loss: 0.1370\n",
      "Epoch 879/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1365 - val_loss: 0.1386\n",
      "Epoch 880/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1369 - val_loss: 0.1390\n",
      "Epoch 881/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1364 - val_loss: 0.1367\n",
      "Epoch 882/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1365 - val_loss: 0.1406\n",
      "Epoch 883/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1371 - val_loss: 0.1364\n",
      "Epoch 884/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1371 - val_loss: 0.1406\n",
      "Epoch 885/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1372 - val_loss: 0.1387\n",
      "Epoch 886/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1370 - val_loss: 0.1360\n",
      "Epoch 887/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1368 - val_loss: 0.1401\n",
      "Epoch 888/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1371 - val_loss: 0.1356\n",
      "Epoch 889/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1379 - val_loss: 0.1429\n",
      "Epoch 890/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1361 - val_loss: 0.1351\n",
      "Epoch 891/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1361 - val_loss: 0.1379\n",
      "Epoch 892/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1381 - val_loss: 0.1355\n",
      "Epoch 893/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1366 - val_loss: 0.1369\n",
      "Epoch 894/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1368 - val_loss: 0.1366\n",
      "Epoch 895/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1349 - val_loss: 0.1355\n",
      "Epoch 896/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1359 - val_loss: 0.1414\n",
      "Epoch 897/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1362 - val_loss: 0.1343\n",
      "Epoch 898/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1377 - val_loss: 0.1459\n",
      "Epoch 899/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1406 - val_loss: 0.1420\n",
      "Epoch 900/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1402 - val_loss: 0.1363\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1365 - val_loss: 0.1430\n",
      "Epoch 902/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1343 - val_loss: 0.1342\n",
      "Epoch 903/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1343 - val_loss: 0.1425\n",
      "Epoch 904/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1355 - val_loss: 0.1342\n",
      "Epoch 905/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1361 - val_loss: 0.1370\n",
      "Epoch 906/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1360 - val_loss: 0.1370\n",
      "Epoch 907/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1359 - val_loss: 0.1385\n",
      "Epoch 908/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1345 - val_loss: 0.1361\n",
      "Epoch 909/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1338 - val_loss: 0.1347\n",
      "Epoch 910/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1349 - val_loss: 0.1358\n",
      "Epoch 911/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1342 - val_loss: 0.1377\n",
      "Epoch 912/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1351 - val_loss: 0.1380\n",
      "Epoch 913/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1340 - val_loss: 0.1361\n",
      "Epoch 914/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1346 - val_loss: 0.1337\n",
      "Epoch 915/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1333 - val_loss: 0.1364\n",
      "Epoch 916/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1336 - val_loss: 0.1349\n",
      "Epoch 917/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1334 - val_loss: 0.1336\n",
      "Epoch 918/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1336 - val_loss: 0.1393\n",
      "Epoch 919/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1339 - val_loss: 0.1336\n",
      "Epoch 920/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1331 - val_loss: 0.1400\n",
      "Epoch 921/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1337 - val_loss: 0.1351\n",
      "Epoch 922/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1323 - val_loss: 0.1346\n",
      "Epoch 923/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1349 - val_loss: 0.1335\n",
      "Epoch 924/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1328 - val_loss: 0.1373\n",
      "Epoch 925/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1340 - val_loss: 0.1377\n",
      "Epoch 926/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1333 - val_loss: 0.1346\n",
      "Epoch 927/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1337 - val_loss: 0.1331\n",
      "Epoch 928/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1326 - val_loss: 0.1344\n",
      "Epoch 929/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1325 - val_loss: 0.1372\n",
      "Epoch 930/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1330 - val_loss: 0.1339\n",
      "Epoch 931/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1329 - val_loss: 0.1327\n",
      "Epoch 932/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1322 - val_loss: 0.1367\n",
      "Epoch 933/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1330 - val_loss: 0.1353\n",
      "Epoch 934/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1317 - val_loss: 0.1328\n",
      "Epoch 935/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1323 - val_loss: 0.1383\n",
      "Epoch 936/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1340 - val_loss: 0.1319\n",
      "Epoch 937/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1324 - val_loss: 0.1354\n",
      "Epoch 938/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1325 - val_loss: 0.1338\n",
      "Epoch 939/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1317 - val_loss: 0.1341\n",
      "Epoch 940/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1318 - val_loss: 0.1327\n",
      "Epoch 941/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1312 - val_loss: 0.1375\n",
      "Epoch 942/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1334 - val_loss: 0.1353\n",
      "Epoch 943/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1310 - val_loss: 0.1332\n",
      "Epoch 944/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1323 - val_loss: 0.1417\n",
      "Epoch 945/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1319 - val_loss: 0.1316\n",
      "Epoch 946/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1315 - val_loss: 0.1330\n",
      "Epoch 947/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1310 - val_loss: 0.1375\n",
      "Epoch 948/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1314 - val_loss: 0.1322\n",
      "Epoch 949/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1302 - val_loss: 0.1371\n",
      "Epoch 950/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1306 - val_loss: 0.1321\n",
      "Epoch 951/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1326 - val_loss: 0.1344\n",
      "Epoch 952/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1305 - val_loss: 0.1319\n",
      "Epoch 953/1000\n",
      "1791/1791 [==============================] - 0s 21us/sample - loss: 0.1319 - val_loss: 0.1325\n",
      "Epoch 954/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1306 - val_loss: 0.1342\n",
      "Epoch 955/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1304 - val_loss: 0.1353\n",
      "Epoch 956/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1303 - val_loss: 0.1310\n",
      "Epoch 957/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1314 - val_loss: 0.1329\n",
      "Epoch 958/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1308 - val_loss: 0.1323\n",
      "Epoch 959/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1307 - val_loss: 0.1311\n",
      "Epoch 960/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1304 - val_loss: 0.1327\n",
      "Epoch 961/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1297 - val_loss: 0.1349\n",
      "Epoch 962/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1307 - val_loss: 0.1316\n",
      "Epoch 963/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1302 - val_loss: 0.1351\n",
      "Epoch 964/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1298 - val_loss: 0.1333\n",
      "Epoch 965/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1304 - val_loss: 0.1376\n",
      "Epoch 966/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1308 - val_loss: 0.1308\n",
      "Epoch 967/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1310 - val_loss: 0.1342\n",
      "Epoch 968/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1297 - val_loss: 0.1342\n",
      "Epoch 969/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1300 - val_loss: 0.1325\n",
      "Epoch 970/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1295 - val_loss: 0.1325\n",
      "Epoch 971/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1301 - val_loss: 0.1331\n",
      "Epoch 972/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1296 - val_loss: 0.1344\n",
      "Epoch 973/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1303 - val_loss: 0.1328\n",
      "Epoch 974/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1293 - val_loss: 0.1315\n",
      "Epoch 975/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1290 - val_loss: 0.1313\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1301 - val_loss: 0.1332\n",
      "Epoch 977/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1292 - val_loss: 0.1317\n",
      "Epoch 978/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1291 - val_loss: 0.1327\n",
      "Epoch 979/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1287 - val_loss: 0.1337\n",
      "Epoch 980/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1296 - val_loss: 0.1349\n",
      "Epoch 981/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1285 - val_loss: 0.1337\n",
      "Epoch 982/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1282 - val_loss: 0.1330\n",
      "Epoch 983/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1285 - val_loss: 0.1323\n",
      "Epoch 984/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1282 - val_loss: 0.1311\n",
      "Epoch 985/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1285 - val_loss: 0.1393\n",
      "Epoch 986/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1291 - val_loss: 0.1310\n",
      "Epoch 987/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1275 - val_loss: 0.1318\n",
      "Epoch 988/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1280 - val_loss: 0.1350\n",
      "Epoch 989/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1269 - val_loss: 0.1312\n",
      "Epoch 990/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1275 - val_loss: 0.1361\n",
      "Epoch 991/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1287 - val_loss: 0.1307\n",
      "Epoch 992/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1277 - val_loss: 0.1309\n",
      "Epoch 993/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1272 - val_loss: 0.1308\n",
      "Epoch 994/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1277 - val_loss: 0.1320\n",
      "Epoch 995/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1281 - val_loss: 0.1336\n",
      "Epoch 996/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1270 - val_loss: 0.1312\n",
      "Epoch 997/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1272 - val_loss: 0.1313\n",
      "Epoch 998/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1265 - val_loss: 0.1314\n",
      "Epoch 999/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1267 - val_loss: 0.1317\n",
      "Epoch 1000/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1265 - val_loss: 0.1346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21510604f08>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=1000,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop],batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x215116fe308>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[344   5]\n",
      " [ 20 228]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.96       349\n",
      "           1       0.98      0.92      0.95       248\n",
      "\n",
      "    accuracy                           0.96       597\n",
      "   macro avg       0.96      0.95      0.96       597\n",
      "weighted avg       0.96      0.96      0.96       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_ANN_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANN_scaler.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler,'ANN_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = df.drop('Cancer Positive',axis=1).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    31.000000\n",
       "BMI                    10.204207\n",
       "BreastFeeding           1.000000\n",
       "Marital Status          1.000000\n",
       "Alcohol                 0.000000\n",
       "Smoking                 0.000000\n",
       "BreastCancerHistory     0.000000\n",
       "Age at firstPeriod     12.000000\n",
       "MenstrualCycle          1.000000\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = scaler.transform(new_data.values.reshape(-1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28125   , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30769231, 1.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00055713]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055713055189698935"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(new_data)[0][0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "later_model = load_model('final_ANN_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00055713]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "later_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
